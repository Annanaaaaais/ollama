# Documentation

All information about Ollama beyond the main README can be found in three main areas:

1. The documentation describes all the features and functionality of Ollama.
2. [Tutorials](./tutorials.md) apply the documentation to tasks.
3. [Examples](./examples) include working tools and applications that use Ollama in interesting ways.

## Documentation Topics

To get started, see the project's **[quicktart](../README.md#quickstart)**.

Ollama has a REST API. For more information see the **[API Documentation](./api.md)**.

Create new models or modify models already in the library using the Modelfile. Learn more about the Modelfile syntax in the **[Modelfile Documentation](./modelfile.md)**.

Import models using source model weights found on Hugging Face and similar sites by referring to the **[Import Documentation](./import.md)**.

Installing on Linux in most cases is easy using the script on Ollama.ai. To get more detail about the install, including CUDA drivers, see the **[Linux Documentation](./linux.md)**.

Ollama can be deployed using Docker. Learn more about using Docker with Ollama using the **[Docker Documentation](./docker.md)**.

It is easy to install on Linux and Mac, but many users will choose to build Ollama on their own. To do this, refer to the **[Development Documentation](./development.md)**.

If encountering a problem with Ollama, the best place to start is the logs. Find more information about them here in the **[Troubleshooting Guide](./troubleshooting.md)**.

Finally for all the questions that don't fit anywhere else, there is the **[FAQ](./faq.md)**
