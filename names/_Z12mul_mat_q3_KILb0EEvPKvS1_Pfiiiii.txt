.entry _Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii
.param .u64 _Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_0,
.param .u64 _Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_1,
.param .u64 _Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_2,
.param .u32 _Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_3,
.param .u32 _Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_4,
.param .u32 _Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_5,
.param .u32 _Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_6,
.param .u32 _Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_7
)
{
.reg .pred %p<166>;
.reg .b16 %rs<139>;
.reg .f32 %f<1967>;
.reg .b32 %r<8725>;
.reg .b64 %rd<481>;

	.shared .align 4 .b8 _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a69mul_mat_qILi256ELi4ELi16ELb0E10block_q3_KLi128ELi128ELi4EXadL_ZNS_19allocate_tiles_q3_KILi128EEEvPPiPP7__half2S4_S4_EEXadL_ZNS_15load_tiles_q3_KILi128ELi4ELb0EEEvPKvS3_S6_S3_S3_RKiSC_SC_SC_EELi2EXadL_ZNS_25vec_dot_q3_K_q8_1_mul_matEPSB_PKS5_SD_SD_SD_SF_SC_SC_SC_EEEEvSA_SA_PfiiiiiE9tile_y_qs[16384];

	.shared .align 4 .b8 _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a69mul_mat_qILi256ELi4ELi16ELb0E10block_q3_KLi128ELi128ELi4EXadL_ZNS_19allocate_tiles_q3_KILi128EEEvPPiPP7__half2S4_S4_EEXadL_ZNS_15load_tiles_q3_KILi128ELi4ELb0EEEvPKvS3_S6_S3_S3_RKiSC_SC_SC_EELi2EXadL_ZNS_25vec_dot_q3_K_q8_1_mul_matEPSB_PKS5_SD_SD_SD_SF_SC_SC_SC_EEEEvSA_SA_PfiiiiiE9tile_y_ds[2048];

ld.param.u64 %rd33, [_Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_0];
ld.param.u64 %rd34, [_Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_1];
ld.param.u32 %r51, [_Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_3];
ld.param.u32 %r48, [_Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_5];
ld.param.u32 %r49, [_Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_6];
shr.s32 %r52, %r51, 31;
shr.u32 %r53, %r52, 24;
add.s32 %r54, %r51, %r53;
shr.s32 %r1, %r54, 8;
setp.gt.s32 %p1, %r51, 255;
@%p1 bra $L__BB53_2;
bra.uni $L__BB53_1;

$L__BB53_2:
shr.s32 %r56, %r49, 31;
shr.u32 %r57, %r56, 27;
add.s32 %r58, %r49, %r57;
shr.s32 %r2, %r58, 5;
mov.u32 %r55, 0;
mov.f32 %f1711, 0f00000000;
cvta.to.global.u64 %rd36, %rd33;
cvta.to.global.u64 %rd309, %rd34;
mov.f32 %f1712, %f1711;
mov.f32 %f1713, %f1711;
mov.f32 %f1714, %f1711;
mov.f32 %f1715, %f1711;
mov.f32 %f1716, %f1711;
mov.f32 %f1717, %f1711;
mov.f32 %f1718, %f1711;
mov.f32 %f1719, %f1711;
mov.f32 %f1720, %f1711;
mov.f32 %f1721, %f1711;
mov.f32 %f1722, %f1711;
mov.f32 %f1723, %f1711;
mov.f32 %f1724, %f1711;
mov.f32 %f1725, %f1711;
mov.f32 %f1726, %f1711;
mov.f32 %f1727, %f1711;
mov.f32 %f1728, %f1711;
mov.f32 %f1729, %f1711;
mov.f32 %f1730, %f1711;
mov.f32 %f1731, %f1711;
mov.f32 %f1732, %f1711;
mov.f32 %f1733, %f1711;
mov.f32 %f1734, %f1711;
mov.f32 %f1735, %f1711;
mov.f32 %f1736, %f1711;
mov.f32 %f1737, %f1711;
mov.f32 %f1738, %f1711;
mov.f32 %f1739, %f1711;
mov.f32 %f1740, %f1711;
mov.f32 %f1741, %f1711;
mov.f32 %f1742, %f1711;
mov.f32 %f1743, %f1711;
mov.f32 %f1744, %f1711;
mov.f32 %f1745, %f1711;
mov.f32 %f1746, %f1711;
mov.f32 %f1747, %f1711;
mov.f32 %f1748, %f1711;
mov.f32 %f1749, %f1711;
mov.f32 %f1750, %f1711;
mov.f32 %f1751, %f1711;
mov.f32 %f1752, %f1711;
mov.f32 %f1753, %f1711;
mov.f32 %f1754, %f1711;
mov.f32 %f1755, %f1711;
mov.f32 %f1756, %f1711;
mov.f32 %f1757, %f1711;
mov.f32 %f1758, %f1711;
mov.f32 %f1759, %f1711;
mov.f32 %f1760, %f1711;
mov.f32 %f1761, %f1711;
mov.f32 %f1762, %f1711;
mov.f32 %f1763, %f1711;
mov.f32 %f1764, %f1711;
mov.f32 %f1765, %f1711;
mov.f32 %f1766, %f1711;
mov.f32 %f1767, %f1711;
mov.f32 %f1768, %f1711;
mov.f32 %f1769, %f1711;
mov.f32 %f1770, %f1711;
mov.f32 %f1771, %f1711;
mov.f32 %f1772, %f1711;
mov.f32 %f1773, %f1711;
mov.f32 %f1774, %f1711;
mov.f32 %f1775, %f1711;
mov.f32 %f1776, %f1711;
mov.f32 %f1777, %f1711;
mov.f32 %f1778, %f1711;
mov.f32 %f1779, %f1711;
mov.f32 %f1780, %f1711;
mov.f32 %f1781, %f1711;
mov.f32 %f1782, %f1711;
mov.f32 %f1783, %f1711;
mov.f32 %f1784, %f1711;
mov.f32 %f1785, %f1711;
mov.f32 %f1786, %f1711;
mov.f32 %f1787, %f1711;
mov.f32 %f1788, %f1711;
mov.f32 %f1789, %f1711;
mov.f32 %f1790, %f1711;
mov.f32 %f1791, %f1711;
mov.f32 %f1792, %f1711;
mov.f32 %f1793, %f1711;
mov.f32 %f1794, %f1711;
mov.f32 %f1795, %f1711;
mov.f32 %f1796, %f1711;
mov.f32 %f1797, %f1711;
mov.f32 %f1798, %f1711;
mov.f32 %f1799, %f1711;
mov.f32 %f1800, %f1711;
mov.f32 %f1801, %f1711;
mov.f32 %f1802, %f1711;
mov.f32 %f1803, %f1711;
mov.f32 %f1804, %f1711;
mov.f32 %f1805, %f1711;
mov.f32 %f1806, %f1711;
mov.f32 %f1807, %f1711;
mov.f32 %f1808, %f1711;
mov.f32 %f1809, %f1711;
mov.f32 %f1810, %f1711;
mov.f32 %f1811, %f1711;
mov.f32 %f1812, %f1711;
mov.f32 %f1813, %f1711;
mov.f32 %f1814, %f1711;
mov.f32 %f1815, %f1711;
mov.f32 %f1816, %f1711;
mov.f32 %f1817, %f1711;
mov.f32 %f1818, %f1711;
mov.f32 %f1819, %f1711;
mov.f32 %f1820, %f1711;
mov.f32 %f1821, %f1711;
mov.f32 %f1822, %f1711;
mov.f32 %f1823, %f1711;
mov.f32 %f1824, %f1711;
mov.f32 %f1825, %f1711;
mov.f32 %f1826, %f1711;
mov.f32 %f1827, %f1711;
mov.f32 %f1828, %f1711;
mov.f32 %f1829, %f1711;
mov.f32 %f1830, %f1711;
mov.f32 %f1831, %f1711;
mov.f32 %f1832, %f1711;
mov.f32 %f1833, %f1711;
mov.f32 %f1834, %f1711;
mov.f32 %f1835, %f1711;
mov.f32 %f1836, %f1711;
mov.f32 %f1837, %f1711;
mov.f32 %f1838, %f1711;
mov.u32 %r8722, %r55;

$L__BB53_3:
mov.u32 %r84, %tid.x;
shr.u32 %r85, %r84, 1;
mov.u32 %r86, %tid.y;
shl.b32 %r87, %r86, 4;
add.s32 %r88, %r85, %r87;
add.s32 %r89, %r88, 64;
shr.u32 %r90, %r89, 4;
and.b32 %r91, %r84, 1;
add.s32 %r92, %r90, %r91;
shl.b32 %r93, %r89, 1;
add.s32 %r94, %r92, %r93;
shl.b32 %r95, %r94, 2;
mov.u32 %r96, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a619allocate_tiles_q3_KILi128EEEvPPiPP7__half2S2_S2_E9tile_x_dm;
add.s32 %r97, %r96, %r95;
shr.u32 %r98, %r88, 4;
add.s32 %r99, %r98, %r91;
shl.b32 %r100, %r88, 1;
add.s32 %r101, %r99, %r100;
shl.b32 %r102, %r101, 2;
add.s32 %r103, %r96, %r102;
mov.u32 %r104, %ctaid.x;
mul.lo.s32 %r105, %r104, %r1;
shl.b32 %r106, %r105, 7;
cvt.s64.s32 %rd37, %r106;
cvt.s64.s32 %rd38, %r8722;
add.s64 %rd39, %rd38, %rd37;
mul.lo.s64 %rd40, %rd39, 110;
add.s64 %rd41, %rd36, %rd40;
shr.u32 %r107, %r84, 4;
mul.lo.s32 %r108, %r86, %r1;
add.s32 %r109, %r108, %r107;
and.b32 %r110, %r84, 15;
shl.b32 %r111, %r84, 2;
and.b32 %r112, %r111, 60;
cvt.u64.u32 %rd42, %r112;
mul.wide.s32 %rd43, %r109, 110;
add.s64 %rd44, %rd41, %rd43;
add.s64 %rd45, %rd44, %rd42;
ld.global.nc.u16 %rs3, [%rd45+32];
ld.global.nc.u16 %rs4, [%rd45+34];
mov.b32 %r113, {%rs3, %rs4};
mad.lo.s32 %r114, %r86, 33, %r84;
shl.b32 %r115, %r114, 2;
mov.u32 %r116, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a619allocate_tiles_q3_KILi128EEEvPPiPP7__half2S2_S2_E9tile_x_ql;
add.s32 %r117, %r116, %r115;
st.shared.u32 [%r117], %r113;
shl.b32 %r118, %r1, 2;
add.s32 %r119, %r108, %r118;
add.s32 %r120, %r119, %r107;
mul.wide.s32 %rd46, %r120, 110;
add.s64 %rd47, %rd41, %rd46;
add.s64 %rd48, %rd47, %rd42;
ld.global.nc.u16 %rs5, [%rd48+32];
ld.global.nc.u16 %rs6, [%rd48+34];
mov.b32 %r121, {%rs5, %rs6};
st.shared.u32 [%r117+528], %r121;
add.s32 %r122, %r119, %r118;
add.s32 %r123, %r122, %r107;
mul.wide.s32 %rd49, %r123, 110;
add.s64 %rd50, %rd41, %rd49;
add.s64 %rd51, %rd50, %rd42;
ld.global.nc.u16 %rs7, [%rd51+32];
ld.global.nc.u16 %rs8, [%rd51+34];
mov.b32 %r124, {%rs7, %rs8};
st.shared.u32 [%r117+1056], %r124;
add.s32 %r125, %r122, %r118;
add.s32 %r126, %r125, %r107;
mul.wide.s32 %rd52, %r126, 110;
add.s64 %rd53, %rd41, %rd52;
add.s64 %rd54, %rd53, %rd42;
ld.global.nc.u16 %rs9, [%rd54+32];
ld.global.nc.u16 %rs10, [%rd54+34];
mov.b32 %r127, {%rs9, %rs10};
st.shared.u32 [%r117+1584], %r127;
add.s32 %r128, %r125, %r118;
add.s32 %r129, %r128, %r107;
mul.wide.s32 %rd55, %r129, 110;
add.s64 %rd56, %rd41, %rd55;
add.s64 %rd57, %rd56, %rd42;
ld.global.nc.u16 %rs11, [%rd57+32];
ld.global.nc.u16 %rs12, [%rd57+34];
mov.b32 %r130, {%rs11, %rs12};
st.shared.u32 [%r117+2112], %r130;
add.s32 %r131, %r128, %r118;
add.s32 %r132, %r131, %r107;
mul.wide.s32 %rd58, %r132, 110;
add.s64 %rd59, %rd41, %rd58;
add.s64 %rd60, %rd59, %rd42;
ld.global.nc.u16 %rs13, [%rd60+32];
ld.global.nc.u16 %rs14, [%rd60+34];
mov.b32 %r133, {%rs13, %rs14};
st.shared.u32 [%r117+2640], %r133;
add.s32 %r134, %r131, %r118;
add.s32 %r135, %r134, %r107;
mul.wide.s32 %rd61, %r135, 110;
add.s64 %rd62, %rd41, %rd61;
add.s64 %rd63, %rd62, %rd42;
ld.global.nc.u16 %rs15, [%rd63+32];
ld.global.nc.u16 %rs16, [%rd63+34];
mov.b32 %r136, {%rs15, %rs16};
st.shared.u32 [%r117+3168], %r136;
add.s32 %r137, %r134, %r118;
add.s32 %r138, %r137, %r107;
mul.wide.s32 %rd64, %r138, 110;
add.s64 %rd65, %rd41, %rd64;
add.s64 %rd66, %rd65, %rd42;
ld.global.nc.u16 %rs17, [%rd66+32];
ld.global.nc.u16 %rs18, [%rd66+34];
mov.b32 %r139, {%rs17, %rs18};
st.shared.u32 [%r117+3696], %r139;
add.s32 %r140, %r137, %r118;
cvt.s64.s32 %rd67, %r140;
cvt.u64.u32 %rd68, %r107;
add.s64 %rd69, %rd67, %rd68;
mul.lo.s64 %rd70, %rd69, 110;
add.s64 %rd71, %rd41, %rd70;
add.s64 %rd72, %rd71, %rd42;
ld.global.nc.u16 %rs19, [%rd72+32];
ld.global.nc.u16 %rs20, [%rd72+34];
mov.b32 %r141, {%rs19, %rs20};
st.shared.u32 [%r117+4224], %r141;
add.s32 %r142, %r140, %r118;
cvt.s64.s32 %rd73, %r142;
add.s64 %rd74, %rd73, %rd68;
mul.lo.s64 %rd75, %rd74, 110;
add.s64 %rd76, %rd41, %rd75;
add.s64 %rd77, %rd76, %rd42;
ld.global.nc.u16 %rs21, [%rd77+32];
ld.global.nc.u16 %rs22, [%rd77+34];
mov.b32 %r143, {%rs21, %rs22};
st.shared.u32 [%r117+4752], %r143;
add.s32 %r144, %r142, %r118;
cvt.s64.s32 %rd78, %r144;
add.s64 %rd79, %rd78, %rd68;
mul.lo.s64 %rd80, %rd79, 110;
add.s64 %rd81, %rd41, %rd80;
add.s64 %rd82, %rd81, %rd42;
ld.global.nc.u16 %rs23, [%rd82+32];
ld.global.nc.u16 %rs24, [%rd82+34];
mov.b32 %r145, {%rs23, %rs24};
st.shared.u32 [%r117+5280], %r145;
add.s32 %r146, %r144, %r118;
cvt.s64.s32 %rd83, %r146;
add.s64 %rd84, %rd83, %rd68;
mul.lo.s64 %rd85, %rd84, 110;
add.s64 %rd86, %rd41, %rd85;
add.s64 %rd87, %rd86, %rd42;
ld.global.nc.u16 %rs25, [%rd87+32];
ld.global.nc.u16 %rs26, [%rd87+34];
mov.b32 %r147, {%rs25, %rs26};
st.shared.u32 [%r117+5808], %r147;
add.s32 %r148, %r146, %r118;
cvt.s64.s32 %rd88, %r148;
add.s64 %rd89, %rd88, %rd68;
mul.lo.s64 %rd90, %rd89, 110;
add.s64 %rd91, %rd41, %rd90;
add.s64 %rd92, %rd91, %rd42;
ld.global.nc.u16 %rs27, [%rd92+32];
ld.global.nc.u16 %rs28, [%rd92+34];
mov.b32 %r149, {%rs27, %rs28};
st.shared.u32 [%r117+6336], %r149;
add.s32 %r150, %r148, %r118;
cvt.s64.s32 %rd93, %r150;
add.s64 %rd94, %rd93, %rd68;
mul.lo.s64 %rd95, %rd94, 110;
add.s64 %rd96, %rd41, %rd95;
add.s64 %rd97, %rd96, %rd42;
ld.global.nc.u16 %rs29, [%rd97+32];
ld.global.nc.u16 %rs30, [%rd97+34];
mov.b32 %r151, {%rs29, %rs30};
st.shared.u32 [%r117+6864], %r151;
add.s32 %r152, %r150, %r118;
cvt.s64.s32 %rd98, %r152;
add.s64 %rd99, %rd98, %rd68;
mul.lo.s64 %rd100, %rd99, 110;
add.s64 %rd101, %rd41, %rd100;
add.s64 %rd102, %rd101, %rd42;
ld.global.nc.u16 %rs31, [%rd102+32];
ld.global.nc.u16 %rs32, [%rd102+34];
mov.b32 %r153, {%rs31, %rs32};
st.shared.u32 [%r117+7392], %r153;
add.s32 %r154, %r152, %r118;
cvt.s64.s32 %rd103, %r154;
add.s64 %rd104, %rd103, %rd68;
mul.lo.s64 %rd105, %rd104, 110;
add.s64 %rd106, %rd41, %rd105;
add.s64 %rd107, %rd106, %rd42;
ld.global.nc.u16 %rs33, [%rd107+32];
ld.global.nc.u16 %rs34, [%rd107+34];
mov.b32 %r155, {%rs33, %rs34};
st.shared.u32 [%r117+7920], %r155;
add.s32 %r156, %r154, %r118;
cvt.s64.s32 %rd108, %r156;
add.s64 %rd109, %rd108, %rd68;
mul.lo.s64 %rd110, %rd109, 110;
add.s64 %rd111, %rd41, %rd110;
add.s64 %rd112, %rd111, %rd42;
ld.global.nc.u16 %rs35, [%rd112+32];
ld.global.nc.u16 %rs36, [%rd112+34];
mov.b32 %r157, {%rs35, %rs36};
st.shared.u32 [%r117+8448], %r157;
add.s32 %r158, %r156, %r118;
cvt.s64.s32 %rd113, %r158;
add.s64 %rd114, %rd113, %rd68;
mul.lo.s64 %rd115, %rd114, 110;
add.s64 %rd116, %rd41, %rd115;
add.s64 %rd117, %rd116, %rd42;
ld.global.nc.u16 %rs37, [%rd117+32];
ld.global.nc.u16 %rs38, [%rd117+34];
mov.b32 %r159, {%rs37, %rs38};
st.shared.u32 [%r117+8976], %r159;
add.s32 %r160, %r158, %r118;
cvt.s64.s32 %rd118, %r160;
add.s64 %rd119, %rd118, %rd68;
mul.lo.s64 %rd120, %rd119, 110;
add.s64 %rd121, %rd41, %rd120;
add.s64 %rd122, %rd121, %rd42;
ld.global.nc.u16 %rs39, [%rd122+32];
ld.global.nc.u16 %rs40, [%rd122+34];
mov.b32 %r161, {%rs39, %rs40};
st.shared.u32 [%r117+9504], %r161;
add.s32 %r162, %r160, %r118;
cvt.s64.s32 %rd123, %r162;
add.s64 %rd124, %rd123, %rd68;
mul.lo.s64 %rd125, %rd124, 110;
add.s64 %rd126, %rd41, %rd125;
add.s64 %rd127, %rd126, %rd42;
ld.global.nc.u16 %rs41, [%rd127+32];
ld.global.nc.u16 %rs42, [%rd127+34];
mov.b32 %r163, {%rs41, %rs42};
st.shared.u32 [%r117+10032], %r163;
add.s32 %r164, %r162, %r118;
cvt.s64.s32 %rd128, %r164;
add.s64 %rd129, %rd128, %rd68;
mul.lo.s64 %rd130, %rd129, 110;
add.s64 %rd131, %rd41, %rd130;
add.s64 %rd132, %rd131, %rd42;
ld.global.nc.u16 %rs43, [%rd132+32];
ld.global.nc.u16 %rs44, [%rd132+34];
mov.b32 %r165, {%rs43, %rs44};
st.shared.u32 [%r117+10560], %r165;
add.s32 %r166, %r164, %r118;
cvt.s64.s32 %rd133, %r166;
add.s64 %rd134, %rd133, %rd68;
mul.lo.s64 %rd135, %rd134, 110;
add.s64 %rd136, %rd41, %rd135;
add.s64 %rd137, %rd136, %rd42;
ld.global.nc.u16 %rs45, [%rd137+32];
ld.global.nc.u16 %rs46, [%rd137+34];
mov.b32 %r167, {%rs45, %rs46};
st.shared.u32 [%r117+11088], %r167;
add.s32 %r168, %r166, %r118;
cvt.s64.s32 %rd138, %r168;
add.s64 %rd139, %rd138, %rd68;
mul.lo.s64 %rd140, %rd139, 110;
add.s64 %rd141, %rd41, %rd140;
add.s64 %rd142, %rd141, %rd42;
ld.global.nc.u16 %rs47, [%rd142+32];
ld.global.nc.u16 %rs48, [%rd142+34];
mov.b32 %r169, {%rs47, %rs48};
st.shared.u32 [%r117+11616], %r169;
add.s32 %r170, %r168, %r118;
cvt.s64.s32 %rd143, %r170;
add.s64 %rd144, %rd143, %rd68;
mul.lo.s64 %rd145, %rd144, 110;
add.s64 %rd146, %rd41, %rd145;
add.s64 %rd147, %rd146, %rd42;
ld.global.nc.u16 %rs49, [%rd147+32];
ld.global.nc.u16 %rs50, [%rd147+34];
mov.b32 %r171, {%rs49, %rs50};
st.shared.u32 [%r117+12144], %r171;
add.s32 %r172, %r170, %r118;
cvt.s64.s32 %rd148, %r172;
add.s64 %rd149, %rd148, %rd68;
mul.lo.s64 %rd150, %rd149, 110;
add.s64 %rd151, %rd41, %rd150;
add.s64 %rd152, %rd151, %rd42;
ld.global.nc.u16 %rs51, [%rd152+32];
ld.global.nc.u16 %rs52, [%rd152+34];
mov.b32 %r173, {%rs51, %rs52};
st.shared.u32 [%r117+12672], %r173;
add.s32 %r174, %r172, %r118;
cvt.s64.s32 %rd153, %r174;
add.s64 %rd154, %rd153, %rd68;
mul.lo.s64 %rd155, %rd154, 110;
add.s64 %rd156, %rd41, %rd155;
add.s64 %rd157, %rd156, %rd42;
ld.global.nc.u16 %rs53, [%rd157+32];
ld.global.nc.u16 %rs54, [%rd157+34];
mov.b32 %r175, {%rs53, %rs54};
st.shared.u32 [%r117+13200], %r175;
add.s32 %r176, %r174, %r118;
cvt.s64.s32 %rd158, %r176;
add.s64 %rd159, %rd158, %rd68;
mul.lo.s64 %rd160, %rd159, 110;
add.s64 %rd161, %rd41, %rd160;
add.s64 %rd162, %rd161, %rd42;
ld.global.nc.u16 %rs55, [%rd162+32];
ld.global.nc.u16 %rs56, [%rd162+34];
mov.b32 %r177, {%rs55, %rs56};
st.shared.u32 [%r117+13728], %r177;
add.s32 %r178, %r176, %r118;
cvt.s64.s32 %rd163, %r178;
add.s64 %rd164, %rd163, %rd68;
mul.lo.s64 %rd165, %rd164, 110;
add.s64 %rd166, %rd41, %rd165;
add.s64 %rd167, %rd166, %rd42;
ld.global.nc.u16 %rs57, [%rd167+32];
ld.global.nc.u16 %rs58, [%rd167+34];
mov.b32 %r179, {%rs57, %rs58};
st.shared.u32 [%r117+14256], %r179;
add.s32 %r180, %r178, %r118;
cvt.s64.s32 %rd168, %r180;
add.s64 %rd169, %rd168, %rd68;
mul.lo.s64 %rd170, %rd169, 110;
add.s64 %rd171, %rd41, %rd170;
add.s64 %rd172, %rd171, %rd42;
ld.global.nc.u16 %rs59, [%rd172+32];
ld.global.nc.u16 %rs60, [%rd172+34];
mov.b32 %r181, {%rs59, %rs60};
st.shared.u32 [%r117+14784], %r181;
add.s32 %r182, %r180, %r118;
cvt.s64.s32 %rd173, %r182;
add.s64 %rd174, %rd173, %rd68;
mul.lo.s64 %rd175, %rd174, 110;
add.s64 %rd176, %rd41, %rd175;
add.s64 %rd177, %rd176, %rd42;
ld.global.nc.u16 %rs61, [%rd177+32];
ld.global.nc.u16 %rs62, [%rd177+34];
mov.b32 %r183, {%rs61, %rs62};
st.shared.u32 [%r117+15312], %r183;
add.s32 %r184, %r182, %r118;
cvt.s64.s32 %rd178, %r184;
add.s64 %rd179, %rd178, %rd68;
mul.lo.s64 %rd180, %rd179, 110;
add.s64 %rd181, %rd41, %rd180;
add.s64 %rd182, %rd181, %rd42;
ld.global.nc.u16 %rs63, [%rd182+32];
ld.global.nc.u16 %rs64, [%rd182+34];
mov.b32 %r185, {%rs63, %rs64};
st.shared.u32 [%r117+15840], %r185;
add.s32 %r186, %r184, %r118;
cvt.s64.s32 %rd183, %r186;
add.s64 %rd184, %rd183, %rd68;
mul.lo.s64 %rd185, %rd184, 110;
add.s64 %rd186, %rd41, %rd185;
add.s64 %rd187, %rd186, %rd42;
ld.global.nc.u16 %rs65, [%rd187+32];
ld.global.nc.u16 %rs66, [%rd187+34];
mov.b32 %r187, {%rs65, %rs66};
st.shared.u32 [%r117+16368], %r187;
mul.lo.s32 %r188, %r88, %r1;
cvt.s64.s32 %rd188, %r188;
cvt.u64.u32 %rd189, %r91;
add.s64 %rd190, %rd188, %rd189;
mul.lo.s64 %rd191, %rd190, 110;
add.s64 %rd192, %rd41, %rd191;
ld.global.nc.u16 %rs1, [%rd192+108];

	{ cvt.f32.f16 %f1025, %rs1;}


	st.shared.f32 [%r103], %f1025;
shl.b32 %r189, %r1, 6;
add.s32 %r190, %r188, %r189;
cvt.s64.s32 %rd193, %r190;
add.s64 %rd194, %rd193, %rd189;
mul.lo.s64 %rd195, %rd194, 110;
add.s64 %rd196, %rd41, %rd195;
ld.global.nc.u16 %rs2, [%rd196+108];

	{ cvt.f32.f16 %f1026, %rs2;}


	st.shared.f32 [%r97], %f1026;
and.b32 %r191, %r84, 8;
shr.u32 %r192, %r191, 3;
shl.b32 %r193, %r86, 1;
add.s32 %r194, %r107, %r193;
mul.lo.s32 %r195, %r194, %r1;
add.s32 %r196, %r195, %r192;
and.b32 %r197, %r84, 7;
and.b32 %r198, %r111, 28;
cvt.u64.u32 %rd197, %r198;
mul.wide.s32 %rd198, %r196, 110;
add.s64 %rd199, %rd41, %rd198;
add.s64 %rd200, %rd199, %rd197;
ld.global.nc.u16 %rs67, [%rd200];
ld.global.nc.u16 %rs68, [%rd200+2];
mov.b32 %r199, {%rs67, %rs68};
not.b32 %r200, %r199;
shr.u32 %r201, %r194, 1;
add.s32 %r202, %r201, %r110;
shl.b32 %r203, %r194, 4;
add.s32 %r204, %r202, %r203;
shl.b32 %r205, %r204, 2;
mov.u32 %r206, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a619allocate_tiles_q3_KILi128EEEvPPiPP7__half2S2_S2_E9tile_x_qh;
add.s32 %r207, %r206, %r205;
st.shared.u32 [%r207], %r200;
shl.b32 %r208, %r1, 3;
add.s32 %r209, %r195, %r208;
add.s32 %r210, %r209, %r192;
mul.wide.s32 %rd201, %r210, 110;
add.s64 %rd202, %rd41, %rd201;
add.s64 %rd203, %rd202, %rd197;
ld.global.nc.u16 %rs69, [%rd203];
ld.global.nc.u16 %rs70, [%rd203+2];
mov.b32 %r211, {%rs69, %rs70};
not.b32 %r212, %r211;
add.s32 %r213, %r194, 8;
shr.u32 %r214, %r213, 1;
add.s32 %r215, %r214, %r110;
shl.b32 %r216, %r213, 4;
add.s32 %r217, %r215, %r216;
shl.b32 %r218, %r217, 2;
add.s32 %r219, %r206, %r218;
st.shared.u32 [%r219], %r212;
add.s32 %r220, %r209, %r208;
add.s32 %r221, %r220, %r192;
mul.wide.s32 %rd204, %r221, 110;
add.s64 %rd205, %rd41, %rd204;
add.s64 %rd206, %rd205, %rd197;
ld.global.nc.u16 %rs71, [%rd206];
ld.global.nc.u16 %rs72, [%rd206+2];
mov.b32 %r222, {%rs71, %rs72};
not.b32 %r223, %r222;
add.s32 %r224, %r194, 16;
shr.u32 %r225, %r224, 1;
add.s32 %r226, %r225, %r110;
shl.b32 %r227, %r224, 4;
add.s32 %r228, %r226, %r227;
shl.b32 %r229, %r228, 2;
add.s32 %r230, %r206, %r229;
st.shared.u32 [%r230], %r223;
add.s32 %r231, %r220, %r208;
add.s32 %r232, %r231, %r192;
mul.wide.s32 %rd207, %r232, 110;
add.s64 %rd208, %rd41, %rd207;
add.s64 %rd209, %rd208, %rd197;
ld.global.nc.u16 %rs73, [%rd209];
ld.global.nc.u16 %rs74, [%rd209+2];
mov.b32 %r233, {%rs73, %rs74};
not.b32 %r234, %r233;
add.s32 %r235, %r194, 24;
shr.u32 %r236, %r235, 1;
add.s32 %r237, %r236, %r110;
shl.b32 %r238, %r235, 4;
add.s32 %r239, %r237, %r238;
shl.b32 %r240, %r239, 2;
add.s32 %r241, %r206, %r240;
st.shared.u32 [%r241], %r234;
add.s32 %r242, %r231, %r208;
cvt.s64.s32 %rd210, %r242;
cvt.u64.u32 %rd211, %r192;
add.s64 %rd212, %rd210, %rd211;
mul.lo.s64 %rd213, %rd212, 110;
add.s64 %rd214, %rd41, %rd213;
add.s64 %rd215, %rd214, %rd197;
ld.global.nc.u16 %rs75, [%rd215];
ld.global.nc.u16 %rs76, [%rd215+2];
mov.b32 %r243, {%rs75, %rs76};
not.b32 %r244, %r243;
add.s32 %r245, %r194, 32;
shr.u32 %r246, %r245, 1;
add.s32 %r247, %r246, %r110;
shl.b32 %r248, %r245, 4;
add.s32 %r249, %r247, %r248;
shl.b32 %r250, %r249, 2;
add.s32 %r251, %r206, %r250;
st.shared.u32 [%r251], %r244;
add.s32 %r252, %r242, %r208;
cvt.s64.s32 %rd216, %r252;
add.s64 %rd217, %rd216, %rd211;
mul.lo.s64 %rd218, %rd217, 110;
add.s64 %rd219, %rd41, %rd218;
add.s64 %rd220, %rd219, %rd197;
ld.global.nc.u16 %rs77, [%rd220];
ld.global.nc.u16 %rs78, [%rd220+2];
mov.b32 %r253, {%rs77, %rs78};
not.b32 %r254, %r253;
add.s32 %r255, %r194, 40;
shr.u32 %r256, %r255, 1;
add.s32 %r257, %r256, %r110;
shl.b32 %r258, %r255, 4;
add.s32 %r259, %r257, %r258;
shl.b32 %r260, %r259, 2;
add.s32 %r261, %r206, %r260;
st.shared.u32 [%r261], %r254;
add.s32 %r262, %r252, %r208;
cvt.s64.s32 %rd221, %r262;
add.s64 %rd222, %rd221, %rd211;
mul.lo.s64 %rd223, %rd222, 110;
add.s64 %rd224, %rd41, %rd223;
add.s64 %rd225, %rd224, %rd197;
ld.global.nc.u16 %rs79, [%rd225];
ld.global.nc.u16 %rs80, [%rd225+2];
mov.b32 %r263, {%rs79, %rs80};
not.b32 %r264, %r263;
add.s32 %r265, %r194, 48;
shr.u32 %r266, %r265, 1;
add.s32 %r267, %r266, %r110;
shl.b32 %r268, %r265, 4;
add.s32 %r269, %r267, %r268;
shl.b32 %r270, %r269, 2;
add.s32 %r271, %r206, %r270;
st.shared.u32 [%r271], %r264;
add.s32 %r272, %r262, %r208;
cvt.s64.s32 %rd226, %r272;
add.s64 %rd227, %rd226, %rd211;
mul.lo.s64 %rd228, %rd227, 110;
add.s64 %rd229, %rd41, %rd228;
add.s64 %rd230, %rd229, %rd197;
ld.global.nc.u16 %rs81, [%rd230];
ld.global.nc.u16 %rs82, [%rd230+2];
mov.b32 %r273, {%rs81, %rs82};
not.b32 %r274, %r273;
add.s32 %r275, %r194, 56;
shr.u32 %r276, %r275, 1;
add.s32 %r277, %r276, %r110;
shl.b32 %r278, %r275, 4;
add.s32 %r279, %r277, %r278;
shl.b32 %r280, %r279, 2;
add.s32 %r281, %r206, %r280;
st.shared.u32 [%r281], %r274;
add.s32 %r282, %r272, %r208;
cvt.s64.s32 %rd231, %r282;
add.s64 %rd232, %rd231, %rd211;
mul.lo.s64 %rd233, %rd232, 110;
add.s64 %rd234, %rd41, %rd233;
add.s64 %rd235, %rd234, %rd197;
ld.global.nc.u16 %rs83, [%rd235];
ld.global.nc.u16 %rs84, [%rd235+2];
mov.b32 %r283, {%rs83, %rs84};
not.b32 %r284, %r283;
add.s32 %r285, %r194, 64;
shr.u32 %r286, %r285, 1;
add.s32 %r287, %r286, %r110;
shl.b32 %r288, %r285, 4;
add.s32 %r289, %r287, %r288;
shl.b32 %r290, %r289, 2;
add.s32 %r291, %r206, %r290;
st.shared.u32 [%r291], %r284;
add.s32 %r292, %r282, %r208;
cvt.s64.s32 %rd236, %r292;
add.s64 %rd237, %rd236, %rd211;
mul.lo.s64 %rd238, %rd237, 110;
add.s64 %rd239, %rd41, %rd238;
add.s64 %rd240, %rd239, %rd197;
ld.global.nc.u16 %rs85, [%rd240];
ld.global.nc.u16 %rs86, [%rd240+2];
mov.b32 %r293, {%rs85, %rs86};
not.b32 %r294, %r293;
add.s32 %r295, %r194, 72;
shr.u32 %r296, %r295, 1;
add.s32 %r297, %r296, %r110;
shl.b32 %r298, %r295, 4;
add.s32 %r299, %r297, %r298;
shl.b32 %r300, %r299, 2;
add.s32 %r301, %r206, %r300;
st.shared.u32 [%r301], %r294;
add.s32 %r302, %r292, %r208;
cvt.s64.s32 %rd241, %r302;
add.s64 %rd242, %rd241, %rd211;
mul.lo.s64 %rd243, %rd242, 110;
add.s64 %rd244, %rd41, %rd243;
add.s64 %rd245, %rd244, %rd197;
ld.global.nc.u16 %rs87, [%rd245];
ld.global.nc.u16 %rs88, [%rd245+2];
mov.b32 %r303, {%rs87, %rs88};
not.b32 %r304, %r303;
add.s32 %r305, %r194, 80;
shr.u32 %r306, %r305, 1;
add.s32 %r307, %r306, %r110;
shl.b32 %r308, %r305, 4;
add.s32 %r309, %r307, %r308;
shl.b32 %r310, %r309, 2;
add.s32 %r311, %r206, %r310;
st.shared.u32 [%r311], %r304;
add.s32 %r312, %r302, %r208;
cvt.s64.s32 %rd246, %r312;
add.s64 %rd247, %rd246, %rd211;
mul.lo.s64 %rd248, %rd247, 110;
add.s64 %rd249, %rd41, %rd248;
add.s64 %rd250, %rd249, %rd197;
ld.global.nc.u16 %rs89, [%rd250];
ld.global.nc.u16 %rs90, [%rd250+2];
mov.b32 %r313, {%rs89, %rs90};
not.b32 %r314, %r313;
add.s32 %r315, %r194, 88;
shr.u32 %r316, %r315, 1;
add.s32 %r317, %r316, %r110;
shl.b32 %r318, %r315, 4;
add.s32 %r319, %r317, %r318;
shl.b32 %r320, %r319, 2;
add.s32 %r321, %r206, %r320;
st.shared.u32 [%r321], %r314;
add.s32 %r322, %r312, %r208;
cvt.s64.s32 %rd251, %r322;
add.s64 %rd252, %rd251, %rd211;
mul.lo.s64 %rd253, %rd252, 110;
add.s64 %rd254, %rd41, %rd253;
add.s64 %rd255, %rd254, %rd197;
ld.global.nc.u16 %rs91, [%rd255];
ld.global.nc.u16 %rs92, [%rd255+2];
mov.b32 %r323, {%rs91, %rs92};
not.b32 %r324, %r323;
add.s32 %r325, %r194, 96;
shr.u32 %r326, %r325, 1;
add.s32 %r327, %r326, %r110;
shl.b32 %r328, %r325, 4;
add.s32 %r329, %r327, %r328;
shl.b32 %r330, %r329, 2;
add.s32 %r331, %r206, %r330;
st.shared.u32 [%r331], %r324;
add.s32 %r332, %r322, %r208;
cvt.s64.s32 %rd256, %r332;
add.s64 %rd257, %rd256, %rd211;
mul.lo.s64 %rd258, %rd257, 110;
add.s64 %rd259, %rd41, %rd258;
add.s64 %rd260, %rd259, %rd197;
ld.global.nc.u16 %rs93, [%rd260];
ld.global.nc.u16 %rs94, [%rd260+2];
mov.b32 %r333, {%rs93, %rs94};
not.b32 %r334, %r333;
add.s32 %r335, %r194, 104;
shr.u32 %r336, %r335, 1;
add.s32 %r337, %r336, %r110;
shl.b32 %r338, %r335, 4;
add.s32 %r339, %r337, %r338;
shl.b32 %r340, %r339, 2;
add.s32 %r341, %r206, %r340;
st.shared.u32 [%r341], %r334;
add.s32 %r342, %r332, %r208;
cvt.s64.s32 %rd261, %r342;
add.s64 %rd262, %rd261, %rd211;
mul.lo.s64 %rd263, %rd262, 110;
add.s64 %rd264, %rd41, %rd263;
add.s64 %rd265, %rd264, %rd197;
ld.global.nc.u16 %rs95, [%rd265];
ld.global.nc.u16 %rs96, [%rd265+2];
mov.b32 %r343, {%rs95, %rs96};
not.b32 %r344, %r343;
add.s32 %r345, %r194, 112;
shr.u32 %r346, %r345, 1;
add.s32 %r347, %r346, %r110;
shl.b32 %r348, %r345, 4;
add.s32 %r349, %r347, %r348;
shl.b32 %r350, %r349, 2;
add.s32 %r351, %r206, %r350;
st.shared.u32 [%r351], %r344;
add.s32 %r352, %r342, %r208;
cvt.s64.s32 %rd266, %r352;
add.s64 %rd267, %rd266, %rd211;
mul.lo.s64 %rd268, %rd267, 110;
add.s64 %rd269, %rd41, %rd268;
add.s64 %rd270, %rd269, %rd197;
ld.global.nc.u16 %rs97, [%rd270];
ld.global.nc.u16 %rs98, [%rd270+2];
mov.b32 %r353, {%rs97, %rs98};
not.b32 %r354, %r353;
add.s32 %r355, %r194, 120;
shr.u32 %r356, %r355, 1;
add.s32 %r357, %r356, %r110;
shl.b32 %r358, %r355, 4;
add.s32 %r359, %r357, %r358;
shl.b32 %r360, %r359, 2;
add.s32 %r361, %r206, %r360;
st.shared.u32 [%r361], %r354;
and.b32 %r362, %r84, 4;
shr.u32 %r363, %r362, 2;
shr.u32 %r364, %r84, 3;
shl.b32 %r365, %r86, 2;
add.s32 %r366, %r364, %r365;
mul.lo.s32 %r367, %r366, %r1;
add.s32 %r368, %r367, %r363;
and.b32 %r369, %r111, 4;
cvt.u64.u32 %rd271, %r369;
mul.wide.s32 %rd272, %r368, 110;
add.s64 %rd273, %rd41, %rd272;
add.s64 %rd274, %rd273, %rd271;
ld.global.nc.u16 %rs99, [%rd274+96];
ld.global.nc.u16 %rs100, [%rd274+98];
mov.b32 %r370, {%rs99, %rs100};
shl.b32 %r371, %r84, 1;
and.b32 %r372, %r371, 4;
shr.s32 %r373, %r370, %r372;
and.b32 %r374, %r373, 252645135;
ld.global.nc.u16 %rs101, [%rd273+104];
ld.global.nc.u16 %rs102, [%rd273+106];
mov.b32 %r375, {%rs101, %rs102};
and.b32 %r376, %r371, 6;
shr.s32 %r377, %r375, %r376;
shl.b32 %r378, %r377, 4;
and.b32 %r379, %r378, 808464432;
or.b32 %r60, %r379, %r374;
mov.u32 %r82, 538976288;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r60; 
mov.b32 b,%r82; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r59,r; 
}

	shr.u32 %r380, %r366, 2;
add.s32 %r381, %r380, %r197;
shl.b32 %r382, %r366, 3;
add.s32 %r383, %r381, %r382;
shl.b32 %r384, %r383, 2;
mov.u32 %r385, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a619allocate_tiles_q3_KILi128EEEvPPiPP7__half2S2_S2_E9tile_x_sc;
add.s32 %r386, %r385, %r384;
st.shared.u32 [%r386], %r59;
shl.b32 %r387, %r1, 4;
add.s32 %r388, %r367, %r387;
add.s32 %r389, %r388, %r363;
mul.wide.s32 %rd275, %r389, 110;
add.s64 %rd276, %rd41, %rd275;
add.s64 %rd277, %rd276, %rd271;
ld.global.nc.u16 %rs103, [%rd277+96];
ld.global.nc.u16 %rs104, [%rd277+98];
mov.b32 %r390, {%rs103, %rs104};
shr.s32 %r391, %r390, %r372;
and.b32 %r392, %r391, 252645135;
ld.global.nc.u16 %rs105, [%rd276+104];
ld.global.nc.u16 %rs106, [%rd276+106];
mov.b32 %r393, {%rs105, %rs106};
shr.s32 %r394, %r393, %r376;
shl.b32 %r395, %r394, 4;
and.b32 %r396, %r395, 808464432;
or.b32 %r63, %r396, %r392;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r63; 
mov.b32 b,%r82; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r62,r; 
}

	add.s32 %r397, %r366, 16;
shr.u32 %r398, %r397, 2;
add.s32 %r399, %r398, %r197;
shl.b32 %r400, %r397, 3;
add.s32 %r401, %r399, %r400;
shl.b32 %r402, %r401, 2;
add.s32 %r403, %r385, %r402;
st.shared.u32 [%r403], %r62;
add.s32 %r404, %r388, %r387;
cvt.s64.s32 %rd278, %r404;
cvt.u64.u32 %rd279, %r363;
add.s64 %rd280, %rd278, %rd279;
mul.lo.s64 %rd281, %rd280, 110;
add.s64 %rd282, %rd41, %rd281;
add.s64 %rd283, %rd282, %rd271;
ld.global.nc.u16 %rs107, [%rd283+96];
ld.global.nc.u16 %rs108, [%rd283+98];
mov.b32 %r405, {%rs107, %rs108};
shr.s32 %r406, %r405, %r372;
and.b32 %r407, %r406, 252645135;
ld.global.nc.u16 %rs109, [%rd282+104];
ld.global.nc.u16 %rs110, [%rd282+106];
mov.b32 %r408, {%rs109, %rs110};
shr.s32 %r409, %r408, %r376;
shl.b32 %r410, %r409, 4;
and.b32 %r411, %r410, 808464432;
or.b32 %r66, %r411, %r407;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r66; 
mov.b32 b,%r82; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r65,r; 
}

	add.s32 %r412, %r366, 32;
shr.u32 %r413, %r412, 2;
add.s32 %r414, %r413, %r197;
shl.b32 %r415, %r412, 3;
add.s32 %r416, %r414, %r415;
shl.b32 %r417, %r416, 2;
add.s32 %r418, %r385, %r417;
st.shared.u32 [%r418], %r65;
add.s32 %r419, %r404, %r387;
cvt.s64.s32 %rd284, %r419;
add.s64 %rd285, %rd284, %rd279;
mul.lo.s64 %rd286, %rd285, 110;
add.s64 %rd287, %rd41, %rd286;
add.s64 %rd288, %rd287, %rd271;
ld.global.nc.u16 %rs111, [%rd288+96];
ld.global.nc.u16 %rs112, [%rd288+98];
mov.b32 %r420, {%rs111, %rs112};
shr.s32 %r421, %r420, %r372;
and.b32 %r422, %r421, 252645135;
ld.global.nc.u16 %rs113, [%rd287+104];
ld.global.nc.u16 %rs114, [%rd287+106];
mov.b32 %r423, {%rs113, %rs114};
shr.s32 %r424, %r423, %r376;
shl.b32 %r425, %r424, 4;
and.b32 %r426, %r425, 808464432;
or.b32 %r69, %r426, %r422;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r69; 
mov.b32 b,%r82; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r68,r; 
}

	add.s32 %r427, %r366, 48;
shr.u32 %r428, %r427, 2;
add.s32 %r429, %r428, %r197;
shl.b32 %r430, %r427, 3;
add.s32 %r431, %r429, %r430;
shl.b32 %r432, %r431, 2;
add.s32 %r433, %r385, %r432;
st.shared.u32 [%r433], %r68;
add.s32 %r434, %r419, %r387;
cvt.s64.s32 %rd289, %r434;
add.s64 %rd290, %rd289, %rd279;
mul.lo.s64 %rd291, %rd290, 110;
add.s64 %rd292, %rd41, %rd291;
add.s64 %rd293, %rd292, %rd271;
ld.global.nc.u16 %rs115, [%rd293+96];
ld.global.nc.u16 %rs116, [%rd293+98];
mov.b32 %r435, {%rs115, %rs116};
shr.s32 %r436, %r435, %r372;
and.b32 %r437, %r436, 252645135;
ld.global.nc.u16 %rs117, [%rd292+104];
ld.global.nc.u16 %rs118, [%rd292+106];
mov.b32 %r438, {%rs117, %rs118};
shr.s32 %r439, %r438, %r376;
shl.b32 %r440, %r439, 4;
and.b32 %r441, %r440, 808464432;
or.b32 %r72, %r441, %r437;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r72; 
mov.b32 b,%r82; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r71,r; 
}

	add.s32 %r442, %r366, 64;
shr.u32 %r443, %r442, 2;
add.s32 %r444, %r443, %r197;
shl.b32 %r445, %r442, 3;
add.s32 %r446, %r444, %r445;
shl.b32 %r447, %r446, 2;
add.s32 %r448, %r385, %r447;
st.shared.u32 [%r448], %r71;
add.s32 %r449, %r434, %r387;
cvt.s64.s32 %rd294, %r449;
add.s64 %rd295, %rd294, %rd279;
mul.lo.s64 %rd296, %rd295, 110;
add.s64 %rd297, %rd41, %rd296;
add.s64 %rd298, %rd297, %rd271;
ld.global.nc.u16 %rs119, [%rd298+96];
ld.global.nc.u16 %rs120, [%rd298+98];
mov.b32 %r450, {%rs119, %rs120};
shr.s32 %r451, %r450, %r372;
and.b32 %r452, %r451, 252645135;
ld.global.nc.u16 %rs121, [%rd297+104];
ld.global.nc.u16 %rs122, [%rd297+106];
mov.b32 %r453, {%rs121, %rs122};
shr.s32 %r454, %r453, %r376;
shl.b32 %r455, %r454, 4;
and.b32 %r456, %r455, 808464432;
or.b32 %r75, %r456, %r452;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r75; 
mov.b32 b,%r82; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r74,r; 
}

	add.s32 %r457, %r366, 80;
shr.u32 %r458, %r457, 2;
add.s32 %r459, %r458, %r197;
shl.b32 %r460, %r457, 3;
add.s32 %r461, %r459, %r460;
shl.b32 %r462, %r461, 2;
add.s32 %r463, %r385, %r462;
st.shared.u32 [%r463], %r74;
add.s32 %r464, %r449, %r387;
cvt.s64.s32 %rd299, %r464;
add.s64 %rd300, %rd299, %rd279;
mul.lo.s64 %rd301, %rd300, 110;
add.s64 %rd302, %rd41, %rd301;
add.s64 %rd303, %rd302, %rd271;
ld.global.nc.u16 %rs123, [%rd303+96];
ld.global.nc.u16 %rs124, [%rd303+98];
mov.b32 %r465, {%rs123, %rs124};
shr.s32 %r466, %r465, %r372;
and.b32 %r467, %r466, 252645135;
ld.global.nc.u16 %rs125, [%rd302+104];
ld.global.nc.u16 %rs126, [%rd302+106];
mov.b32 %r468, {%rs125, %rs126};
shr.s32 %r469, %r468, %r376;
shl.b32 %r470, %r469, 4;
and.b32 %r471, %r470, 808464432;
or.b32 %r78, %r471, %r467;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r78; 
mov.b32 b,%r82; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r77,r; 
}

	add.s32 %r472, %r366, 96;
shr.u32 %r473, %r472, 2;
add.s32 %r474, %r473, %r197;
shl.b32 %r475, %r472, 3;
add.s32 %r476, %r474, %r475;
shl.b32 %r477, %r476, 2;
add.s32 %r478, %r385, %r477;
st.shared.u32 [%r478], %r77;
add.s32 %r479, %r464, %r387;
cvt.s64.s32 %rd304, %r479;
add.s64 %rd305, %rd304, %rd279;
mul.lo.s64 %rd306, %rd305, 110;
add.s64 %rd307, %rd41, %rd306;
add.s64 %rd308, %rd307, %rd271;
ld.global.nc.u16 %rs127, [%rd308+96];
ld.global.nc.u16 %rs128, [%rd308+98];
mov.b32 %r480, {%rs127, %rs128};
shr.s32 %r481, %r480, %r372;
and.b32 %r482, %r481, 252645135;
ld.global.nc.u16 %rs129, [%rd307+104];
ld.global.nc.u16 %rs130, [%rd307+106];
mov.b32 %r483, {%rs129, %rs130};
shr.s32 %r484, %r483, %r376;
shl.b32 %r485, %r484, 4;
and.b32 %r486, %r485, 808464432;
or.b32 %r81, %r486, %r482;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r81; 
mov.b32 b,%r82; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r80,r; 
}

	add.s32 %r487, %r366, 112;
shr.u32 %r488, %r487, 2;
add.s32 %r489, %r488, %r197;
shl.b32 %r490, %r487, 3;
add.s32 %r491, %r489, %r490;
shl.b32 %r492, %r491, 2;
add.s32 %r493, %r385, %r492;
st.shared.u32 [%r493], %r80;
mov.u32 %r8723, %r55;

$L__BB53_4:
mov.u32 %r8721, %tid.x;
shl.b32 %r8720, %r8721, 2;
and.b32 %r8719, %r8720, 28;
cvt.u64.u32 %rd480, %r8719;
mov.u32 %r8705, %tid.y;
mov.u32 %r8704, %tid.x;
shl.b32 %r499, %r8723, 5;
add.s32 %r500, %r499, %r8704;
shr.s32 %r501, %r500, 31;
shr.u32 %r502, %r501, 29;
add.s32 %r503, %r500, %r502;
shr.s32 %r504, %r503, 3;
mov.u32 %r505, %ctaid.y;
shl.b32 %r506, %r505, 7;
add.s32 %r508, %r506, %r8705;
add.s32 %r509, %r48, -1;
min.u32 %r510, %r508, %r509;
shl.b32 %r511, %r8722, 3;
add.s32 %r512, %r504, %r511;
mad.lo.s32 %r513, %r510, %r2, %r512;
shr.u32 %r514, %r501, 27;
add.s32 %r515, %r500, %r514;
and.b32 %r516, %r515, 1073741792;
sub.s32 %r517, %r500, %r516;
shl.b32 %r518, %r8705, 5;
add.s32 %r519, %r518, %r517;
mul.wide.s32 %rd311, %r513, 36;
add.s64 %rd312, %rd309, %rd311;
add.s64 %rd313, %rd312, %rd480;
ld.global.nc.u32 %r522, [%rd313+4];
shl.b32 %r523, %r519, 2;
mov.u32 %r524, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a69mul_mat_qILi256ELi4ELi16ELb0E10block_q3_KLi128ELi128ELi4EXadL_ZNS_19allocate_tiles_q3_KILi128EEEvPPiPP7__half2S4_S4_EEXadL_ZNS_15load_tiles_q3_KILi128ELi4ELb0EEEvPKvS3_S6_S3_S3_RKiSC_SC_SC_EELi2EXadL_ZNS_25vec_dot_q3_K_q8_1_mul_matEPSB_PKS5_SD_SD_SD_SF_SC_SC_SC_EEEEvSA_SA_PfiiiiiE9tile_y_qs;
add.s32 %r525, %r524, %r523;
st.shared.u32 [%r525], %r522;
add.s32 %r526, %r508, 4;
min.u32 %r527, %r526, %r509;
mad.lo.s32 %r528, %r527, %r2, %r512;
mul.wide.s32 %rd314, %r528, 36;
add.s64 %rd315, %rd309, %rd314;
add.s64 %rd316, %rd315, %rd480;
ld.global.nc.u32 %r529, [%rd316+4];
st.shared.u32 [%r525+512], %r529;
add.s32 %r530, %r508, 8;
min.u32 %r531, %r530, %r509;
mad.lo.s32 %r532, %r531, %r2, %r512;
mul.wide.s32 %rd317, %r532, 36;
add.s64 %rd318, %rd309, %rd317;
add.s64 %rd319, %rd318, %rd480;
ld.global.nc.u32 %r533, [%rd319+4];
st.shared.u32 [%r525+1024], %r533;
add.s32 %r534, %r508, 12;
min.u32 %r535, %r534, %r509;
mad.lo.s32 %r536, %r535, %r2, %r512;
mul.wide.s32 %rd320, %r536, 36;
add.s64 %rd321, %rd309, %rd320;
add.s64 %rd322, %rd321, %rd480;
ld.global.nc.u32 %r537, [%rd322+4];
st.shared.u32 [%r525+1536], %r537;
add.s32 %r538, %r508, 16;
min.u32 %r539, %r538, %r509;
mad.lo.s32 %r540, %r539, %r2, %r512;
mul.wide.s32 %rd323, %r540, 36;
add.s64 %rd324, %rd309, %rd323;
add.s64 %rd325, %rd324, %rd480;
ld.global.nc.u32 %r541, [%rd325+4];
st.shared.u32 [%r525+2048], %r541;
add.s32 %r542, %r508, 20;
min.u32 %r543, %r542, %r509;
mad.lo.s32 %r544, %r543, %r2, %r512;
mul.wide.s32 %rd326, %r544, 36;
add.s64 %rd327, %rd309, %rd326;
add.s64 %rd328, %rd327, %rd480;
ld.global.nc.u32 %r545, [%rd328+4];
st.shared.u32 [%r525+2560], %r545;
add.s32 %r546, %r508, 24;
min.u32 %r547, %r546, %r509;
mad.lo.s32 %r548, %r547, %r2, %r512;
mul.wide.s32 %rd329, %r548, 36;
add.s64 %rd330, %rd309, %rd329;
add.s64 %rd331, %rd330, %rd480;
ld.global.nc.u32 %r549, [%rd331+4];
st.shared.u32 [%r525+3072], %r549;
add.s32 %r550, %r508, 28;
min.u32 %r551, %r550, %r509;
mad.lo.s32 %r552, %r551, %r2, %r512;
mul.wide.s32 %rd332, %r552, 36;
add.s64 %rd333, %rd309, %rd332;
add.s64 %rd334, %rd333, %rd480;
ld.global.nc.u32 %r553, [%rd334+4];
st.shared.u32 [%r525+3584], %r553;
add.s32 %r554, %r508, 32;
min.u32 %r555, %r554, %r509;
mad.lo.s32 %r556, %r555, %r2, %r512;
mul.wide.s32 %rd335, %r556, 36;
add.s64 %rd336, %rd309, %rd335;
add.s64 %rd337, %rd336, %rd480;
ld.global.nc.u32 %r557, [%rd337+4];
st.shared.u32 [%r525+4096], %r557;
add.s32 %r558, %r508, 36;
min.u32 %r559, %r558, %r509;
mad.lo.s32 %r560, %r559, %r2, %r512;
mul.wide.s32 %rd338, %r560, 36;
add.s64 %rd339, %rd309, %rd338;
add.s64 %rd340, %rd339, %rd480;
ld.global.nc.u32 %r561, [%rd340+4];
st.shared.u32 [%r525+4608], %r561;
add.s32 %r562, %r508, 40;
min.u32 %r563, %r562, %r509;
mad.lo.s32 %r564, %r563, %r2, %r512;
mul.wide.s32 %rd341, %r564, 36;
add.s64 %rd342, %rd309, %rd341;
add.s64 %rd343, %rd342, %rd480;
ld.global.nc.u32 %r565, [%rd343+4];
st.shared.u32 [%r525+5120], %r565;
add.s32 %r566, %r508, 44;
min.u32 %r567, %r566, %r509;
mad.lo.s32 %r568, %r567, %r2, %r512;
mul.wide.s32 %rd344, %r568, 36;
add.s64 %rd345, %rd309, %rd344;
add.s64 %rd346, %rd345, %rd480;
ld.global.nc.u32 %r569, [%rd346+4];
st.shared.u32 [%r525+5632], %r569;
add.s32 %r570, %r508, 48;
min.u32 %r571, %r570, %r509;
mad.lo.s32 %r572, %r571, %r2, %r512;
mul.wide.s32 %rd347, %r572, 36;
add.s64 %rd348, %rd309, %rd347;
add.s64 %rd349, %rd348, %rd480;
ld.global.nc.u32 %r573, [%rd349+4];
st.shared.u32 [%r525+6144], %r573;
add.s32 %r574, %r508, 52;
min.u32 %r575, %r574, %r509;
mad.lo.s32 %r576, %r575, %r2, %r512;
mul.wide.s32 %rd350, %r576, 36;
add.s64 %rd351, %rd309, %rd350;
add.s64 %rd352, %rd351, %rd480;
ld.global.nc.u32 %r577, [%rd352+4];
st.shared.u32 [%r525+6656], %r577;
add.s32 %r578, %r508, 56;
min.u32 %r579, %r578, %r509;
mad.lo.s32 %r580, %r579, %r2, %r512;
mul.wide.s32 %rd353, %r580, 36;
add.s64 %rd354, %rd309, %rd353;
add.s64 %rd355, %rd354, %rd480;
ld.global.nc.u32 %r581, [%rd355+4];
st.shared.u32 [%r525+7168], %r581;
add.s32 %r582, %r508, 60;
min.u32 %r583, %r582, %r509;
mad.lo.s32 %r584, %r583, %r2, %r512;
mul.wide.s32 %rd356, %r584, 36;
add.s64 %rd357, %rd309, %rd356;
add.s64 %rd358, %rd357, %rd480;
ld.global.nc.u32 %r585, [%rd358+4];
st.shared.u32 [%r525+7680], %r585;
add.s32 %r586, %r508, 64;
min.u32 %r587, %r586, %r509;
mad.lo.s32 %r588, %r587, %r2, %r512;
mul.wide.s32 %rd359, %r588, 36;
add.s64 %rd360, %rd309, %rd359;
add.s64 %rd361, %rd360, %rd480;
ld.global.nc.u32 %r589, [%rd361+4];
st.shared.u32 [%r525+8192], %r589;
add.s32 %r590, %r508, 68;
min.u32 %r591, %r590, %r509;
mad.lo.s32 %r592, %r591, %r2, %r512;
mul.wide.s32 %rd362, %r592, 36;
add.s64 %rd363, %rd309, %rd362;
add.s64 %rd364, %rd363, %rd480;
ld.global.nc.u32 %r593, [%rd364+4];
st.shared.u32 [%r525+8704], %r593;
add.s32 %r594, %r508, 72;
min.u32 %r595, %r594, %r509;
mad.lo.s32 %r596, %r595, %r2, %r512;
mul.wide.s32 %rd365, %r596, 36;
add.s64 %rd366, %rd309, %rd365;
add.s64 %rd367, %rd366, %rd480;
ld.global.nc.u32 %r597, [%rd367+4];
st.shared.u32 [%r525+9216], %r597;
add.s32 %r598, %r508, 76;
min.u32 %r599, %r598, %r509;
mad.lo.s32 %r600, %r599, %r2, %r512;
mul.wide.s32 %rd368, %r600, 36;
add.s64 %rd369, %rd309, %rd368;
add.s64 %rd370, %rd369, %rd480;
ld.global.nc.u32 %r601, [%rd370+4];
st.shared.u32 [%r525+9728], %r601;
add.s32 %r602, %r508, 80;
min.u32 %r603, %r602, %r509;
mad.lo.s32 %r604, %r603, %r2, %r512;
mul.wide.s32 %rd371, %r604, 36;
add.s64 %rd372, %rd309, %rd371;
add.s64 %rd373, %rd372, %rd480;
ld.global.nc.u32 %r605, [%rd373+4];
st.shared.u32 [%r525+10240], %r605;
add.s32 %r606, %r508, 84;
min.u32 %r607, %r606, %r509;
mad.lo.s32 %r608, %r607, %r2, %r512;
mul.wide.s32 %rd374, %r608, 36;
add.s64 %rd375, %rd309, %rd374;
add.s64 %rd376, %rd375, %rd480;
ld.global.nc.u32 %r609, [%rd376+4];
st.shared.u32 [%r525+10752], %r609;
add.s32 %r610, %r508, 88;
min.u32 %r611, %r610, %r509;
mad.lo.s32 %r612, %r611, %r2, %r512;
mul.wide.s32 %rd377, %r612, 36;
add.s64 %rd378, %rd309, %rd377;
add.s64 %rd379, %rd378, %rd480;
ld.global.nc.u32 %r613, [%rd379+4];
st.shared.u32 [%r525+11264], %r613;
add.s32 %r614, %r508, 92;
min.u32 %r615, %r614, %r509;
mad.lo.s32 %r616, %r615, %r2, %r512;
mul.wide.s32 %rd380, %r616, 36;
add.s64 %rd381, %rd309, %rd380;
add.s64 %rd382, %rd381, %rd480;
ld.global.nc.u32 %r617, [%rd382+4];
st.shared.u32 [%r525+11776], %r617;
add.s32 %r618, %r508, 96;
min.u32 %r619, %r618, %r509;
mad.lo.s32 %r620, %r619, %r2, %r512;
mul.wide.s32 %rd383, %r620, 36;
add.s64 %rd384, %rd309, %rd383;
add.s64 %rd385, %rd384, %rd480;
ld.global.nc.u32 %r621, [%rd385+4];
st.shared.u32 [%r525+12288], %r621;
add.s32 %r622, %r508, 100;
min.u32 %r623, %r622, %r509;
mad.lo.s32 %r624, %r623, %r2, %r512;
mul.wide.s32 %rd386, %r624, 36;
add.s64 %rd387, %rd309, %rd386;
add.s64 %rd388, %rd387, %rd480;
ld.global.nc.u32 %r625, [%rd388+4];
st.shared.u32 [%r525+12800], %r625;
add.s32 %r626, %r508, 104;
min.u32 %r627, %r626, %r509;
mad.lo.s32 %r628, %r627, %r2, %r512;
mul.wide.s32 %rd389, %r628, 36;
add.s64 %rd390, %rd309, %rd389;
add.s64 %rd391, %rd390, %rd480;
ld.global.nc.u32 %r629, [%rd391+4];
st.shared.u32 [%r525+13312], %r629;
add.s32 %r630, %r508, 108;
min.u32 %r631, %r630, %r509;
mad.lo.s32 %r632, %r631, %r2, %r512;
mul.wide.s32 %rd392, %r632, 36;
add.s64 %rd393, %rd309, %rd392;
add.s64 %rd394, %rd393, %rd480;
ld.global.nc.u32 %r633, [%rd394+4];
st.shared.u32 [%r525+13824], %r633;
add.s32 %r634, %r508, 112;
min.u32 %r635, %r634, %r509;
mad.lo.s32 %r636, %r635, %r2, %r512;
mul.wide.s32 %rd395, %r636, 36;
add.s64 %rd396, %rd309, %rd395;
add.s64 %rd397, %rd396, %rd480;
ld.global.nc.u32 %r637, [%rd397+4];
st.shared.u32 [%r525+14336], %r637;
add.s32 %r638, %r508, 116;
min.u32 %r639, %r638, %r509;
mad.lo.s32 %r640, %r639, %r2, %r512;
mul.wide.s32 %rd398, %r640, 36;
add.s64 %rd399, %rd309, %rd398;
add.s64 %rd400, %rd399, %rd480;
ld.global.nc.u32 %r641, [%rd400+4];
st.shared.u32 [%r525+14848], %r641;
add.s32 %r642, %r508, 120;
min.u32 %r643, %r642, %r509;
mad.lo.s32 %r644, %r643, %r2, %r512;
mul.wide.s32 %rd401, %r644, 36;
add.s64 %rd402, %rd309, %rd401;
add.s64 %rd403, %rd402, %rd480;
ld.global.nc.u32 %r645, [%rd403+4];
st.shared.u32 [%r525+15360], %r645;
add.s32 %r646, %r508, 124;
min.u32 %r647, %r646, %r509;
mad.lo.s32 %r648, %r647, %r2, %r512;
mul.wide.s32 %rd404, %r648, 36;
add.s64 %rd405, %rd309, %rd404;
add.s64 %rd406, %rd405, %rd480;
ld.global.nc.u32 %r649, [%rd406+4];
st.shared.u32 [%r525+15872], %r649;
shl.b32 %r650, %r8705, 3;
shr.u32 %r651, %r8704, 2;
add.s32 %r652, %r651, %r650;
and.b32 %r653, %r8704, 3;
bfi.b32 %r654, %r8722, %r653, 3, 29;
shl.b32 %r655, %r8723, 2;
add.s32 %r656, %r654, %r655;
add.s32 %r657, %r652, %r506;
min.s32 %r658, %r657, %r509;
mad.lo.s32 %r659, %r658, %r2, %r656;
mul.wide.s32 %rd407, %r659, 36;
add.s64 %rd408, %rd309, %rd407;
bfi.b32 %r660, %r652, %r653, 2, 30;
shl.b32 %r661, %r660, 2;
mov.u32 %r662, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a69mul_mat_qILi256ELi4ELi16ELb0E10block_q3_KLi128ELi128ELi4EXadL_ZNS_19allocate_tiles_q3_KILi128EEEvPPiPP7__half2S4_S4_EEXadL_ZNS_15load_tiles_q3_KILi128ELi4ELb0EEEvPKvS3_S6_S3_S3_RKiSC_SC_SC_EELi2EXadL_ZNS_25vec_dot_q3_K_q8_1_mul_matEPSB_PKS5_SD_SD_SD_SF_SC_SC_SC_EEEEvSA_SA_PfiiiiiE9tile_y_ds;
add.s32 %r663, %r662, %r661;
ld.global.nc.u32 %r494, [%rd408];

	{.reg .f16 low,high;
mov.b32 {low,high}, %r494;
mov.b16 %rs131, low;}

	
	{ cvt.f32.f16 %f1027, %rs131;}


	st.shared.f32 [%r663], %f1027;
add.s32 %r664, %r657, 32;
min.s32 %r665, %r664, %r509;
mad.lo.s32 %r666, %r665, %r2, %r656;
mul.wide.s32 %rd409, %r666, 36;
add.s64 %rd410, %rd309, %rd409;
ld.global.nc.u32 %r495, [%rd410];

	{.reg .f16 low,high;
mov.b32 {low,high}, %r495;
mov.b16 %rs133, low;}

	
	{ cvt.f32.f16 %f1028, %rs133;}


	st.shared.f32 [%r663+512], %f1028;
add.s32 %r667, %r657, 64;
min.s32 %r668, %r667, %r509;
mad.lo.s32 %r669, %r668, %r2, %r656;
mul.wide.s32 %rd411, %r669, 36;
add.s64 %rd412, %rd309, %rd411;
ld.global.nc.u32 %r496, [%rd412];

	{.reg .f16 low,high;
mov.b32 {low,high}, %r496;
mov.b16 %rs135, low;}

	
	{ cvt.f32.f16 %f1029, %rs135;}


	st.shared.f32 [%r663+1024], %f1029;
add.s32 %r670, %r657, 96;
min.s32 %r671, %r670, %r509;
mad.lo.s32 %r672, %r671, %r2, %r656;
mul.wide.s32 %rd413, %r672, 36;
add.s64 %rd414, %rd309, %rd413;
ld.global.nc.u32 %r497, [%rd414];

	{.reg .f16 low,high;
mov.b32 {low,high}, %r497;
mov.b16 %rs137, low;}

	
	{ cvt.f32.f16 %f1030, %rs137;}


	st.shared.f32 [%r663+1536], %f1030;
bar.sync 0;
add.s32 %r673, %r499, 32;
shr.s32 %r5, %r673, 2;
shl.b32 %r8724, %r8723, 3;
setp.ge.s32 %p2, %r8724, %r5;
@%p2 bra $L__BB53_6;

$L__BB53_5:
mov.u32 %r8718, %tid.x;
mov.u32 %r8717, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a619allocate_tiles_q3_KILi128EEEvPPiPP7__half2S2_S2_E9tile_x_dm;
shl.b32 %r8716, %r8718, 1;
shr.u32 %r8715, %r8718, 4;
mov.u32 %r8714, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a619allocate_tiles_q3_KILi128EEEvPPiPP7__half2S2_S2_E9tile_x_qh;
mov.u32 %r8713, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a619allocate_tiles_q3_KILi128EEEvPPiPP7__half2S2_S2_E9tile_x_ql;
mov.u32 %r8712, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a619allocate_tiles_q3_KILi128EEEvPPiPP7__half2S2_S2_E9tile_x_sc;
shr.u32 %r8711, %r8718, 1;
shr.u32 %r7842, %r8724, 4;
shl.b32 %r7843, %r7842, 2;
and.b32 %r7844, %r8724, 6;
and.b32 %r7845, %r8724, 1073741816;
shl.b32 %r7846, %r7842, 3;
shr.u32 %r7847, %r8724, 1;
shl.b32 %r7848, %r8724, 2;
and.b32 %r7849, %r7848, 24;
or.b32 %r7852, %r518, %r7849;
shr.u32 %r7853, %r7852, 1;
add.s32 %r7855, %r662, %r7853;
add.s32 %r7858, %r651, %r7843;
shl.b32 %r7859, %r8718, 3;
add.s32 %r7860, %r7858, %r7859;
mad.lo.s32 %r7861, %r8718, 33, %r7845;
add.s32 %r7863, %r8711, %r7846;
shl.b32 %r7864, %r8718, 4;
add.s32 %r7865, %r7863, %r7864;
shl.b32 %r7866, %r7860, 2;
add.s32 %r7868, %r8712, %r7866;
shl.b32 %r7869, %r7861, 2;
add.s32 %r7871, %r8713, %r7869;
ld.shared.u32 %r7872, [%r7871];
mov.u32 %r7829, 0;
shr.s32 %r7873, %r7872, %r7844;
and.b32 %r5827, %r7873, 50529027;
shl.b32 %r7874, %r7865, 2;
add.s32 %r7876, %r8714, %r7874;
and.b32 %r7877, %r8724, 14;
shr.u32 %r7878, %r7877, 1;
ld.shared.u32 %r7879, [%r7876];
shr.s32 %r7880, %r7879, %r7878;
shl.b32 %r7881, %r7880, 2;
and.b32 %r5828, %r7881, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r674,r; 
}

	ld.shared.u32 %r7882, [%r7871+4];
shr.s32 %r7883, %r7882, %r7844;
and.b32 %r5830, %r7883, 50529027;
and.b32 %r7884, %r7847, 7;
ld.shared.u32 %r7885, [%r7876+4];
shr.s32 %r7886, %r7885, %r7884;
shl.b32 %r7887, %r7886, 2;
and.b32 %r5831, %r7887, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r677,r; 
}

	ld.shared.u32 %r7888, [%r7871+8];
shr.s32 %r7889, %r7888, %r7844;
and.b32 %r5833, %r7889, 50529027;
ld.shared.u32 %r7890, [%r7876+8];
shr.s32 %r7891, %r7890, %r7884;
shl.b32 %r7892, %r7891, 2;
and.b32 %r5834, %r7892, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r680,r; 
}

	ld.shared.u32 %r7893, [%r7871+12];
shr.s32 %r7894, %r7893, %r7844;
and.b32 %r5836, %r7894, 50529027;
ld.shared.u32 %r7895, [%r7876+12];
shr.s32 %r7896, %r7895, %r7884;
shl.b32 %r7897, %r7896, 2;
and.b32 %r5837, %r7897, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r683,r; 
}

	ld.shared.u32 %r7898, [%r7871+16];
shr.s32 %r7899, %r7898, %r7844;
and.b32 %r5839, %r7899, 50529027;
ld.shared.u32 %r7900, [%r7876+16];
shr.s32 %r7901, %r7900, %r7884;
shl.b32 %r7902, %r7901, 2;
and.b32 %r5840, %r7902, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r686,r; 
}

	ld.shared.u32 %r7903, [%r7871+20];
shr.s32 %r7904, %r7903, %r7844;
and.b32 %r5842, %r7904, 50529027;
ld.shared.u32 %r7905, [%r7876+20];
shr.s32 %r7906, %r7905, %r7884;
shl.b32 %r7907, %r7906, 2;
and.b32 %r5843, %r7907, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r689,r; 
}

	ld.shared.u32 %r7908, [%r7871+24];
shr.s32 %r7909, %r7908, %r7844;
and.b32 %r5845, %r7909, 50529027;
ld.shared.u32 %r7910, [%r7876+24];
shr.s32 %r7911, %r7910, %r7884;
shl.b32 %r7912, %r7911, 2;
and.b32 %r5846, %r7912, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r692,r; 
}

	ld.shared.u32 %r7913, [%r7871+28];
shr.s32 %r7914, %r7913, %r7844;
and.b32 %r5848, %r7914, 50529027;
ld.shared.u32 %r7915, [%r7876+28];
shr.s32 %r7916, %r7915, %r7884;
shl.b32 %r7917, %r7916, 2;
and.b32 %r5849, %r7917, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r695,r; 
}

	add.s32 %r7919, %r8715, %r7842;
add.s32 %r7921, %r7919, %r8716;
shl.b32 %r7922, %r7921, 2;
add.s32 %r7924, %r8717, %r7922;
shl.b32 %r7925, %r7852, 2;
add.s32 %r7927, %r524, %r7925;
ld.shared.u32 %r700, [%r7927];

	dp4a.s32.s32 %r698, %r674, %r700, %r7829;

	ld.shared.u32 %r872, [%r7927+4];

	dp4a.s32.s32 %r702, %r677, %r872, %r698;

	ld.shared.u32 %r876, [%r7927+8];

	dp4a.s32.s32 %r706, %r680, %r876, %r702;

	ld.shared.u32 %r880, [%r7927+12];

	dp4a.s32.s32 %r710, %r683, %r880, %r706;

	add.s32 %r7928, %r7868, %r7877;
ld.shared.s8 %r7929, [%r7928];
mul.lo.s32 %r7930, %r710, %r7929;
ld.shared.u32 %r884, [%r7927+16];

	dp4a.s32.s32 %r714, %r686, %r884, %r7829;

	ld.shared.u32 %r888, [%r7927+20];

	dp4a.s32.s32 %r718, %r689, %r888, %r714;

	ld.shared.u32 %r892, [%r7927+24];

	dp4a.s32.s32 %r722, %r692, %r892, %r718;

	ld.shared.u32 %r896, [%r7927+28];

	dp4a.s32.s32 %r726, %r695, %r896, %r722;

	ld.shared.s8 %r7931, [%r7928+1];
mad.lo.s32 %r7932, %r726, %r7931, %r7930;
ld.shared.f32 %f1031, [%r7855];
ld.shared.f32 %f1032, [%r7924];
mul.ftz.f32 %f1033, %f1032, %f1031;
cvt.rn.f32.s32 %f1034, %r7932;
fma.rn.ftz.f32 %f1838, %f1033, %f1034, %f1838;
add.s32 %r7933, %r8718, 32;
shr.u32 %r7934, %r7933, 2;
add.s32 %r7935, %r7934, %r7843;
shl.b32 %r7936, %r7933, 3;
add.s32 %r7937, %r7935, %r7936;
shr.u32 %r7938, %r7933, 1;
add.s32 %r7939, %r7938, %r7846;
shl.b32 %r7940, %r7933, 4;
add.s32 %r7941, %r7939, %r7940;
shl.b32 %r7942, %r7937, 2;
add.s32 %r7943, %r8712, %r7942;
ld.shared.u32 %r7944, [%r7871+4224];
shr.s32 %r7945, %r7944, %r7844;
and.b32 %r5883, %r7945, 50529027;
shl.b32 %r7946, %r7941, 2;
add.s32 %r7947, %r8714, %r7946;
ld.shared.u32 %r7948, [%r7947];
shr.s32 %r7949, %r7948, %r7878;
shl.b32 %r7950, %r7949, 2;
and.b32 %r5884, %r7950, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r730,r; 
}

	ld.shared.u32 %r7951, [%r7871+4228];
shr.s32 %r7952, %r7951, %r7844;
and.b32 %r5886, %r7952, 50529027;
ld.shared.u32 %r7953, [%r7947+4];
shr.s32 %r7954, %r7953, %r7884;
shl.b32 %r7955, %r7954, 2;
and.b32 %r5887, %r7955, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r733,r; 
}

	ld.shared.u32 %r7956, [%r7871+4232];
shr.s32 %r7957, %r7956, %r7844;
and.b32 %r5889, %r7957, 50529027;
ld.shared.u32 %r7958, [%r7947+8];
shr.s32 %r7959, %r7958, %r7884;
shl.b32 %r7960, %r7959, 2;
and.b32 %r5890, %r7960, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r736,r; 
}

	ld.shared.u32 %r7961, [%r7871+4236];
shr.s32 %r7962, %r7961, %r7844;
and.b32 %r5892, %r7962, 50529027;
ld.shared.u32 %r7963, [%r7947+12];
shr.s32 %r7964, %r7963, %r7884;
shl.b32 %r7965, %r7964, 2;
and.b32 %r5893, %r7965, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r739,r; 
}

	ld.shared.u32 %r7966, [%r7871+4240];
shr.s32 %r7967, %r7966, %r7844;
and.b32 %r5895, %r7967, 50529027;
ld.shared.u32 %r7968, [%r7947+16];
shr.s32 %r7969, %r7968, %r7884;
shl.b32 %r7970, %r7969, 2;
and.b32 %r5896, %r7970, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r742,r; 
}

	ld.shared.u32 %r7971, [%r7871+4244];
shr.s32 %r7972, %r7971, %r7844;
and.b32 %r5898, %r7972, 50529027;
ld.shared.u32 %r7973, [%r7947+20];
shr.s32 %r7974, %r7973, %r7884;
shl.b32 %r7975, %r7974, 2;
and.b32 %r5899, %r7975, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r745,r; 
}

	ld.shared.u32 %r7976, [%r7871+4248];
shr.s32 %r7977, %r7976, %r7844;
and.b32 %r5901, %r7977, 50529027;
ld.shared.u32 %r7978, [%r7947+24];
shr.s32 %r7979, %r7978, %r7884;
shl.b32 %r7980, %r7979, 2;
and.b32 %r5902, %r7980, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r748,r; 
}

	ld.shared.u32 %r7981, [%r7871+4252];
shr.s32 %r7982, %r7981, %r7844;
and.b32 %r5904, %r7982, 50529027;
ld.shared.u32 %r7983, [%r7947+28];
shr.s32 %r7984, %r7983, %r7884;
shl.b32 %r7985, %r7984, 2;
and.b32 %r5905, %r7985, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r751,r; 
}

	shr.u32 %r7986, %r7933, 4;
add.s32 %r7987, %r7986, %r7842;
shl.b32 %r7988, %r7933, 1;
add.s32 %r7989, %r7987, %r7988;
shl.b32 %r7990, %r7989, 2;
add.s32 %r7991, %r8717, %r7990;

	dp4a.s32.s32 %r754, %r730, %r700, %r7829;

	
	dp4a.s32.s32 %r758, %r733, %r872, %r754;

	
	dp4a.s32.s32 %r762, %r736, %r876, %r758;

	
	dp4a.s32.s32 %r766, %r739, %r880, %r762;

	add.s32 %r7992, %r7943, %r7877;
ld.shared.s8 %r7993, [%r7992];
mul.lo.s32 %r7994, %r766, %r7993;

	dp4a.s32.s32 %r770, %r742, %r884, %r7829;

	
	dp4a.s32.s32 %r774, %r745, %r888, %r770;

	
	dp4a.s32.s32 %r778, %r748, %r892, %r774;

	
	dp4a.s32.s32 %r782, %r751, %r896, %r778;

	ld.shared.s8 %r7995, [%r7992+1];
mad.lo.s32 %r7996, %r782, %r7995, %r7994;
ld.shared.f32 %f1035, [%r7991];
mul.ftz.f32 %f1036, %f1035, %f1031;
cvt.rn.f32.s32 %f1037, %r7996;
fma.rn.ftz.f32 %f1806, %f1036, %f1037, %f1806;
add.s32 %r7997, %r8718, 64;
shr.u32 %r7998, %r7997, 2;
add.s32 %r7999, %r7998, %r7843;
shl.b32 %r8000, %r7997, 3;
add.s32 %r8001, %r7999, %r8000;
shr.u32 %r8002, %r7997, 1;
add.s32 %r8003, %r8002, %r7846;
shl.b32 %r8004, %r7997, 4;
add.s32 %r8005, %r8003, %r8004;
shl.b32 %r8006, %r8001, 2;
add.s32 %r8007, %r8712, %r8006;
ld.shared.u32 %r8008, [%r7871+8448];
shr.s32 %r8009, %r8008, %r7844;
and.b32 %r5939, %r8009, 50529027;
shl.b32 %r8010, %r8005, 2;
add.s32 %r8011, %r8714, %r8010;
ld.shared.u32 %r8012, [%r8011];
shr.s32 %r8013, %r8012, %r7878;
shl.b32 %r8014, %r8013, 2;
and.b32 %r5940, %r8014, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r786,r; 
}

	ld.shared.u32 %r8015, [%r7871+8452];
shr.s32 %r8016, %r8015, %r7844;
and.b32 %r5942, %r8016, 50529027;
ld.shared.u32 %r8017, [%r8011+4];
shr.s32 %r8018, %r8017, %r7884;
shl.b32 %r8019, %r8018, 2;
and.b32 %r6167, %r8019, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r789,r; 
}

	ld.shared.u32 %r8020, [%r7871+8456];
shr.s32 %r8021, %r8020, %r7844;
and.b32 %r6169, %r8021, 50529027;
ld.shared.u32 %r8022, [%r8011+8];
shr.s32 %r8023, %r8022, %r7884;
shl.b32 %r8024, %r8023, 2;
and.b32 %r6170, %r8024, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r792,r; 
}

	ld.shared.u32 %r8025, [%r7871+8460];
shr.s32 %r8026, %r8025, %r7844;
and.b32 %r6172, %r8026, 50529027;
ld.shared.u32 %r8027, [%r8011+12];
shr.s32 %r8028, %r8027, %r7884;
shl.b32 %r8029, %r8028, 2;
and.b32 %r6173, %r8029, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r795,r; 
}

	ld.shared.u32 %r8030, [%r7871+8464];
shr.s32 %r8031, %r8030, %r7844;
and.b32 %r6175, %r8031, 50529027;
ld.shared.u32 %r8032, [%r8011+16];
shr.s32 %r8033, %r8032, %r7884;
shl.b32 %r8034, %r8033, 2;
and.b32 %r6176, %r8034, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r798,r; 
}

	ld.shared.u32 %r8035, [%r7871+8468];
shr.s32 %r8036, %r8035, %r7844;
and.b32 %r6178, %r8036, 50529027;
ld.shared.u32 %r8037, [%r8011+20];
shr.s32 %r8038, %r8037, %r7884;
shl.b32 %r8039, %r8038, 2;
and.b32 %r6179, %r8039, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r801,r; 
}

	ld.shared.u32 %r8040, [%r7871+8472];
shr.s32 %r8041, %r8040, %r7844;
and.b32 %r6181, %r8041, 50529027;
ld.shared.u32 %r8042, [%r8011+24];
shr.s32 %r8043, %r8042, %r7884;
shl.b32 %r8044, %r8043, 2;
and.b32 %r6182, %r8044, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r804,r; 
}

	ld.shared.u32 %r8045, [%r7871+8476];
shr.s32 %r8046, %r8045, %r7844;
and.b32 %r6184, %r8046, 50529027;
ld.shared.u32 %r8047, [%r8011+28];
shr.s32 %r8048, %r8047, %r7884;
shl.b32 %r8049, %r8048, 2;
and.b32 %r6185, %r8049, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r807,r; 
}

	shr.u32 %r8050, %r7997, 4;
add.s32 %r8051, %r8050, %r7842;
shl.b32 %r8052, %r7997, 1;
add.s32 %r8053, %r8051, %r8052;
shl.b32 %r8054, %r8053, 2;
add.s32 %r8055, %r8717, %r8054;

	dp4a.s32.s32 %r810, %r786, %r700, %r7829;

	
	dp4a.s32.s32 %r814, %r789, %r872, %r810;

	
	dp4a.s32.s32 %r818, %r792, %r876, %r814;

	
	dp4a.s32.s32 %r822, %r795, %r880, %r818;

	add.s32 %r8056, %r8007, %r7877;
ld.shared.s8 %r8057, [%r8056];
mul.lo.s32 %r8058, %r822, %r8057;

	dp4a.s32.s32 %r826, %r798, %r884, %r7829;

	
	dp4a.s32.s32 %r830, %r801, %r888, %r826;

	
	dp4a.s32.s32 %r834, %r804, %r892, %r830;

	
	dp4a.s32.s32 %r838, %r807, %r896, %r834;

	ld.shared.s8 %r8059, [%r8056+1];
mad.lo.s32 %r8060, %r838, %r8059, %r8058;
ld.shared.f32 %f1038, [%r8055];
mul.ftz.f32 %f1039, %f1038, %f1031;
cvt.rn.f32.s32 %f1040, %r8060;
fma.rn.ftz.f32 %f1774, %f1039, %f1040, %f1774;
add.s32 %r8061, %r8718, 96;
shr.u32 %r8062, %r8061, 2;
add.s32 %r8063, %r8062, %r7843;
shl.b32 %r8064, %r8061, 3;
add.s32 %r8065, %r8063, %r8064;
shr.u32 %r8066, %r8061, 1;
add.s32 %r8067, %r8066, %r7846;
shl.b32 %r8068, %r8061, 4;
add.s32 %r8069, %r8067, %r8068;
shl.b32 %r8070, %r8065, 2;
add.s32 %r8071, %r8712, %r8070;
ld.shared.u32 %r8072, [%r7871+12672];
shr.s32 %r8073, %r8072, %r7844;
and.b32 %r6219, %r8073, 50529027;
shl.b32 %r8074, %r8069, 2;
add.s32 %r8075, %r8714, %r8074;
ld.shared.u32 %r8076, [%r8075];
shr.s32 %r8077, %r8076, %r7878;
shl.b32 %r8078, %r8077, 2;
and.b32 %r6220, %r8078, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r842,r; 
}

	ld.shared.u32 %r8079, [%r7871+12676];
shr.s32 %r8080, %r8079, %r7844;
and.b32 %r6222, %r8080, 50529027;
ld.shared.u32 %r8081, [%r8075+4];
shr.s32 %r8082, %r8081, %r7884;
shl.b32 %r8083, %r8082, 2;
and.b32 %r6223, %r8083, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r845,r; 
}

	ld.shared.u32 %r8084, [%r7871+12680];
shr.s32 %r8085, %r8084, %r7844;
and.b32 %r6225, %r8085, 50529027;
ld.shared.u32 %r8086, [%r8075+8];
shr.s32 %r8087, %r8086, %r7884;
shl.b32 %r8088, %r8087, 2;
and.b32 %r6226, %r8088, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r848,r; 
}

	ld.shared.u32 %r8089, [%r7871+12684];
shr.s32 %r8090, %r8089, %r7844;
and.b32 %r6228, %r8090, 50529027;
ld.shared.u32 %r8091, [%r8075+12];
shr.s32 %r8092, %r8091, %r7884;
shl.b32 %r8093, %r8092, 2;
and.b32 %r6229, %r8093, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r851,r; 
}

	ld.shared.u32 %r8094, [%r7871+12688];
shr.s32 %r8095, %r8094, %r7844;
and.b32 %r6231, %r8095, 50529027;
ld.shared.u32 %r8096, [%r8075+16];
shr.s32 %r8097, %r8096, %r7884;
shl.b32 %r8098, %r8097, 2;
and.b32 %r6232, %r8098, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r854,r; 
}

	ld.shared.u32 %r8099, [%r7871+12692];
shr.s32 %r8100, %r8099, %r7844;
and.b32 %r6234, %r8100, 50529027;
ld.shared.u32 %r8101, [%r8075+20];
shr.s32 %r8102, %r8101, %r7884;
shl.b32 %r8103, %r8102, 2;
and.b32 %r6235, %r8103, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r857,r; 
}

	ld.shared.u32 %r8104, [%r7871+12696];
shr.s32 %r8105, %r8104, %r7844;
and.b32 %r6237, %r8105, 50529027;
ld.shared.u32 %r8106, [%r8075+24];
shr.s32 %r8107, %r8106, %r7884;
shl.b32 %r8108, %r8107, 2;
and.b32 %r6238, %r8108, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r860,r; 
}

	ld.shared.u32 %r8109, [%r7871+12700];
shr.s32 %r8110, %r8109, %r7844;
and.b32 %r6240, %r8110, 50529027;
ld.shared.u32 %r8111, [%r8075+28];
shr.s32 %r8112, %r8111, %r7884;
shl.b32 %r8113, %r8112, 2;
and.b32 %r6241, %r8113, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r863,r; 
}

	shr.u32 %r8114, %r8061, 4;
add.s32 %r8115, %r8114, %r7842;
shl.b32 %r8116, %r8061, 1;
add.s32 %r8117, %r8115, %r8116;
shl.b32 %r8118, %r8117, 2;
add.s32 %r8119, %r8717, %r8118;

	dp4a.s32.s32 %r866, %r842, %r700, %r7829;

	
	dp4a.s32.s32 %r870, %r845, %r872, %r866;

	
	dp4a.s32.s32 %r874, %r848, %r876, %r870;

	
	dp4a.s32.s32 %r878, %r851, %r880, %r874;

	add.s32 %r8120, %r8071, %r7877;
ld.shared.s8 %r8121, [%r8120];
mul.lo.s32 %r8122, %r878, %r8121;

	dp4a.s32.s32 %r882, %r854, %r884, %r7829;

	
	dp4a.s32.s32 %r886, %r857, %r888, %r882;

	
	dp4a.s32.s32 %r890, %r860, %r892, %r886;

	
	dp4a.s32.s32 %r894, %r863, %r896, %r890;

	ld.shared.s8 %r8123, [%r8120+1];
mad.lo.s32 %r8124, %r894, %r8123, %r8122;
ld.shared.f32 %f1041, [%r8119];
mul.ftz.f32 %f1042, %f1041, %f1031;
cvt.rn.f32.s32 %f1043, %r8124;
fma.rn.ftz.f32 %f1742, %f1042, %f1043, %f1742;
add.s32 %r8125, %r7852, 128;
shr.u32 %r8126, %r8125, 1;
add.s32 %r8127, %r662, %r8126;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r898,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r901,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r904,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r907,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r910,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r913,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r916,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r919,r; 
}

	ld.shared.u32 %r1092, [%r7927+512];

	dp4a.s32.s32 %r922, %r898, %r1092, %r7829;

	ld.shared.u32 %r1096, [%r7927+516];

	dp4a.s32.s32 %r926, %r901, %r1096, %r922;

	ld.shared.u32 %r1100, [%r7927+520];

	dp4a.s32.s32 %r930, %r904, %r1100, %r926;

	ld.shared.u32 %r1104, [%r7927+524];

	dp4a.s32.s32 %r934, %r907, %r1104, %r930;

	mul.lo.s32 %r8128, %r934, %r7929;
ld.shared.u32 %r1108, [%r7927+528];

	dp4a.s32.s32 %r938, %r910, %r1108, %r7829;

	ld.shared.u32 %r1112, [%r7927+532];

	dp4a.s32.s32 %r942, %r913, %r1112, %r938;

	ld.shared.u32 %r1116, [%r7927+536];

	dp4a.s32.s32 %r946, %r916, %r1116, %r942;

	ld.shared.u32 %r1120, [%r7927+540];

	dp4a.s32.s32 %r950, %r919, %r1120, %r946;

	mad.lo.s32 %r8129, %r950, %r7931, %r8128;
ld.shared.f32 %f1044, [%r8127];
mul.ftz.f32 %f1045, %f1032, %f1044;
cvt.rn.f32.s32 %f1046, %r8129;
fma.rn.ftz.f32 %f1837, %f1045, %f1046, %f1837;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r954,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r957,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r960,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r963,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r966,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r969,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r972,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r975,r; 
}

	
	dp4a.s32.s32 %r978, %r954, %r1092, %r7829;

	
	dp4a.s32.s32 %r982, %r957, %r1096, %r978;

	
	dp4a.s32.s32 %r986, %r960, %r1100, %r982;

	
	dp4a.s32.s32 %r990, %r963, %r1104, %r986;

	mul.lo.s32 %r8130, %r990, %r7993;

	dp4a.s32.s32 %r994, %r966, %r1108, %r7829;

	
	dp4a.s32.s32 %r998, %r969, %r1112, %r994;

	
	dp4a.s32.s32 %r1002, %r972, %r1116, %r998;

	
	dp4a.s32.s32 %r1006, %r975, %r1120, %r1002;

	mad.lo.s32 %r8131, %r1006, %r7995, %r8130;
mul.ftz.f32 %f1047, %f1035, %f1044;
cvt.rn.f32.s32 %f1048, %r8131;
fma.rn.ftz.f32 %f1805, %f1047, %f1048, %f1805;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1010,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1013,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1016,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1019,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1022,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1025,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1028,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1031,r; 
}

	
	dp4a.s32.s32 %r1034, %r1010, %r1092, %r7829;

	
	dp4a.s32.s32 %r1038, %r1013, %r1096, %r1034;

	
	dp4a.s32.s32 %r1042, %r1016, %r1100, %r1038;

	
	dp4a.s32.s32 %r1046, %r1019, %r1104, %r1042;

	mul.lo.s32 %r8132, %r1046, %r8057;

	dp4a.s32.s32 %r1050, %r1022, %r1108, %r7829;

	
	dp4a.s32.s32 %r1054, %r1025, %r1112, %r1050;

	
	dp4a.s32.s32 %r1058, %r1028, %r1116, %r1054;

	
	dp4a.s32.s32 %r1062, %r1031, %r1120, %r1058;

	mad.lo.s32 %r8133, %r1062, %r8059, %r8132;
mul.ftz.f32 %f1049, %f1038, %f1044;
cvt.rn.f32.s32 %f1050, %r8133;
fma.rn.ftz.f32 %f1773, %f1049, %f1050, %f1773;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1066,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1069,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1072,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1075,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1078,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1081,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1084,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1087,r; 
}

	
	dp4a.s32.s32 %r1090, %r1066, %r1092, %r7829;

	
	dp4a.s32.s32 %r1094, %r1069, %r1096, %r1090;

	
	dp4a.s32.s32 %r1098, %r1072, %r1100, %r1094;

	
	dp4a.s32.s32 %r1102, %r1075, %r1104, %r1098;

	mul.lo.s32 %r8134, %r1102, %r8121;

	dp4a.s32.s32 %r1106, %r1078, %r1108, %r7829;

	
	dp4a.s32.s32 %r1110, %r1081, %r1112, %r1106;

	
	dp4a.s32.s32 %r1114, %r1084, %r1116, %r1110;

	
	dp4a.s32.s32 %r1118, %r1087, %r1120, %r1114;

	mad.lo.s32 %r8135, %r1118, %r8123, %r8134;
mul.ftz.f32 %f1051, %f1041, %f1044;
cvt.rn.f32.s32 %f1052, %r8135;
fma.rn.ftz.f32 %f1741, %f1051, %f1052, %f1741;
add.s32 %r8136, %r7852, 256;
shr.u32 %r8137, %r8136, 1;
add.s32 %r8138, %r662, %r8137;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1122,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1125,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1128,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1131,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1134,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1137,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1140,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1143,r; 
}

	ld.shared.u32 %r1316, [%r7927+1024];

	dp4a.s32.s32 %r1146, %r1122, %r1316, %r7829;

	ld.shared.u32 %r1320, [%r7927+1028];

	dp4a.s32.s32 %r1150, %r1125, %r1320, %r1146;

	ld.shared.u32 %r1324, [%r7927+1032];

	dp4a.s32.s32 %r1154, %r1128, %r1324, %r1150;

	ld.shared.u32 %r1328, [%r7927+1036];

	dp4a.s32.s32 %r1158, %r1131, %r1328, %r1154;

	mul.lo.s32 %r8139, %r1158, %r7929;
ld.shared.u32 %r1332, [%r7927+1040];

	dp4a.s32.s32 %r1162, %r1134, %r1332, %r7829;

	ld.shared.u32 %r1336, [%r7927+1044];

	dp4a.s32.s32 %r1166, %r1137, %r1336, %r1162;

	ld.shared.u32 %r1340, [%r7927+1048];

	dp4a.s32.s32 %r1170, %r1140, %r1340, %r1166;

	ld.shared.u32 %r1344, [%r7927+1052];

	dp4a.s32.s32 %r1174, %r1143, %r1344, %r1170;

	mad.lo.s32 %r8140, %r1174, %r7931, %r8139;
ld.shared.f32 %f1053, [%r8138];
mul.ftz.f32 %f1054, %f1032, %f1053;
cvt.rn.f32.s32 %f1055, %r8140;
fma.rn.ftz.f32 %f1836, %f1054, %f1055, %f1836;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1178,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1181,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1184,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1187,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1190,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1193,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1196,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1199,r; 
}

	
	dp4a.s32.s32 %r1202, %r1178, %r1316, %r7829;

	
	dp4a.s32.s32 %r1206, %r1181, %r1320, %r1202;

	
	dp4a.s32.s32 %r1210, %r1184, %r1324, %r1206;

	
	dp4a.s32.s32 %r1214, %r1187, %r1328, %r1210;

	mul.lo.s32 %r8141, %r1214, %r7993;

	dp4a.s32.s32 %r1218, %r1190, %r1332, %r7829;

	
	dp4a.s32.s32 %r1222, %r1193, %r1336, %r1218;

	
	dp4a.s32.s32 %r1226, %r1196, %r1340, %r1222;

	
	dp4a.s32.s32 %r1230, %r1199, %r1344, %r1226;

	mad.lo.s32 %r8142, %r1230, %r7995, %r8141;
mul.ftz.f32 %f1056, %f1035, %f1053;
cvt.rn.f32.s32 %f1057, %r8142;
fma.rn.ftz.f32 %f1804, %f1056, %f1057, %f1804;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1234,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1237,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1240,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1243,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1246,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1249,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1252,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1255,r; 
}

	
	dp4a.s32.s32 %r1258, %r1234, %r1316, %r7829;

	
	dp4a.s32.s32 %r1262, %r1237, %r1320, %r1258;

	
	dp4a.s32.s32 %r1266, %r1240, %r1324, %r1262;

	
	dp4a.s32.s32 %r1270, %r1243, %r1328, %r1266;

	mul.lo.s32 %r8143, %r1270, %r8057;

	dp4a.s32.s32 %r1274, %r1246, %r1332, %r7829;

	
	dp4a.s32.s32 %r1278, %r1249, %r1336, %r1274;

	
	dp4a.s32.s32 %r1282, %r1252, %r1340, %r1278;

	
	dp4a.s32.s32 %r1286, %r1255, %r1344, %r1282;

	mad.lo.s32 %r8144, %r1286, %r8059, %r8143;
mul.ftz.f32 %f1058, %f1038, %f1053;
cvt.rn.f32.s32 %f1059, %r8144;
fma.rn.ftz.f32 %f1772, %f1058, %f1059, %f1772;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1290,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1293,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1296,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1299,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1302,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1305,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1308,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1311,r; 
}

	
	dp4a.s32.s32 %r1314, %r1290, %r1316, %r7829;

	
	dp4a.s32.s32 %r1318, %r1293, %r1320, %r1314;

	
	dp4a.s32.s32 %r1322, %r1296, %r1324, %r1318;

	
	dp4a.s32.s32 %r1326, %r1299, %r1328, %r1322;

	mul.lo.s32 %r8145, %r1326, %r8121;

	dp4a.s32.s32 %r1330, %r1302, %r1332, %r7829;

	
	dp4a.s32.s32 %r1334, %r1305, %r1336, %r1330;

	
	dp4a.s32.s32 %r1338, %r1308, %r1340, %r1334;

	
	dp4a.s32.s32 %r1342, %r1311, %r1344, %r1338;

	mad.lo.s32 %r8146, %r1342, %r8123, %r8145;
mul.ftz.f32 %f1060, %f1041, %f1053;
cvt.rn.f32.s32 %f1061, %r8146;
fma.rn.ftz.f32 %f1740, %f1060, %f1061, %f1740;
add.s32 %r8147, %r7852, 384;
shr.u32 %r8148, %r8147, 1;
add.s32 %r8149, %r662, %r8148;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1346,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1349,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1352,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1355,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1358,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1361,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1364,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1367,r; 
}

	ld.shared.u32 %r1540, [%r7927+1536];

	dp4a.s32.s32 %r1370, %r1346, %r1540, %r7829;

	ld.shared.u32 %r1544, [%r7927+1540];

	dp4a.s32.s32 %r1374, %r1349, %r1544, %r1370;

	ld.shared.u32 %r1548, [%r7927+1544];

	dp4a.s32.s32 %r1378, %r1352, %r1548, %r1374;

	ld.shared.u32 %r1552, [%r7927+1548];

	dp4a.s32.s32 %r1382, %r1355, %r1552, %r1378;

	mul.lo.s32 %r8150, %r1382, %r7929;
ld.shared.u32 %r1556, [%r7927+1552];

	dp4a.s32.s32 %r1386, %r1358, %r1556, %r7829;

	ld.shared.u32 %r1560, [%r7927+1556];

	dp4a.s32.s32 %r1390, %r1361, %r1560, %r1386;

	ld.shared.u32 %r1564, [%r7927+1560];

	dp4a.s32.s32 %r1394, %r1364, %r1564, %r1390;

	ld.shared.u32 %r1568, [%r7927+1564];

	dp4a.s32.s32 %r1398, %r1367, %r1568, %r1394;

	mad.lo.s32 %r8151, %r1398, %r7931, %r8150;
ld.shared.f32 %f1062, [%r8149];
mul.ftz.f32 %f1063, %f1032, %f1062;
cvt.rn.f32.s32 %f1064, %r8151;
fma.rn.ftz.f32 %f1835, %f1063, %f1064, %f1835;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1402,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1405,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1408,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1411,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1414,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1417,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1420,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1423,r; 
}

	
	dp4a.s32.s32 %r1426, %r1402, %r1540, %r7829;

	
	dp4a.s32.s32 %r1430, %r1405, %r1544, %r1426;

	
	dp4a.s32.s32 %r1434, %r1408, %r1548, %r1430;

	
	dp4a.s32.s32 %r1438, %r1411, %r1552, %r1434;

	mul.lo.s32 %r8152, %r1438, %r7993;

	dp4a.s32.s32 %r1442, %r1414, %r1556, %r7829;

	
	dp4a.s32.s32 %r1446, %r1417, %r1560, %r1442;

	
	dp4a.s32.s32 %r1450, %r1420, %r1564, %r1446;

	
	dp4a.s32.s32 %r1454, %r1423, %r1568, %r1450;

	mad.lo.s32 %r8153, %r1454, %r7995, %r8152;
mul.ftz.f32 %f1065, %f1035, %f1062;
cvt.rn.f32.s32 %f1066, %r8153;
fma.rn.ftz.f32 %f1803, %f1065, %f1066, %f1803;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1458,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1461,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1464,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1467,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1470,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1473,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1476,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1479,r; 
}

	
	dp4a.s32.s32 %r1482, %r1458, %r1540, %r7829;

	
	dp4a.s32.s32 %r1486, %r1461, %r1544, %r1482;

	
	dp4a.s32.s32 %r1490, %r1464, %r1548, %r1486;

	
	dp4a.s32.s32 %r1494, %r1467, %r1552, %r1490;

	mul.lo.s32 %r8154, %r1494, %r8057;

	dp4a.s32.s32 %r1498, %r1470, %r1556, %r7829;

	
	dp4a.s32.s32 %r1502, %r1473, %r1560, %r1498;

	
	dp4a.s32.s32 %r1506, %r1476, %r1564, %r1502;

	
	dp4a.s32.s32 %r1510, %r1479, %r1568, %r1506;

	mad.lo.s32 %r8155, %r1510, %r8059, %r8154;
mul.ftz.f32 %f1067, %f1038, %f1062;
cvt.rn.f32.s32 %f1068, %r8155;
fma.rn.ftz.f32 %f1771, %f1067, %f1068, %f1771;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1514,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1517,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1520,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1523,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1526,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1529,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1532,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1535,r; 
}

	
	dp4a.s32.s32 %r1538, %r1514, %r1540, %r7829;

	
	dp4a.s32.s32 %r1542, %r1517, %r1544, %r1538;

	
	dp4a.s32.s32 %r1546, %r1520, %r1548, %r1542;

	
	dp4a.s32.s32 %r1550, %r1523, %r1552, %r1546;

	mul.lo.s32 %r8156, %r1550, %r8121;

	dp4a.s32.s32 %r1554, %r1526, %r1556, %r7829;

	
	dp4a.s32.s32 %r1558, %r1529, %r1560, %r1554;

	
	dp4a.s32.s32 %r1562, %r1532, %r1564, %r1558;

	
	dp4a.s32.s32 %r1566, %r1535, %r1568, %r1562;

	mad.lo.s32 %r8157, %r1566, %r8123, %r8156;
mul.ftz.f32 %f1069, %f1041, %f1062;
cvt.rn.f32.s32 %f1070, %r8157;
fma.rn.ftz.f32 %f1739, %f1069, %f1070, %f1739;
add.s32 %r8158, %r7852, 512;
shr.u32 %r8159, %r8158, 1;
add.s32 %r8160, %r662, %r8159;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1570,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1573,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1576,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1579,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1582,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1585,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1588,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1591,r; 
}

	ld.shared.u32 %r1764, [%r7927+2048];

	dp4a.s32.s32 %r1594, %r1570, %r1764, %r7829;

	ld.shared.u32 %r1768, [%r7927+2052];

	dp4a.s32.s32 %r1598, %r1573, %r1768, %r1594;

	ld.shared.u32 %r1772, [%r7927+2056];

	dp4a.s32.s32 %r1602, %r1576, %r1772, %r1598;

	ld.shared.u32 %r1776, [%r7927+2060];

	dp4a.s32.s32 %r1606, %r1579, %r1776, %r1602;

	mul.lo.s32 %r8161, %r1606, %r7929;
ld.shared.u32 %r1780, [%r7927+2064];

	dp4a.s32.s32 %r1610, %r1582, %r1780, %r7829;

	ld.shared.u32 %r1784, [%r7927+2068];

	dp4a.s32.s32 %r1614, %r1585, %r1784, %r1610;

	ld.shared.u32 %r1788, [%r7927+2072];

	dp4a.s32.s32 %r1618, %r1588, %r1788, %r1614;

	ld.shared.u32 %r1792, [%r7927+2076];

	dp4a.s32.s32 %r1622, %r1591, %r1792, %r1618;

	mad.lo.s32 %r8162, %r1622, %r7931, %r8161;
ld.shared.f32 %f1071, [%r8160];
mul.ftz.f32 %f1072, %f1032, %f1071;
cvt.rn.f32.s32 %f1073, %r8162;
fma.rn.ftz.f32 %f1834, %f1072, %f1073, %f1834;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1626,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1629,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1632,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1635,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1638,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1641,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1644,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1647,r; 
}

	
	dp4a.s32.s32 %r1650, %r1626, %r1764, %r7829;

	
	dp4a.s32.s32 %r1654, %r1629, %r1768, %r1650;

	
	dp4a.s32.s32 %r1658, %r1632, %r1772, %r1654;

	
	dp4a.s32.s32 %r1662, %r1635, %r1776, %r1658;

	mul.lo.s32 %r8163, %r1662, %r7993;

	dp4a.s32.s32 %r1666, %r1638, %r1780, %r7829;

	
	dp4a.s32.s32 %r1670, %r1641, %r1784, %r1666;

	
	dp4a.s32.s32 %r1674, %r1644, %r1788, %r1670;

	
	dp4a.s32.s32 %r1678, %r1647, %r1792, %r1674;

	mad.lo.s32 %r8164, %r1678, %r7995, %r8163;
mul.ftz.f32 %f1074, %f1035, %f1071;
cvt.rn.f32.s32 %f1075, %r8164;
fma.rn.ftz.f32 %f1802, %f1074, %f1075, %f1802;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1682,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1685,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1688,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1691,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1694,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1697,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1700,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1703,r; 
}

	
	dp4a.s32.s32 %r1706, %r1682, %r1764, %r7829;

	
	dp4a.s32.s32 %r1710, %r1685, %r1768, %r1706;

	
	dp4a.s32.s32 %r1714, %r1688, %r1772, %r1710;

	
	dp4a.s32.s32 %r1718, %r1691, %r1776, %r1714;

	mul.lo.s32 %r8165, %r1718, %r8057;

	dp4a.s32.s32 %r1722, %r1694, %r1780, %r7829;

	
	dp4a.s32.s32 %r1726, %r1697, %r1784, %r1722;

	
	dp4a.s32.s32 %r1730, %r1700, %r1788, %r1726;

	
	dp4a.s32.s32 %r1734, %r1703, %r1792, %r1730;

	mad.lo.s32 %r8166, %r1734, %r8059, %r8165;
mul.ftz.f32 %f1076, %f1038, %f1071;
cvt.rn.f32.s32 %f1077, %r8166;
fma.rn.ftz.f32 %f1770, %f1076, %f1077, %f1770;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1738,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1741,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1744,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1747,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1750,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1753,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1756,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1759,r; 
}

	
	dp4a.s32.s32 %r1762, %r1738, %r1764, %r7829;

	
	dp4a.s32.s32 %r1766, %r1741, %r1768, %r1762;

	
	dp4a.s32.s32 %r1770, %r1744, %r1772, %r1766;

	
	dp4a.s32.s32 %r1774, %r1747, %r1776, %r1770;

	mul.lo.s32 %r8167, %r1774, %r8121;

	dp4a.s32.s32 %r1778, %r1750, %r1780, %r7829;

	
	dp4a.s32.s32 %r1782, %r1753, %r1784, %r1778;

	
	dp4a.s32.s32 %r1786, %r1756, %r1788, %r1782;

	
	dp4a.s32.s32 %r1790, %r1759, %r1792, %r1786;

	mad.lo.s32 %r8168, %r1790, %r8123, %r8167;
mul.ftz.f32 %f1078, %f1041, %f1071;
cvt.rn.f32.s32 %f1079, %r8168;
fma.rn.ftz.f32 %f1738, %f1078, %f1079, %f1738;
add.s32 %r8169, %r7852, 640;
shr.u32 %r8170, %r8169, 1;
add.s32 %r8171, %r662, %r8170;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1794,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1797,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1800,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1803,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1806,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1809,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1812,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1815,r; 
}

	ld.shared.u32 %r1988, [%r7927+2560];

	dp4a.s32.s32 %r1818, %r1794, %r1988, %r7829;

	ld.shared.u32 %r1992, [%r7927+2564];

	dp4a.s32.s32 %r1822, %r1797, %r1992, %r1818;

	ld.shared.u32 %r1996, [%r7927+2568];

	dp4a.s32.s32 %r1826, %r1800, %r1996, %r1822;

	ld.shared.u32 %r2000, [%r7927+2572];

	dp4a.s32.s32 %r1830, %r1803, %r2000, %r1826;

	mul.lo.s32 %r8172, %r1830, %r7929;
ld.shared.u32 %r2004, [%r7927+2576];

	dp4a.s32.s32 %r1834, %r1806, %r2004, %r7829;

	ld.shared.u32 %r2008, [%r7927+2580];

	dp4a.s32.s32 %r1838, %r1809, %r2008, %r1834;

	ld.shared.u32 %r2012, [%r7927+2584];

	dp4a.s32.s32 %r1842, %r1812, %r2012, %r1838;

	ld.shared.u32 %r2016, [%r7927+2588];

	dp4a.s32.s32 %r1846, %r1815, %r2016, %r1842;

	mad.lo.s32 %r8173, %r1846, %r7931, %r8172;
ld.shared.f32 %f1080, [%r8171];
mul.ftz.f32 %f1081, %f1032, %f1080;
cvt.rn.f32.s32 %f1082, %r8173;
fma.rn.ftz.f32 %f1833, %f1081, %f1082, %f1833;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1850,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1853,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1856,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1859,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1862,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1865,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1868,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1871,r; 
}

	
	dp4a.s32.s32 %r1874, %r1850, %r1988, %r7829;

	
	dp4a.s32.s32 %r1878, %r1853, %r1992, %r1874;

	
	dp4a.s32.s32 %r1882, %r1856, %r1996, %r1878;

	
	dp4a.s32.s32 %r1886, %r1859, %r2000, %r1882;

	mul.lo.s32 %r8174, %r1886, %r7993;

	dp4a.s32.s32 %r1890, %r1862, %r2004, %r7829;

	
	dp4a.s32.s32 %r1894, %r1865, %r2008, %r1890;

	
	dp4a.s32.s32 %r1898, %r1868, %r2012, %r1894;

	
	dp4a.s32.s32 %r1902, %r1871, %r2016, %r1898;

	mad.lo.s32 %r8175, %r1902, %r7995, %r8174;
mul.ftz.f32 %f1083, %f1035, %f1080;
cvt.rn.f32.s32 %f1084, %r8175;
fma.rn.ftz.f32 %f1801, %f1083, %f1084, %f1801;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1906,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1909,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1912,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1915,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1918,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1921,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1924,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1927,r; 
}

	
	dp4a.s32.s32 %r1930, %r1906, %r1988, %r7829;

	
	dp4a.s32.s32 %r1934, %r1909, %r1992, %r1930;

	
	dp4a.s32.s32 %r1938, %r1912, %r1996, %r1934;

	
	dp4a.s32.s32 %r1942, %r1915, %r2000, %r1938;

	mul.lo.s32 %r8176, %r1942, %r8057;

	dp4a.s32.s32 %r1946, %r1918, %r2004, %r7829;

	
	dp4a.s32.s32 %r1950, %r1921, %r2008, %r1946;

	
	dp4a.s32.s32 %r1954, %r1924, %r2012, %r1950;

	
	dp4a.s32.s32 %r1958, %r1927, %r2016, %r1954;

	mad.lo.s32 %r8177, %r1958, %r8059, %r8176;
mul.ftz.f32 %f1085, %f1038, %f1080;
cvt.rn.f32.s32 %f1086, %r8177;
fma.rn.ftz.f32 %f1769, %f1085, %f1086, %f1769;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1962,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1965,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1968,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1971,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1974,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1977,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1980,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1983,r; 
}

	
	dp4a.s32.s32 %r1986, %r1962, %r1988, %r7829;

	
	dp4a.s32.s32 %r1990, %r1965, %r1992, %r1986;

	
	dp4a.s32.s32 %r1994, %r1968, %r1996, %r1990;

	
	dp4a.s32.s32 %r1998, %r1971, %r2000, %r1994;

	mul.lo.s32 %r8178, %r1998, %r8121;

	dp4a.s32.s32 %r2002, %r1974, %r2004, %r7829;

	
	dp4a.s32.s32 %r2006, %r1977, %r2008, %r2002;

	
	dp4a.s32.s32 %r2010, %r1980, %r2012, %r2006;

	
	dp4a.s32.s32 %r2014, %r1983, %r2016, %r2010;

	mad.lo.s32 %r8179, %r2014, %r8123, %r8178;
mul.ftz.f32 %f1087, %f1041, %f1080;
cvt.rn.f32.s32 %f1088, %r8179;
fma.rn.ftz.f32 %f1737, %f1087, %f1088, %f1737;
add.s32 %r8180, %r7852, 768;
shr.u32 %r8181, %r8180, 1;
add.s32 %r8182, %r662, %r8181;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2018,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2021,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2024,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2027,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2030,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2033,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2036,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2039,r; 
}

	ld.shared.u32 %r2212, [%r7927+3072];

	dp4a.s32.s32 %r2042, %r2018, %r2212, %r7829;

	ld.shared.u32 %r2216, [%r7927+3076];

	dp4a.s32.s32 %r2046, %r2021, %r2216, %r2042;

	ld.shared.u32 %r2220, [%r7927+3080];

	dp4a.s32.s32 %r2050, %r2024, %r2220, %r2046;

	ld.shared.u32 %r2224, [%r7927+3084];

	dp4a.s32.s32 %r2054, %r2027, %r2224, %r2050;

	mul.lo.s32 %r8183, %r2054, %r7929;
ld.shared.u32 %r2228, [%r7927+3088];

	dp4a.s32.s32 %r2058, %r2030, %r2228, %r7829;

	ld.shared.u32 %r2232, [%r7927+3092];

	dp4a.s32.s32 %r2062, %r2033, %r2232, %r2058;

	ld.shared.u32 %r2236, [%r7927+3096];

	dp4a.s32.s32 %r2066, %r2036, %r2236, %r2062;

	ld.shared.u32 %r2240, [%r7927+3100];

	dp4a.s32.s32 %r2070, %r2039, %r2240, %r2066;

	mad.lo.s32 %r8184, %r2070, %r7931, %r8183;
ld.shared.f32 %f1089, [%r8182];
mul.ftz.f32 %f1090, %f1032, %f1089;
cvt.rn.f32.s32 %f1091, %r8184;
fma.rn.ftz.f32 %f1832, %f1090, %f1091, %f1832;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2074,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2077,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2080,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2083,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2086,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2089,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2092,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2095,r; 
}

	
	dp4a.s32.s32 %r2098, %r2074, %r2212, %r7829;

	
	dp4a.s32.s32 %r2102, %r2077, %r2216, %r2098;

	
	dp4a.s32.s32 %r2106, %r2080, %r2220, %r2102;

	
	dp4a.s32.s32 %r2110, %r2083, %r2224, %r2106;

	mul.lo.s32 %r8185, %r2110, %r7993;

	dp4a.s32.s32 %r2114, %r2086, %r2228, %r7829;

	
	dp4a.s32.s32 %r2118, %r2089, %r2232, %r2114;

	
	dp4a.s32.s32 %r2122, %r2092, %r2236, %r2118;

	
	dp4a.s32.s32 %r2126, %r2095, %r2240, %r2122;

	mad.lo.s32 %r8186, %r2126, %r7995, %r8185;
mul.ftz.f32 %f1092, %f1035, %f1089;
cvt.rn.f32.s32 %f1093, %r8186;
fma.rn.ftz.f32 %f1800, %f1092, %f1093, %f1800;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2130,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2133,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2136,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2139,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2142,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2145,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2148,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2151,r; 
}

	
	dp4a.s32.s32 %r2154, %r2130, %r2212, %r7829;

	
	dp4a.s32.s32 %r2158, %r2133, %r2216, %r2154;

	
	dp4a.s32.s32 %r2162, %r2136, %r2220, %r2158;

	
	dp4a.s32.s32 %r2166, %r2139, %r2224, %r2162;

	mul.lo.s32 %r8187, %r2166, %r8057;

	dp4a.s32.s32 %r2170, %r2142, %r2228, %r7829;

	
	dp4a.s32.s32 %r2174, %r2145, %r2232, %r2170;

	
	dp4a.s32.s32 %r2178, %r2148, %r2236, %r2174;

	
	dp4a.s32.s32 %r2182, %r2151, %r2240, %r2178;

	mad.lo.s32 %r8188, %r2182, %r8059, %r8187;
mul.ftz.f32 %f1094, %f1038, %f1089;
cvt.rn.f32.s32 %f1095, %r8188;
fma.rn.ftz.f32 %f1768, %f1094, %f1095, %f1768;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2186,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2189,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2192,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2195,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2198,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2201,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2204,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2207,r; 
}

	
	dp4a.s32.s32 %r2210, %r2186, %r2212, %r7829;

	
	dp4a.s32.s32 %r2214, %r2189, %r2216, %r2210;

	
	dp4a.s32.s32 %r2218, %r2192, %r2220, %r2214;

	
	dp4a.s32.s32 %r2222, %r2195, %r2224, %r2218;

	mul.lo.s32 %r8189, %r2222, %r8121;

	dp4a.s32.s32 %r2226, %r2198, %r2228, %r7829;

	
	dp4a.s32.s32 %r2230, %r2201, %r2232, %r2226;

	
	dp4a.s32.s32 %r2234, %r2204, %r2236, %r2230;

	
	dp4a.s32.s32 %r2238, %r2207, %r2240, %r2234;

	mad.lo.s32 %r8190, %r2238, %r8123, %r8189;
mul.ftz.f32 %f1096, %f1041, %f1089;
cvt.rn.f32.s32 %f1097, %r8190;
fma.rn.ftz.f32 %f1736, %f1096, %f1097, %f1736;
add.s32 %r8191, %r7852, 896;
shr.u32 %r8192, %r8191, 1;
add.s32 %r8193, %r662, %r8192;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2242,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2245,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2248,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2251,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2254,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2257,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2260,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2263,r; 
}

	ld.shared.u32 %r2436, [%r7927+3584];

	dp4a.s32.s32 %r2266, %r2242, %r2436, %r7829;

	ld.shared.u32 %r2440, [%r7927+3588];

	dp4a.s32.s32 %r2270, %r2245, %r2440, %r2266;

	ld.shared.u32 %r2444, [%r7927+3592];

	dp4a.s32.s32 %r2274, %r2248, %r2444, %r2270;

	ld.shared.u32 %r2448, [%r7927+3596];

	dp4a.s32.s32 %r2278, %r2251, %r2448, %r2274;

	mul.lo.s32 %r8194, %r2278, %r7929;
ld.shared.u32 %r2452, [%r7927+3600];

	dp4a.s32.s32 %r2282, %r2254, %r2452, %r7829;

	ld.shared.u32 %r2456, [%r7927+3604];

	dp4a.s32.s32 %r2286, %r2257, %r2456, %r2282;

	ld.shared.u32 %r2460, [%r7927+3608];

	dp4a.s32.s32 %r2290, %r2260, %r2460, %r2286;

	ld.shared.u32 %r2464, [%r7927+3612];

	dp4a.s32.s32 %r2294, %r2263, %r2464, %r2290;

	mad.lo.s32 %r8195, %r2294, %r7931, %r8194;
ld.shared.f32 %f1098, [%r8193];
mul.ftz.f32 %f1099, %f1032, %f1098;
cvt.rn.f32.s32 %f1100, %r8195;
fma.rn.ftz.f32 %f1831, %f1099, %f1100, %f1831;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2298,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2301,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2304,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2307,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2310,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2313,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2316,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2319,r; 
}

	
	dp4a.s32.s32 %r2322, %r2298, %r2436, %r7829;

	
	dp4a.s32.s32 %r2326, %r2301, %r2440, %r2322;

	
	dp4a.s32.s32 %r2330, %r2304, %r2444, %r2326;

	
	dp4a.s32.s32 %r2334, %r2307, %r2448, %r2330;

	mul.lo.s32 %r8196, %r2334, %r7993;

	dp4a.s32.s32 %r2338, %r2310, %r2452, %r7829;

	
	dp4a.s32.s32 %r2342, %r2313, %r2456, %r2338;

	
	dp4a.s32.s32 %r2346, %r2316, %r2460, %r2342;

	
	dp4a.s32.s32 %r2350, %r2319, %r2464, %r2346;

	mad.lo.s32 %r8197, %r2350, %r7995, %r8196;
mul.ftz.f32 %f1101, %f1035, %f1098;
cvt.rn.f32.s32 %f1102, %r8197;
fma.rn.ftz.f32 %f1799, %f1101, %f1102, %f1799;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2354,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2357,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2360,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2363,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2366,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2369,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2372,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2375,r; 
}

	
	dp4a.s32.s32 %r2378, %r2354, %r2436, %r7829;

	
	dp4a.s32.s32 %r2382, %r2357, %r2440, %r2378;

	
	dp4a.s32.s32 %r2386, %r2360, %r2444, %r2382;

	
	dp4a.s32.s32 %r2390, %r2363, %r2448, %r2386;

	mul.lo.s32 %r8198, %r2390, %r8057;

	dp4a.s32.s32 %r2394, %r2366, %r2452, %r7829;

	
	dp4a.s32.s32 %r2398, %r2369, %r2456, %r2394;

	
	dp4a.s32.s32 %r2402, %r2372, %r2460, %r2398;

	
	dp4a.s32.s32 %r2406, %r2375, %r2464, %r2402;

	mad.lo.s32 %r8199, %r2406, %r8059, %r8198;
mul.ftz.f32 %f1103, %f1038, %f1098;
cvt.rn.f32.s32 %f1104, %r8199;
fma.rn.ftz.f32 %f1767, %f1103, %f1104, %f1767;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2410,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2413,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2416,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2419,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2422,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2425,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2428,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2431,r; 
}

	
	dp4a.s32.s32 %r2434, %r2410, %r2436, %r7829;

	
	dp4a.s32.s32 %r2438, %r2413, %r2440, %r2434;

	
	dp4a.s32.s32 %r2442, %r2416, %r2444, %r2438;

	
	dp4a.s32.s32 %r2446, %r2419, %r2448, %r2442;

	mul.lo.s32 %r8200, %r2446, %r8121;

	dp4a.s32.s32 %r2450, %r2422, %r2452, %r7829;

	
	dp4a.s32.s32 %r2454, %r2425, %r2456, %r2450;

	
	dp4a.s32.s32 %r2458, %r2428, %r2460, %r2454;

	
	dp4a.s32.s32 %r2462, %r2431, %r2464, %r2458;

	mad.lo.s32 %r8201, %r2462, %r8123, %r8200;
mul.ftz.f32 %f1105, %f1041, %f1098;
cvt.rn.f32.s32 %f1106, %r8201;
fma.rn.ftz.f32 %f1735, %f1105, %f1106, %f1735;
add.s32 %r8202, %r7852, 1024;
shr.u32 %r8203, %r8202, 1;
add.s32 %r8204, %r662, %r8203;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2466,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2469,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2472,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2475,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2478,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2481,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2484,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2487,r; 
}

	ld.shared.u32 %r2660, [%r7927+4096];

	dp4a.s32.s32 %r2490, %r2466, %r2660, %r7829;

	ld.shared.u32 %r2664, [%r7927+4100];

	dp4a.s32.s32 %r2494, %r2469, %r2664, %r2490;

	ld.shared.u32 %r2668, [%r7927+4104];

	dp4a.s32.s32 %r2498, %r2472, %r2668, %r2494;

	ld.shared.u32 %r2672, [%r7927+4108];

	dp4a.s32.s32 %r2502, %r2475, %r2672, %r2498;

	mul.lo.s32 %r8205, %r2502, %r7929;
ld.shared.u32 %r2676, [%r7927+4112];

	dp4a.s32.s32 %r2506, %r2478, %r2676, %r7829;

	ld.shared.u32 %r2680, [%r7927+4116];

	dp4a.s32.s32 %r2510, %r2481, %r2680, %r2506;

	ld.shared.u32 %r2684, [%r7927+4120];

	dp4a.s32.s32 %r2514, %r2484, %r2684, %r2510;

	ld.shared.u32 %r2688, [%r7927+4124];

	dp4a.s32.s32 %r2518, %r2487, %r2688, %r2514;

	mad.lo.s32 %r8206, %r2518, %r7931, %r8205;
ld.shared.f32 %f1107, [%r8204];
mul.ftz.f32 %f1108, %f1032, %f1107;
cvt.rn.f32.s32 %f1109, %r8206;
fma.rn.ftz.f32 %f1830, %f1108, %f1109, %f1830;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2522,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2525,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2528,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2531,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2534,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2537,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2540,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2543,r; 
}

	
	dp4a.s32.s32 %r2546, %r2522, %r2660, %r7829;

	
	dp4a.s32.s32 %r2550, %r2525, %r2664, %r2546;

	
	dp4a.s32.s32 %r2554, %r2528, %r2668, %r2550;

	
	dp4a.s32.s32 %r2558, %r2531, %r2672, %r2554;

	mul.lo.s32 %r8207, %r2558, %r7993;

	dp4a.s32.s32 %r2562, %r2534, %r2676, %r7829;

	
	dp4a.s32.s32 %r2566, %r2537, %r2680, %r2562;

	
	dp4a.s32.s32 %r2570, %r2540, %r2684, %r2566;

	
	dp4a.s32.s32 %r2574, %r2543, %r2688, %r2570;

	mad.lo.s32 %r8208, %r2574, %r7995, %r8207;
mul.ftz.f32 %f1110, %f1035, %f1107;
cvt.rn.f32.s32 %f1111, %r8208;
fma.rn.ftz.f32 %f1798, %f1110, %f1111, %f1798;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2578,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2581,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2584,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2587,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2590,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2593,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2596,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2599,r; 
}

	
	dp4a.s32.s32 %r2602, %r2578, %r2660, %r7829;

	
	dp4a.s32.s32 %r2606, %r2581, %r2664, %r2602;

	
	dp4a.s32.s32 %r2610, %r2584, %r2668, %r2606;

	
	dp4a.s32.s32 %r2614, %r2587, %r2672, %r2610;

	mul.lo.s32 %r8209, %r2614, %r8057;

	dp4a.s32.s32 %r2618, %r2590, %r2676, %r7829;

	
	dp4a.s32.s32 %r2622, %r2593, %r2680, %r2618;

	
	dp4a.s32.s32 %r2626, %r2596, %r2684, %r2622;

	
	dp4a.s32.s32 %r2630, %r2599, %r2688, %r2626;

	mad.lo.s32 %r8210, %r2630, %r8059, %r8209;
mul.ftz.f32 %f1112, %f1038, %f1107;
cvt.rn.f32.s32 %f1113, %r8210;
fma.rn.ftz.f32 %f1766, %f1112, %f1113, %f1766;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2634,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2637,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2640,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2643,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2646,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2649,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2652,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2655,r; 
}

	
	dp4a.s32.s32 %r2658, %r2634, %r2660, %r7829;

	
	dp4a.s32.s32 %r2662, %r2637, %r2664, %r2658;

	
	dp4a.s32.s32 %r2666, %r2640, %r2668, %r2662;

	
	dp4a.s32.s32 %r2670, %r2643, %r2672, %r2666;

	mul.lo.s32 %r8211, %r2670, %r8121;

	dp4a.s32.s32 %r2674, %r2646, %r2676, %r7829;

	
	dp4a.s32.s32 %r2678, %r2649, %r2680, %r2674;

	
	dp4a.s32.s32 %r2682, %r2652, %r2684, %r2678;

	
	dp4a.s32.s32 %r2686, %r2655, %r2688, %r2682;

	mad.lo.s32 %r8212, %r2686, %r8123, %r8211;
mul.ftz.f32 %f1114, %f1041, %f1107;
cvt.rn.f32.s32 %f1115, %r8212;
fma.rn.ftz.f32 %f1734, %f1114, %f1115, %f1734;
add.s32 %r8213, %r7852, 1152;
shr.u32 %r8214, %r8213, 1;
add.s32 %r8215, %r662, %r8214;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2690,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2693,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2696,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2699,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2702,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2705,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2708,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2711,r; 
}

	ld.shared.u32 %r2884, [%r7927+4608];

	dp4a.s32.s32 %r2714, %r2690, %r2884, %r7829;

	ld.shared.u32 %r2888, [%r7927+4612];

	dp4a.s32.s32 %r2718, %r2693, %r2888, %r2714;

	ld.shared.u32 %r2892, [%r7927+4616];

	dp4a.s32.s32 %r2722, %r2696, %r2892, %r2718;

	ld.shared.u32 %r2896, [%r7927+4620];

	dp4a.s32.s32 %r2726, %r2699, %r2896, %r2722;

	mul.lo.s32 %r8216, %r2726, %r7929;
ld.shared.u32 %r2900, [%r7927+4624];

	dp4a.s32.s32 %r2730, %r2702, %r2900, %r7829;

	ld.shared.u32 %r2904, [%r7927+4628];

	dp4a.s32.s32 %r2734, %r2705, %r2904, %r2730;

	ld.shared.u32 %r2908, [%r7927+4632];

	dp4a.s32.s32 %r2738, %r2708, %r2908, %r2734;

	ld.shared.u32 %r2912, [%r7927+4636];

	dp4a.s32.s32 %r2742, %r2711, %r2912, %r2738;

	mad.lo.s32 %r8217, %r2742, %r7931, %r8216;
ld.shared.f32 %f1116, [%r8215];
mul.ftz.f32 %f1117, %f1032, %f1116;
cvt.rn.f32.s32 %f1118, %r8217;
fma.rn.ftz.f32 %f1829, %f1117, %f1118, %f1829;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2746,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2749,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2752,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2755,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2758,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2761,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2764,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2767,r; 
}

	
	dp4a.s32.s32 %r2770, %r2746, %r2884, %r7829;

	
	dp4a.s32.s32 %r2774, %r2749, %r2888, %r2770;

	
	dp4a.s32.s32 %r2778, %r2752, %r2892, %r2774;

	
	dp4a.s32.s32 %r2782, %r2755, %r2896, %r2778;

	mul.lo.s32 %r8218, %r2782, %r7993;

	dp4a.s32.s32 %r2786, %r2758, %r2900, %r7829;

	
	dp4a.s32.s32 %r2790, %r2761, %r2904, %r2786;

	
	dp4a.s32.s32 %r2794, %r2764, %r2908, %r2790;

	
	dp4a.s32.s32 %r2798, %r2767, %r2912, %r2794;

	mad.lo.s32 %r8219, %r2798, %r7995, %r8218;
mul.ftz.f32 %f1119, %f1035, %f1116;
cvt.rn.f32.s32 %f1120, %r8219;
fma.rn.ftz.f32 %f1797, %f1119, %f1120, %f1797;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2802,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2805,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2808,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2811,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2814,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2817,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2820,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2823,r; 
}

	
	dp4a.s32.s32 %r2826, %r2802, %r2884, %r7829;

	
	dp4a.s32.s32 %r2830, %r2805, %r2888, %r2826;

	
	dp4a.s32.s32 %r2834, %r2808, %r2892, %r2830;

	
	dp4a.s32.s32 %r2838, %r2811, %r2896, %r2834;

	mul.lo.s32 %r8220, %r2838, %r8057;

	dp4a.s32.s32 %r2842, %r2814, %r2900, %r7829;

	
	dp4a.s32.s32 %r2846, %r2817, %r2904, %r2842;

	
	dp4a.s32.s32 %r2850, %r2820, %r2908, %r2846;

	
	dp4a.s32.s32 %r2854, %r2823, %r2912, %r2850;

	mad.lo.s32 %r8221, %r2854, %r8059, %r8220;
mul.ftz.f32 %f1121, %f1038, %f1116;
cvt.rn.f32.s32 %f1122, %r8221;
fma.rn.ftz.f32 %f1765, %f1121, %f1122, %f1765;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2858,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2861,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2864,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2867,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2870,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2873,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2876,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2879,r; 
}

	
	dp4a.s32.s32 %r2882, %r2858, %r2884, %r7829;

	
	dp4a.s32.s32 %r2886, %r2861, %r2888, %r2882;

	
	dp4a.s32.s32 %r2890, %r2864, %r2892, %r2886;

	
	dp4a.s32.s32 %r2894, %r2867, %r2896, %r2890;

	mul.lo.s32 %r8222, %r2894, %r8121;

	dp4a.s32.s32 %r2898, %r2870, %r2900, %r7829;

	
	dp4a.s32.s32 %r2902, %r2873, %r2904, %r2898;

	
	dp4a.s32.s32 %r2906, %r2876, %r2908, %r2902;

	
	dp4a.s32.s32 %r2910, %r2879, %r2912, %r2906;

	mad.lo.s32 %r8223, %r2910, %r8123, %r8222;
mul.ftz.f32 %f1123, %f1041, %f1116;
cvt.rn.f32.s32 %f1124, %r8223;
fma.rn.ftz.f32 %f1733, %f1123, %f1124, %f1733;
add.s32 %r8224, %r7852, 1280;
shr.u32 %r8225, %r8224, 1;
add.s32 %r8226, %r662, %r8225;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2914,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2917,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2920,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2923,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2926,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2929,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2932,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2935,r; 
}

	ld.shared.u32 %r3108, [%r7927+5120];

	dp4a.s32.s32 %r2938, %r2914, %r3108, %r7829;

	ld.shared.u32 %r3112, [%r7927+5124];

	dp4a.s32.s32 %r2942, %r2917, %r3112, %r2938;

	ld.shared.u32 %r3116, [%r7927+5128];

	dp4a.s32.s32 %r2946, %r2920, %r3116, %r2942;

	ld.shared.u32 %r3120, [%r7927+5132];

	dp4a.s32.s32 %r2950, %r2923, %r3120, %r2946;

	mul.lo.s32 %r8227, %r2950, %r7929;
ld.shared.u32 %r3124, [%r7927+5136];

	dp4a.s32.s32 %r2954, %r2926, %r3124, %r7829;

	ld.shared.u32 %r3128, [%r7927+5140];

	dp4a.s32.s32 %r2958, %r2929, %r3128, %r2954;

	ld.shared.u32 %r3132, [%r7927+5144];

	dp4a.s32.s32 %r2962, %r2932, %r3132, %r2958;

	ld.shared.u32 %r3136, [%r7927+5148];

	dp4a.s32.s32 %r2966, %r2935, %r3136, %r2962;

	mad.lo.s32 %r8228, %r2966, %r7931, %r8227;
ld.shared.f32 %f1125, [%r8226];
mul.ftz.f32 %f1126, %f1032, %f1125;
cvt.rn.f32.s32 %f1127, %r8228;
fma.rn.ftz.f32 %f1828, %f1126, %f1127, %f1828;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2970,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2973,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2976,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2979,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2982,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2985,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2988,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2991,r; 
}

	
	dp4a.s32.s32 %r2994, %r2970, %r3108, %r7829;

	
	dp4a.s32.s32 %r2998, %r2973, %r3112, %r2994;

	
	dp4a.s32.s32 %r3002, %r2976, %r3116, %r2998;

	
	dp4a.s32.s32 %r3006, %r2979, %r3120, %r3002;

	mul.lo.s32 %r8229, %r3006, %r7993;

	dp4a.s32.s32 %r3010, %r2982, %r3124, %r7829;

	
	dp4a.s32.s32 %r3014, %r2985, %r3128, %r3010;

	
	dp4a.s32.s32 %r3018, %r2988, %r3132, %r3014;

	
	dp4a.s32.s32 %r3022, %r2991, %r3136, %r3018;

	mad.lo.s32 %r8230, %r3022, %r7995, %r8229;
mul.ftz.f32 %f1128, %f1035, %f1125;
cvt.rn.f32.s32 %f1129, %r8230;
fma.rn.ftz.f32 %f1796, %f1128, %f1129, %f1796;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3026,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3029,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3032,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3035,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3038,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3041,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3044,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3047,r; 
}

	
	dp4a.s32.s32 %r3050, %r3026, %r3108, %r7829;

	
	dp4a.s32.s32 %r3054, %r3029, %r3112, %r3050;

	
	dp4a.s32.s32 %r3058, %r3032, %r3116, %r3054;

	
	dp4a.s32.s32 %r3062, %r3035, %r3120, %r3058;

	mul.lo.s32 %r8231, %r3062, %r8057;

	dp4a.s32.s32 %r3066, %r3038, %r3124, %r7829;

	
	dp4a.s32.s32 %r3070, %r3041, %r3128, %r3066;

	
	dp4a.s32.s32 %r3074, %r3044, %r3132, %r3070;

	
	dp4a.s32.s32 %r3078, %r3047, %r3136, %r3074;

	mad.lo.s32 %r8232, %r3078, %r8059, %r8231;
mul.ftz.f32 %f1130, %f1038, %f1125;
cvt.rn.f32.s32 %f1131, %r8232;
fma.rn.ftz.f32 %f1764, %f1130, %f1131, %f1764;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3082,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3085,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3088,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3091,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3094,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3097,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3100,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3103,r; 
}

	
	dp4a.s32.s32 %r3106, %r3082, %r3108, %r7829;

	
	dp4a.s32.s32 %r3110, %r3085, %r3112, %r3106;

	
	dp4a.s32.s32 %r3114, %r3088, %r3116, %r3110;

	
	dp4a.s32.s32 %r3118, %r3091, %r3120, %r3114;

	mul.lo.s32 %r8233, %r3118, %r8121;

	dp4a.s32.s32 %r3122, %r3094, %r3124, %r7829;

	
	dp4a.s32.s32 %r3126, %r3097, %r3128, %r3122;

	
	dp4a.s32.s32 %r3130, %r3100, %r3132, %r3126;

	
	dp4a.s32.s32 %r3134, %r3103, %r3136, %r3130;

	mad.lo.s32 %r8234, %r3134, %r8123, %r8233;
mul.ftz.f32 %f1132, %f1041, %f1125;
cvt.rn.f32.s32 %f1133, %r8234;
fma.rn.ftz.f32 %f1732, %f1132, %f1133, %f1732;
add.s32 %r8235, %r7852, 1408;
shr.u32 %r8236, %r8235, 1;
add.s32 %r8237, %r662, %r8236;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3138,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3141,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3144,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3147,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3150,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3153,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3156,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3159,r; 
}

	ld.shared.u32 %r3332, [%r7927+5632];

	dp4a.s32.s32 %r3162, %r3138, %r3332, %r7829;

	ld.shared.u32 %r3336, [%r7927+5636];

	dp4a.s32.s32 %r3166, %r3141, %r3336, %r3162;

	ld.shared.u32 %r3340, [%r7927+5640];

	dp4a.s32.s32 %r3170, %r3144, %r3340, %r3166;

	ld.shared.u32 %r3344, [%r7927+5644];

	dp4a.s32.s32 %r3174, %r3147, %r3344, %r3170;

	mul.lo.s32 %r8238, %r3174, %r7929;
ld.shared.u32 %r3348, [%r7927+5648];

	dp4a.s32.s32 %r3178, %r3150, %r3348, %r7829;

	ld.shared.u32 %r3352, [%r7927+5652];

	dp4a.s32.s32 %r3182, %r3153, %r3352, %r3178;

	ld.shared.u32 %r3356, [%r7927+5656];

	dp4a.s32.s32 %r3186, %r3156, %r3356, %r3182;

	ld.shared.u32 %r3360, [%r7927+5660];

	dp4a.s32.s32 %r3190, %r3159, %r3360, %r3186;

	mad.lo.s32 %r8239, %r3190, %r7931, %r8238;
ld.shared.f32 %f1134, [%r8237];
mul.ftz.f32 %f1135, %f1032, %f1134;
cvt.rn.f32.s32 %f1136, %r8239;
fma.rn.ftz.f32 %f1827, %f1135, %f1136, %f1827;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3194,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3197,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3200,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3203,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3206,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3209,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3212,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3215,r; 
}

	
	dp4a.s32.s32 %r3218, %r3194, %r3332, %r7829;

	
	dp4a.s32.s32 %r3222, %r3197, %r3336, %r3218;

	
	dp4a.s32.s32 %r3226, %r3200, %r3340, %r3222;

	
	dp4a.s32.s32 %r3230, %r3203, %r3344, %r3226;

	mul.lo.s32 %r8240, %r3230, %r7993;

	dp4a.s32.s32 %r3234, %r3206, %r3348, %r7829;

	
	dp4a.s32.s32 %r3238, %r3209, %r3352, %r3234;

	
	dp4a.s32.s32 %r3242, %r3212, %r3356, %r3238;

	
	dp4a.s32.s32 %r3246, %r3215, %r3360, %r3242;

	mad.lo.s32 %r8241, %r3246, %r7995, %r8240;
mul.ftz.f32 %f1137, %f1035, %f1134;
cvt.rn.f32.s32 %f1138, %r8241;
fma.rn.ftz.f32 %f1795, %f1137, %f1138, %f1795;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3250,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3253,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3256,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3259,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3262,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3265,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3268,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3271,r; 
}

	
	dp4a.s32.s32 %r3274, %r3250, %r3332, %r7829;

	
	dp4a.s32.s32 %r3278, %r3253, %r3336, %r3274;

	
	dp4a.s32.s32 %r3282, %r3256, %r3340, %r3278;

	
	dp4a.s32.s32 %r3286, %r3259, %r3344, %r3282;

	mul.lo.s32 %r8242, %r3286, %r8057;

	dp4a.s32.s32 %r3290, %r3262, %r3348, %r7829;

	
	dp4a.s32.s32 %r3294, %r3265, %r3352, %r3290;

	
	dp4a.s32.s32 %r3298, %r3268, %r3356, %r3294;

	
	dp4a.s32.s32 %r3302, %r3271, %r3360, %r3298;

	mad.lo.s32 %r8243, %r3302, %r8059, %r8242;
mul.ftz.f32 %f1139, %f1038, %f1134;
cvt.rn.f32.s32 %f1140, %r8243;
fma.rn.ftz.f32 %f1763, %f1139, %f1140, %f1763;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3306,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3309,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3312,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3315,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3318,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3321,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3324,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3327,r; 
}

	
	dp4a.s32.s32 %r3330, %r3306, %r3332, %r7829;

	
	dp4a.s32.s32 %r3334, %r3309, %r3336, %r3330;

	
	dp4a.s32.s32 %r3338, %r3312, %r3340, %r3334;

	
	dp4a.s32.s32 %r3342, %r3315, %r3344, %r3338;

	mul.lo.s32 %r8244, %r3342, %r8121;

	dp4a.s32.s32 %r3346, %r3318, %r3348, %r7829;

	
	dp4a.s32.s32 %r3350, %r3321, %r3352, %r3346;

	
	dp4a.s32.s32 %r3354, %r3324, %r3356, %r3350;

	
	dp4a.s32.s32 %r3358, %r3327, %r3360, %r3354;

	mad.lo.s32 %r8245, %r3358, %r8123, %r8244;
mul.ftz.f32 %f1141, %f1041, %f1134;
cvt.rn.f32.s32 %f1142, %r8245;
fma.rn.ftz.f32 %f1731, %f1141, %f1142, %f1731;
add.s32 %r8246, %r7852, 1536;
shr.u32 %r8247, %r8246, 1;
add.s32 %r8248, %r662, %r8247;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3362,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3365,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3368,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3371,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3374,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3377,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3380,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3383,r; 
}

	ld.shared.u32 %r3556, [%r7927+6144];

	dp4a.s32.s32 %r3386, %r3362, %r3556, %r7829;

	ld.shared.u32 %r3560, [%r7927+6148];

	dp4a.s32.s32 %r3390, %r3365, %r3560, %r3386;

	ld.shared.u32 %r3564, [%r7927+6152];

	dp4a.s32.s32 %r3394, %r3368, %r3564, %r3390;

	ld.shared.u32 %r3568, [%r7927+6156];

	dp4a.s32.s32 %r3398, %r3371, %r3568, %r3394;

	mul.lo.s32 %r8249, %r3398, %r7929;
ld.shared.u32 %r3572, [%r7927+6160];

	dp4a.s32.s32 %r3402, %r3374, %r3572, %r7829;

	ld.shared.u32 %r3576, [%r7927+6164];

	dp4a.s32.s32 %r3406, %r3377, %r3576, %r3402;

	ld.shared.u32 %r3580, [%r7927+6168];

	dp4a.s32.s32 %r3410, %r3380, %r3580, %r3406;

	ld.shared.u32 %r3584, [%r7927+6172];

	dp4a.s32.s32 %r3414, %r3383, %r3584, %r3410;

	mad.lo.s32 %r8250, %r3414, %r7931, %r8249;
ld.shared.f32 %f1143, [%r8248];
mul.ftz.f32 %f1144, %f1032, %f1143;
cvt.rn.f32.s32 %f1145, %r8250;
fma.rn.ftz.f32 %f1826, %f1144, %f1145, %f1826;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3418,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3421,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3424,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3427,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3430,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3433,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3436,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3439,r; 
}

	
	dp4a.s32.s32 %r3442, %r3418, %r3556, %r7829;

	
	dp4a.s32.s32 %r3446, %r3421, %r3560, %r3442;

	
	dp4a.s32.s32 %r3450, %r3424, %r3564, %r3446;

	
	dp4a.s32.s32 %r3454, %r3427, %r3568, %r3450;

	mul.lo.s32 %r8251, %r3454, %r7993;

	dp4a.s32.s32 %r3458, %r3430, %r3572, %r7829;

	
	dp4a.s32.s32 %r3462, %r3433, %r3576, %r3458;

	
	dp4a.s32.s32 %r3466, %r3436, %r3580, %r3462;

	
	dp4a.s32.s32 %r3470, %r3439, %r3584, %r3466;

	mad.lo.s32 %r8252, %r3470, %r7995, %r8251;
mul.ftz.f32 %f1146, %f1035, %f1143;
cvt.rn.f32.s32 %f1147, %r8252;
fma.rn.ftz.f32 %f1794, %f1146, %f1147, %f1794;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3474,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3477,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3480,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3483,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3486,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3489,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3492,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3495,r; 
}

	
	dp4a.s32.s32 %r3498, %r3474, %r3556, %r7829;

	
	dp4a.s32.s32 %r3502, %r3477, %r3560, %r3498;

	
	dp4a.s32.s32 %r3506, %r3480, %r3564, %r3502;

	
	dp4a.s32.s32 %r3510, %r3483, %r3568, %r3506;

	mul.lo.s32 %r8253, %r3510, %r8057;

	dp4a.s32.s32 %r3514, %r3486, %r3572, %r7829;

	
	dp4a.s32.s32 %r3518, %r3489, %r3576, %r3514;

	
	dp4a.s32.s32 %r3522, %r3492, %r3580, %r3518;

	
	dp4a.s32.s32 %r3526, %r3495, %r3584, %r3522;

	mad.lo.s32 %r8254, %r3526, %r8059, %r8253;
mul.ftz.f32 %f1148, %f1038, %f1143;
cvt.rn.f32.s32 %f1149, %r8254;
fma.rn.ftz.f32 %f1762, %f1148, %f1149, %f1762;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3530,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3533,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3536,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3539,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3542,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3545,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3548,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3551,r; 
}

	
	dp4a.s32.s32 %r3554, %r3530, %r3556, %r7829;

	
	dp4a.s32.s32 %r3558, %r3533, %r3560, %r3554;

	
	dp4a.s32.s32 %r3562, %r3536, %r3564, %r3558;

	
	dp4a.s32.s32 %r3566, %r3539, %r3568, %r3562;

	mul.lo.s32 %r8255, %r3566, %r8121;

	dp4a.s32.s32 %r3570, %r3542, %r3572, %r7829;

	
	dp4a.s32.s32 %r3574, %r3545, %r3576, %r3570;

	
	dp4a.s32.s32 %r3578, %r3548, %r3580, %r3574;

	
	dp4a.s32.s32 %r3582, %r3551, %r3584, %r3578;

	mad.lo.s32 %r8256, %r3582, %r8123, %r8255;
mul.ftz.f32 %f1150, %f1041, %f1143;
cvt.rn.f32.s32 %f1151, %r8256;
fma.rn.ftz.f32 %f1730, %f1150, %f1151, %f1730;
add.s32 %r8257, %r7852, 1664;
shr.u32 %r8258, %r8257, 1;
add.s32 %r8259, %r662, %r8258;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3586,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3589,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3592,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3595,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3598,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3601,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3604,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3607,r; 
}

	ld.shared.u32 %r3780, [%r7927+6656];

	dp4a.s32.s32 %r3610, %r3586, %r3780, %r7829;

	ld.shared.u32 %r3784, [%r7927+6660];

	dp4a.s32.s32 %r3614, %r3589, %r3784, %r3610;

	ld.shared.u32 %r3788, [%r7927+6664];

	dp4a.s32.s32 %r3618, %r3592, %r3788, %r3614;

	ld.shared.u32 %r3792, [%r7927+6668];

	dp4a.s32.s32 %r3622, %r3595, %r3792, %r3618;

	mul.lo.s32 %r8260, %r3622, %r7929;
ld.shared.u32 %r3796, [%r7927+6672];

	dp4a.s32.s32 %r3626, %r3598, %r3796, %r7829;

	ld.shared.u32 %r3800, [%r7927+6676];

	dp4a.s32.s32 %r3630, %r3601, %r3800, %r3626;

	ld.shared.u32 %r3804, [%r7927+6680];

	dp4a.s32.s32 %r3634, %r3604, %r3804, %r3630;

	ld.shared.u32 %r3808, [%r7927+6684];

	dp4a.s32.s32 %r3638, %r3607, %r3808, %r3634;

	mad.lo.s32 %r8261, %r3638, %r7931, %r8260;
ld.shared.f32 %f1152, [%r8259];
mul.ftz.f32 %f1153, %f1032, %f1152;
cvt.rn.f32.s32 %f1154, %r8261;
fma.rn.ftz.f32 %f1825, %f1153, %f1154, %f1825;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3642,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3645,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3648,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3651,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3654,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3657,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3660,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3663,r; 
}

	
	dp4a.s32.s32 %r3666, %r3642, %r3780, %r7829;

	
	dp4a.s32.s32 %r3670, %r3645, %r3784, %r3666;

	
	dp4a.s32.s32 %r3674, %r3648, %r3788, %r3670;

	
	dp4a.s32.s32 %r3678, %r3651, %r3792, %r3674;

	mul.lo.s32 %r8262, %r3678, %r7993;

	dp4a.s32.s32 %r3682, %r3654, %r3796, %r7829;

	
	dp4a.s32.s32 %r3686, %r3657, %r3800, %r3682;

	
	dp4a.s32.s32 %r3690, %r3660, %r3804, %r3686;

	
	dp4a.s32.s32 %r3694, %r3663, %r3808, %r3690;

	mad.lo.s32 %r8263, %r3694, %r7995, %r8262;
mul.ftz.f32 %f1155, %f1035, %f1152;
cvt.rn.f32.s32 %f1156, %r8263;
fma.rn.ftz.f32 %f1793, %f1155, %f1156, %f1793;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3698,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3701,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3704,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3707,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3710,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3713,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3716,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3719,r; 
}

	
	dp4a.s32.s32 %r3722, %r3698, %r3780, %r7829;

	
	dp4a.s32.s32 %r3726, %r3701, %r3784, %r3722;

	
	dp4a.s32.s32 %r3730, %r3704, %r3788, %r3726;

	
	dp4a.s32.s32 %r3734, %r3707, %r3792, %r3730;

	mul.lo.s32 %r8264, %r3734, %r8057;

	dp4a.s32.s32 %r3738, %r3710, %r3796, %r7829;

	
	dp4a.s32.s32 %r3742, %r3713, %r3800, %r3738;

	
	dp4a.s32.s32 %r3746, %r3716, %r3804, %r3742;

	
	dp4a.s32.s32 %r3750, %r3719, %r3808, %r3746;

	mad.lo.s32 %r8265, %r3750, %r8059, %r8264;
mul.ftz.f32 %f1157, %f1038, %f1152;
cvt.rn.f32.s32 %f1158, %r8265;
fma.rn.ftz.f32 %f1761, %f1157, %f1158, %f1761;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3754,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3757,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3760,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3763,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3766,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3769,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3772,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3775,r; 
}

	
	dp4a.s32.s32 %r3778, %r3754, %r3780, %r7829;

	
	dp4a.s32.s32 %r3782, %r3757, %r3784, %r3778;

	
	dp4a.s32.s32 %r3786, %r3760, %r3788, %r3782;

	
	dp4a.s32.s32 %r3790, %r3763, %r3792, %r3786;

	mul.lo.s32 %r8266, %r3790, %r8121;

	dp4a.s32.s32 %r3794, %r3766, %r3796, %r7829;

	
	dp4a.s32.s32 %r3798, %r3769, %r3800, %r3794;

	
	dp4a.s32.s32 %r3802, %r3772, %r3804, %r3798;

	
	dp4a.s32.s32 %r3806, %r3775, %r3808, %r3802;

	mad.lo.s32 %r8267, %r3806, %r8123, %r8266;
mul.ftz.f32 %f1159, %f1041, %f1152;
cvt.rn.f32.s32 %f1160, %r8267;
fma.rn.ftz.f32 %f1729, %f1159, %f1160, %f1729;
add.s32 %r8268, %r7852, 1792;
shr.u32 %r8269, %r8268, 1;
add.s32 %r8270, %r662, %r8269;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3810,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3813,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3816,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3819,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3822,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3825,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3828,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3831,r; 
}

	ld.shared.u32 %r4004, [%r7927+7168];

	dp4a.s32.s32 %r3834, %r3810, %r4004, %r7829;

	ld.shared.u32 %r4008, [%r7927+7172];

	dp4a.s32.s32 %r3838, %r3813, %r4008, %r3834;

	ld.shared.u32 %r4012, [%r7927+7176];

	dp4a.s32.s32 %r3842, %r3816, %r4012, %r3838;

	ld.shared.u32 %r4016, [%r7927+7180];

	dp4a.s32.s32 %r3846, %r3819, %r4016, %r3842;

	mul.lo.s32 %r8271, %r3846, %r7929;
ld.shared.u32 %r4020, [%r7927+7184];

	dp4a.s32.s32 %r3850, %r3822, %r4020, %r7829;

	ld.shared.u32 %r4024, [%r7927+7188];

	dp4a.s32.s32 %r3854, %r3825, %r4024, %r3850;

	ld.shared.u32 %r4028, [%r7927+7192];

	dp4a.s32.s32 %r3858, %r3828, %r4028, %r3854;

	ld.shared.u32 %r4032, [%r7927+7196];

	dp4a.s32.s32 %r3862, %r3831, %r4032, %r3858;

	mad.lo.s32 %r8272, %r3862, %r7931, %r8271;
ld.shared.f32 %f1161, [%r8270];
mul.ftz.f32 %f1162, %f1032, %f1161;
cvt.rn.f32.s32 %f1163, %r8272;
fma.rn.ftz.f32 %f1824, %f1162, %f1163, %f1824;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3866,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3869,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3872,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3875,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3878,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3881,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3884,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3887,r; 
}

	
	dp4a.s32.s32 %r3890, %r3866, %r4004, %r7829;

	
	dp4a.s32.s32 %r3894, %r3869, %r4008, %r3890;

	
	dp4a.s32.s32 %r3898, %r3872, %r4012, %r3894;

	
	dp4a.s32.s32 %r3902, %r3875, %r4016, %r3898;

	mul.lo.s32 %r8273, %r3902, %r7993;

	dp4a.s32.s32 %r3906, %r3878, %r4020, %r7829;

	
	dp4a.s32.s32 %r3910, %r3881, %r4024, %r3906;

	
	dp4a.s32.s32 %r3914, %r3884, %r4028, %r3910;

	
	dp4a.s32.s32 %r3918, %r3887, %r4032, %r3914;

	mad.lo.s32 %r8274, %r3918, %r7995, %r8273;
mul.ftz.f32 %f1164, %f1035, %f1161;
cvt.rn.f32.s32 %f1165, %r8274;
fma.rn.ftz.f32 %f1792, %f1164, %f1165, %f1792;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3922,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3925,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3928,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3931,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3934,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3937,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3940,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3943,r; 
}

	
	dp4a.s32.s32 %r3946, %r3922, %r4004, %r7829;

	
	dp4a.s32.s32 %r3950, %r3925, %r4008, %r3946;

	
	dp4a.s32.s32 %r3954, %r3928, %r4012, %r3950;

	
	dp4a.s32.s32 %r3958, %r3931, %r4016, %r3954;

	mul.lo.s32 %r8275, %r3958, %r8057;

	dp4a.s32.s32 %r3962, %r3934, %r4020, %r7829;

	
	dp4a.s32.s32 %r3966, %r3937, %r4024, %r3962;

	
	dp4a.s32.s32 %r3970, %r3940, %r4028, %r3966;

	
	dp4a.s32.s32 %r3974, %r3943, %r4032, %r3970;

	mad.lo.s32 %r8276, %r3974, %r8059, %r8275;
mul.ftz.f32 %f1166, %f1038, %f1161;
cvt.rn.f32.s32 %f1167, %r8276;
fma.rn.ftz.f32 %f1760, %f1166, %f1167, %f1760;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3978,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3981,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3984,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3987,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3990,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3993,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3996,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3999,r; 
}

	
	dp4a.s32.s32 %r4002, %r3978, %r4004, %r7829;

	
	dp4a.s32.s32 %r4006, %r3981, %r4008, %r4002;

	
	dp4a.s32.s32 %r4010, %r3984, %r4012, %r4006;

	
	dp4a.s32.s32 %r4014, %r3987, %r4016, %r4010;

	mul.lo.s32 %r8277, %r4014, %r8121;

	dp4a.s32.s32 %r4018, %r3990, %r4020, %r7829;

	
	dp4a.s32.s32 %r4022, %r3993, %r4024, %r4018;

	
	dp4a.s32.s32 %r4026, %r3996, %r4028, %r4022;

	
	dp4a.s32.s32 %r4030, %r3999, %r4032, %r4026;

	mad.lo.s32 %r8278, %r4030, %r8123, %r8277;
mul.ftz.f32 %f1168, %f1041, %f1161;
cvt.rn.f32.s32 %f1169, %r8278;
fma.rn.ftz.f32 %f1728, %f1168, %f1169, %f1728;
add.s32 %r8279, %r7852, 1920;
shr.u32 %r8280, %r8279, 1;
add.s32 %r8281, %r662, %r8280;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4034,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4037,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4040,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4043,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4046,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4049,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4052,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4055,r; 
}

	ld.shared.u32 %r4228, [%r7927+7680];

	dp4a.s32.s32 %r4058, %r4034, %r4228, %r7829;

	ld.shared.u32 %r4232, [%r7927+7684];

	dp4a.s32.s32 %r4062, %r4037, %r4232, %r4058;

	ld.shared.u32 %r4236, [%r7927+7688];

	dp4a.s32.s32 %r4066, %r4040, %r4236, %r4062;

	ld.shared.u32 %r4240, [%r7927+7692];

	dp4a.s32.s32 %r4070, %r4043, %r4240, %r4066;

	mul.lo.s32 %r8282, %r4070, %r7929;
ld.shared.u32 %r4244, [%r7927+7696];

	dp4a.s32.s32 %r4074, %r4046, %r4244, %r7829;

	ld.shared.u32 %r4248, [%r7927+7700];

	dp4a.s32.s32 %r4078, %r4049, %r4248, %r4074;

	ld.shared.u32 %r4252, [%r7927+7704];

	dp4a.s32.s32 %r4082, %r4052, %r4252, %r4078;

	ld.shared.u32 %r4256, [%r7927+7708];

	dp4a.s32.s32 %r4086, %r4055, %r4256, %r4082;

	mad.lo.s32 %r8283, %r4086, %r7931, %r8282;
ld.shared.f32 %f1170, [%r8281];
mul.ftz.f32 %f1171, %f1032, %f1170;
cvt.rn.f32.s32 %f1172, %r8283;
fma.rn.ftz.f32 %f1823, %f1171, %f1172, %f1823;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4090,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4093,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4096,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4099,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4102,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4105,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4108,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4111,r; 
}

	
	dp4a.s32.s32 %r4114, %r4090, %r4228, %r7829;

	
	dp4a.s32.s32 %r4118, %r4093, %r4232, %r4114;

	
	dp4a.s32.s32 %r4122, %r4096, %r4236, %r4118;

	
	dp4a.s32.s32 %r4126, %r4099, %r4240, %r4122;

	mul.lo.s32 %r8284, %r4126, %r7993;

	dp4a.s32.s32 %r4130, %r4102, %r4244, %r7829;

	
	dp4a.s32.s32 %r4134, %r4105, %r4248, %r4130;

	
	dp4a.s32.s32 %r4138, %r4108, %r4252, %r4134;

	
	dp4a.s32.s32 %r4142, %r4111, %r4256, %r4138;

	mad.lo.s32 %r8285, %r4142, %r7995, %r8284;
mul.ftz.f32 %f1173, %f1035, %f1170;
cvt.rn.f32.s32 %f1174, %r8285;
fma.rn.ftz.f32 %f1791, %f1173, %f1174, %f1791;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4146,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4149,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4152,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4155,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4158,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4161,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4164,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4167,r; 
}

	
	dp4a.s32.s32 %r4170, %r4146, %r4228, %r7829;

	
	dp4a.s32.s32 %r4174, %r4149, %r4232, %r4170;

	
	dp4a.s32.s32 %r4178, %r4152, %r4236, %r4174;

	
	dp4a.s32.s32 %r4182, %r4155, %r4240, %r4178;

	mul.lo.s32 %r8286, %r4182, %r8057;

	dp4a.s32.s32 %r4186, %r4158, %r4244, %r7829;

	
	dp4a.s32.s32 %r4190, %r4161, %r4248, %r4186;

	
	dp4a.s32.s32 %r4194, %r4164, %r4252, %r4190;

	
	dp4a.s32.s32 %r4198, %r4167, %r4256, %r4194;

	mad.lo.s32 %r8287, %r4198, %r8059, %r8286;
mul.ftz.f32 %f1175, %f1038, %f1170;
cvt.rn.f32.s32 %f1176, %r8287;
fma.rn.ftz.f32 %f1759, %f1175, %f1176, %f1759;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4202,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4205,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4208,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4211,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4214,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4217,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4220,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4223,r; 
}

	
	dp4a.s32.s32 %r4226, %r4202, %r4228, %r7829;

	
	dp4a.s32.s32 %r4230, %r4205, %r4232, %r4226;

	
	dp4a.s32.s32 %r4234, %r4208, %r4236, %r4230;

	
	dp4a.s32.s32 %r4238, %r4211, %r4240, %r4234;

	mul.lo.s32 %r8288, %r4238, %r8121;

	dp4a.s32.s32 %r4242, %r4214, %r4244, %r7829;

	
	dp4a.s32.s32 %r4246, %r4217, %r4248, %r4242;

	
	dp4a.s32.s32 %r4250, %r4220, %r4252, %r4246;

	
	dp4a.s32.s32 %r4254, %r4223, %r4256, %r4250;

	mad.lo.s32 %r8289, %r4254, %r8123, %r8288;
mul.ftz.f32 %f1177, %f1041, %f1170;
cvt.rn.f32.s32 %f1178, %r8289;
fma.rn.ftz.f32 %f1727, %f1177, %f1178, %f1727;
add.s32 %r8290, %r7852, 2048;
shr.u32 %r8291, %r8290, 1;
add.s32 %r8292, %r662, %r8291;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4258,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4261,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4264,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4267,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4270,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4273,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4276,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4279,r; 
}

	ld.shared.u32 %r4452, [%r7927+8192];

	dp4a.s32.s32 %r4282, %r4258, %r4452, %r7829;

	ld.shared.u32 %r4456, [%r7927+8196];

	dp4a.s32.s32 %r4286, %r4261, %r4456, %r4282;

	ld.shared.u32 %r4460, [%r7927+8200];

	dp4a.s32.s32 %r4290, %r4264, %r4460, %r4286;

	ld.shared.u32 %r4464, [%r7927+8204];

	dp4a.s32.s32 %r4294, %r4267, %r4464, %r4290;

	mul.lo.s32 %r8293, %r4294, %r7929;
ld.shared.u32 %r4468, [%r7927+8208];

	dp4a.s32.s32 %r4298, %r4270, %r4468, %r7829;

	ld.shared.u32 %r4472, [%r7927+8212];

	dp4a.s32.s32 %r4302, %r4273, %r4472, %r4298;

	ld.shared.u32 %r4476, [%r7927+8216];

	dp4a.s32.s32 %r4306, %r4276, %r4476, %r4302;

	ld.shared.u32 %r4480, [%r7927+8220];

	dp4a.s32.s32 %r4310, %r4279, %r4480, %r4306;

	mad.lo.s32 %r8294, %r4310, %r7931, %r8293;
ld.shared.f32 %f1179, [%r8292];
mul.ftz.f32 %f1180, %f1032, %f1179;
cvt.rn.f32.s32 %f1181, %r8294;
fma.rn.ftz.f32 %f1822, %f1180, %f1181, %f1822;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4314,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4317,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4320,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4323,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4326,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4329,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4332,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4335,r; 
}

	
	dp4a.s32.s32 %r4338, %r4314, %r4452, %r7829;

	
	dp4a.s32.s32 %r4342, %r4317, %r4456, %r4338;

	
	dp4a.s32.s32 %r4346, %r4320, %r4460, %r4342;

	
	dp4a.s32.s32 %r4350, %r4323, %r4464, %r4346;

	mul.lo.s32 %r8295, %r4350, %r7993;

	dp4a.s32.s32 %r4354, %r4326, %r4468, %r7829;

	
	dp4a.s32.s32 %r4358, %r4329, %r4472, %r4354;

	
	dp4a.s32.s32 %r4362, %r4332, %r4476, %r4358;

	
	dp4a.s32.s32 %r4366, %r4335, %r4480, %r4362;

	mad.lo.s32 %r8296, %r4366, %r7995, %r8295;
mul.ftz.f32 %f1182, %f1035, %f1179;
cvt.rn.f32.s32 %f1183, %r8296;
fma.rn.ftz.f32 %f1790, %f1182, %f1183, %f1790;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4370,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4373,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4376,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4379,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4382,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4385,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4388,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4391,r; 
}

	
	dp4a.s32.s32 %r4394, %r4370, %r4452, %r7829;

	
	dp4a.s32.s32 %r4398, %r4373, %r4456, %r4394;

	
	dp4a.s32.s32 %r4402, %r4376, %r4460, %r4398;

	
	dp4a.s32.s32 %r4406, %r4379, %r4464, %r4402;

	mul.lo.s32 %r8297, %r4406, %r8057;

	dp4a.s32.s32 %r4410, %r4382, %r4468, %r7829;

	
	dp4a.s32.s32 %r4414, %r4385, %r4472, %r4410;

	
	dp4a.s32.s32 %r4418, %r4388, %r4476, %r4414;

	
	dp4a.s32.s32 %r4422, %r4391, %r4480, %r4418;

	mad.lo.s32 %r8298, %r4422, %r8059, %r8297;
mul.ftz.f32 %f1184, %f1038, %f1179;
cvt.rn.f32.s32 %f1185, %r8298;
fma.rn.ftz.f32 %f1758, %f1184, %f1185, %f1758;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4426,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4429,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4432,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4435,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4438,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4441,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4444,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4447,r; 
}

	
	dp4a.s32.s32 %r4450, %r4426, %r4452, %r7829;

	
	dp4a.s32.s32 %r4454, %r4429, %r4456, %r4450;

	
	dp4a.s32.s32 %r4458, %r4432, %r4460, %r4454;

	
	dp4a.s32.s32 %r4462, %r4435, %r4464, %r4458;

	mul.lo.s32 %r8299, %r4462, %r8121;

	dp4a.s32.s32 %r4466, %r4438, %r4468, %r7829;

	
	dp4a.s32.s32 %r4470, %r4441, %r4472, %r4466;

	
	dp4a.s32.s32 %r4474, %r4444, %r4476, %r4470;

	
	dp4a.s32.s32 %r4478, %r4447, %r4480, %r4474;

	mad.lo.s32 %r8300, %r4478, %r8123, %r8299;
mul.ftz.f32 %f1186, %f1041, %f1179;
cvt.rn.f32.s32 %f1187, %r8300;
fma.rn.ftz.f32 %f1726, %f1186, %f1187, %f1726;
add.s32 %r8301, %r7852, 2176;
shr.u32 %r8302, %r8301, 1;
add.s32 %r8303, %r662, %r8302;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4482,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4485,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4488,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4491,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4494,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4497,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4500,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4503,r; 
}

	ld.shared.u32 %r4676, [%r7927+8704];

	dp4a.s32.s32 %r4506, %r4482, %r4676, %r7829;

	ld.shared.u32 %r4680, [%r7927+8708];

	dp4a.s32.s32 %r4510, %r4485, %r4680, %r4506;

	ld.shared.u32 %r4684, [%r7927+8712];

	dp4a.s32.s32 %r4514, %r4488, %r4684, %r4510;

	ld.shared.u32 %r4688, [%r7927+8716];

	dp4a.s32.s32 %r4518, %r4491, %r4688, %r4514;

	mul.lo.s32 %r8304, %r4518, %r7929;
ld.shared.u32 %r4692, [%r7927+8720];

	dp4a.s32.s32 %r4522, %r4494, %r4692, %r7829;

	ld.shared.u32 %r4696, [%r7927+8724];

	dp4a.s32.s32 %r4526, %r4497, %r4696, %r4522;

	ld.shared.u32 %r4700, [%r7927+8728];

	dp4a.s32.s32 %r4530, %r4500, %r4700, %r4526;

	ld.shared.u32 %r4704, [%r7927+8732];

	dp4a.s32.s32 %r4534, %r4503, %r4704, %r4530;

	mad.lo.s32 %r8305, %r4534, %r7931, %r8304;
ld.shared.f32 %f1188, [%r8303];
mul.ftz.f32 %f1189, %f1032, %f1188;
cvt.rn.f32.s32 %f1190, %r8305;
fma.rn.ftz.f32 %f1821, %f1189, %f1190, %f1821;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4538,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4541,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4544,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4547,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4550,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4553,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4556,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4559,r; 
}

	
	dp4a.s32.s32 %r4562, %r4538, %r4676, %r7829;

	
	dp4a.s32.s32 %r4566, %r4541, %r4680, %r4562;

	
	dp4a.s32.s32 %r4570, %r4544, %r4684, %r4566;

	
	dp4a.s32.s32 %r4574, %r4547, %r4688, %r4570;

	mul.lo.s32 %r8306, %r4574, %r7993;

	dp4a.s32.s32 %r4578, %r4550, %r4692, %r7829;

	
	dp4a.s32.s32 %r4582, %r4553, %r4696, %r4578;

	
	dp4a.s32.s32 %r4586, %r4556, %r4700, %r4582;

	
	dp4a.s32.s32 %r4590, %r4559, %r4704, %r4586;

	mad.lo.s32 %r8307, %r4590, %r7995, %r8306;
mul.ftz.f32 %f1191, %f1035, %f1188;
cvt.rn.f32.s32 %f1192, %r8307;
fma.rn.ftz.f32 %f1789, %f1191, %f1192, %f1789;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4594,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4597,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4600,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4603,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4606,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4609,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4612,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4615,r; 
}

	
	dp4a.s32.s32 %r4618, %r4594, %r4676, %r7829;

	
	dp4a.s32.s32 %r4622, %r4597, %r4680, %r4618;

	
	dp4a.s32.s32 %r4626, %r4600, %r4684, %r4622;

	
	dp4a.s32.s32 %r4630, %r4603, %r4688, %r4626;

	mul.lo.s32 %r8308, %r4630, %r8057;

	dp4a.s32.s32 %r4634, %r4606, %r4692, %r7829;

	
	dp4a.s32.s32 %r4638, %r4609, %r4696, %r4634;

	
	dp4a.s32.s32 %r4642, %r4612, %r4700, %r4638;

	
	dp4a.s32.s32 %r4646, %r4615, %r4704, %r4642;

	mad.lo.s32 %r8309, %r4646, %r8059, %r8308;
mul.ftz.f32 %f1193, %f1038, %f1188;
cvt.rn.f32.s32 %f1194, %r8309;
fma.rn.ftz.f32 %f1757, %f1193, %f1194, %f1757;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4650,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4653,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4656,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4659,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4662,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4665,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4668,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4671,r; 
}

	
	dp4a.s32.s32 %r4674, %r4650, %r4676, %r7829;

	
	dp4a.s32.s32 %r4678, %r4653, %r4680, %r4674;

	
	dp4a.s32.s32 %r4682, %r4656, %r4684, %r4678;

	
	dp4a.s32.s32 %r4686, %r4659, %r4688, %r4682;

	mul.lo.s32 %r8310, %r4686, %r8121;

	dp4a.s32.s32 %r4690, %r4662, %r4692, %r7829;

	
	dp4a.s32.s32 %r4694, %r4665, %r4696, %r4690;

	
	dp4a.s32.s32 %r4698, %r4668, %r4700, %r4694;

	
	dp4a.s32.s32 %r4702, %r4671, %r4704, %r4698;

	mad.lo.s32 %r8311, %r4702, %r8123, %r8310;
mul.ftz.f32 %f1195, %f1041, %f1188;
cvt.rn.f32.s32 %f1196, %r8311;
fma.rn.ftz.f32 %f1725, %f1195, %f1196, %f1725;
add.s32 %r8312, %r7852, 2304;
shr.u32 %r8313, %r8312, 1;
add.s32 %r8314, %r662, %r8313;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4706,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4709,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4712,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4715,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4718,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4721,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4724,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4727,r; 
}

	ld.shared.u32 %r4900, [%r7927+9216];

	dp4a.s32.s32 %r4730, %r4706, %r4900, %r7829;

	ld.shared.u32 %r4904, [%r7927+9220];

	dp4a.s32.s32 %r4734, %r4709, %r4904, %r4730;

	ld.shared.u32 %r4908, [%r7927+9224];

	dp4a.s32.s32 %r4738, %r4712, %r4908, %r4734;

	ld.shared.u32 %r4912, [%r7927+9228];

	dp4a.s32.s32 %r4742, %r4715, %r4912, %r4738;

	mul.lo.s32 %r8315, %r4742, %r7929;
ld.shared.u32 %r4916, [%r7927+9232];

	dp4a.s32.s32 %r4746, %r4718, %r4916, %r7829;

	ld.shared.u32 %r4920, [%r7927+9236];

	dp4a.s32.s32 %r4750, %r4721, %r4920, %r4746;

	ld.shared.u32 %r4924, [%r7927+9240];

	dp4a.s32.s32 %r4754, %r4724, %r4924, %r4750;

	ld.shared.u32 %r4928, [%r7927+9244];

	dp4a.s32.s32 %r4758, %r4727, %r4928, %r4754;

	mad.lo.s32 %r8316, %r4758, %r7931, %r8315;
ld.shared.f32 %f1197, [%r8314];
mul.ftz.f32 %f1198, %f1032, %f1197;
cvt.rn.f32.s32 %f1199, %r8316;
fma.rn.ftz.f32 %f1820, %f1198, %f1199, %f1820;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4762,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4765,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4768,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4771,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4774,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4777,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4780,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4783,r; 
}

	
	dp4a.s32.s32 %r4786, %r4762, %r4900, %r7829;

	
	dp4a.s32.s32 %r4790, %r4765, %r4904, %r4786;

	
	dp4a.s32.s32 %r4794, %r4768, %r4908, %r4790;

	
	dp4a.s32.s32 %r4798, %r4771, %r4912, %r4794;

	mul.lo.s32 %r8317, %r4798, %r7993;

	dp4a.s32.s32 %r4802, %r4774, %r4916, %r7829;

	
	dp4a.s32.s32 %r4806, %r4777, %r4920, %r4802;

	
	dp4a.s32.s32 %r4810, %r4780, %r4924, %r4806;

	
	dp4a.s32.s32 %r4814, %r4783, %r4928, %r4810;

	mad.lo.s32 %r8318, %r4814, %r7995, %r8317;
mul.ftz.f32 %f1200, %f1035, %f1197;
cvt.rn.f32.s32 %f1201, %r8318;
fma.rn.ftz.f32 %f1788, %f1200, %f1201, %f1788;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4818,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4821,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4824,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4827,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4830,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4833,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4836,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4839,r; 
}

	
	dp4a.s32.s32 %r4842, %r4818, %r4900, %r7829;

	
	dp4a.s32.s32 %r4846, %r4821, %r4904, %r4842;

	
	dp4a.s32.s32 %r4850, %r4824, %r4908, %r4846;

	
	dp4a.s32.s32 %r4854, %r4827, %r4912, %r4850;

	mul.lo.s32 %r8319, %r4854, %r8057;

	dp4a.s32.s32 %r4858, %r4830, %r4916, %r7829;

	
	dp4a.s32.s32 %r4862, %r4833, %r4920, %r4858;

	
	dp4a.s32.s32 %r4866, %r4836, %r4924, %r4862;

	
	dp4a.s32.s32 %r4870, %r4839, %r4928, %r4866;

	mad.lo.s32 %r8320, %r4870, %r8059, %r8319;
mul.ftz.f32 %f1202, %f1038, %f1197;
cvt.rn.f32.s32 %f1203, %r8320;
fma.rn.ftz.f32 %f1756, %f1202, %f1203, %f1756;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4874,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4877,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4880,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4883,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4886,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4889,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4892,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4895,r; 
}

	
	dp4a.s32.s32 %r4898, %r4874, %r4900, %r7829;

	
	dp4a.s32.s32 %r4902, %r4877, %r4904, %r4898;

	
	dp4a.s32.s32 %r4906, %r4880, %r4908, %r4902;

	
	dp4a.s32.s32 %r4910, %r4883, %r4912, %r4906;

	mul.lo.s32 %r8321, %r4910, %r8121;

	dp4a.s32.s32 %r4914, %r4886, %r4916, %r7829;

	
	dp4a.s32.s32 %r4918, %r4889, %r4920, %r4914;

	
	dp4a.s32.s32 %r4922, %r4892, %r4924, %r4918;

	
	dp4a.s32.s32 %r4926, %r4895, %r4928, %r4922;

	mad.lo.s32 %r8322, %r4926, %r8123, %r8321;
mul.ftz.f32 %f1204, %f1041, %f1197;
cvt.rn.f32.s32 %f1205, %r8322;
fma.rn.ftz.f32 %f1724, %f1204, %f1205, %f1724;
add.s32 %r8323, %r7852, 2432;
shr.u32 %r8324, %r8323, 1;
add.s32 %r8325, %r662, %r8324;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4930,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4933,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4936,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4939,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4942,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4945,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4948,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4951,r; 
}

	ld.shared.u32 %r5124, [%r7927+9728];

	dp4a.s32.s32 %r4954, %r4930, %r5124, %r7829;

	ld.shared.u32 %r5128, [%r7927+9732];

	dp4a.s32.s32 %r4958, %r4933, %r5128, %r4954;

	ld.shared.u32 %r5132, [%r7927+9736];

	dp4a.s32.s32 %r4962, %r4936, %r5132, %r4958;

	ld.shared.u32 %r5136, [%r7927+9740];

	dp4a.s32.s32 %r4966, %r4939, %r5136, %r4962;

	mul.lo.s32 %r8326, %r4966, %r7929;
ld.shared.u32 %r5140, [%r7927+9744];

	dp4a.s32.s32 %r4970, %r4942, %r5140, %r7829;

	ld.shared.u32 %r5144, [%r7927+9748];

	dp4a.s32.s32 %r4974, %r4945, %r5144, %r4970;

	ld.shared.u32 %r5148, [%r7927+9752];

	dp4a.s32.s32 %r4978, %r4948, %r5148, %r4974;

	ld.shared.u32 %r5152, [%r7927+9756];

	dp4a.s32.s32 %r4982, %r4951, %r5152, %r4978;

	mad.lo.s32 %r8327, %r4982, %r7931, %r8326;
ld.shared.f32 %f1206, [%r8325];
mul.ftz.f32 %f1207, %f1032, %f1206;
cvt.rn.f32.s32 %f1208, %r8327;
fma.rn.ftz.f32 %f1819, %f1207, %f1208, %f1819;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4986,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4989,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4992,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4995,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4998,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5001,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5004,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5007,r; 
}

	
	dp4a.s32.s32 %r5010, %r4986, %r5124, %r7829;

	
	dp4a.s32.s32 %r5014, %r4989, %r5128, %r5010;

	
	dp4a.s32.s32 %r5018, %r4992, %r5132, %r5014;

	
	dp4a.s32.s32 %r5022, %r4995, %r5136, %r5018;

	mul.lo.s32 %r8328, %r5022, %r7993;

	dp4a.s32.s32 %r5026, %r4998, %r5140, %r7829;

	
	dp4a.s32.s32 %r5030, %r5001, %r5144, %r5026;

	
	dp4a.s32.s32 %r5034, %r5004, %r5148, %r5030;

	
	dp4a.s32.s32 %r5038, %r5007, %r5152, %r5034;

	mad.lo.s32 %r8329, %r5038, %r7995, %r8328;
mul.ftz.f32 %f1209, %f1035, %f1206;
cvt.rn.f32.s32 %f1210, %r8329;
fma.rn.ftz.f32 %f1787, %f1209, %f1210, %f1787;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5042,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5045,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5048,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5051,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5054,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5057,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5060,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5063,r; 
}

	
	dp4a.s32.s32 %r5066, %r5042, %r5124, %r7829;

	
	dp4a.s32.s32 %r5070, %r5045, %r5128, %r5066;

	
	dp4a.s32.s32 %r5074, %r5048, %r5132, %r5070;

	
	dp4a.s32.s32 %r5078, %r5051, %r5136, %r5074;

	mul.lo.s32 %r8330, %r5078, %r8057;

	dp4a.s32.s32 %r5082, %r5054, %r5140, %r7829;

	
	dp4a.s32.s32 %r5086, %r5057, %r5144, %r5082;

	
	dp4a.s32.s32 %r5090, %r5060, %r5148, %r5086;

	
	dp4a.s32.s32 %r5094, %r5063, %r5152, %r5090;

	mad.lo.s32 %r8331, %r5094, %r8059, %r8330;
mul.ftz.f32 %f1211, %f1038, %f1206;
cvt.rn.f32.s32 %f1212, %r8331;
fma.rn.ftz.f32 %f1755, %f1211, %f1212, %f1755;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5098,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5101,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5104,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5107,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5110,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5113,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5116,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5119,r; 
}

	
	dp4a.s32.s32 %r5122, %r5098, %r5124, %r7829;

	
	dp4a.s32.s32 %r5126, %r5101, %r5128, %r5122;

	
	dp4a.s32.s32 %r5130, %r5104, %r5132, %r5126;

	
	dp4a.s32.s32 %r5134, %r5107, %r5136, %r5130;

	mul.lo.s32 %r8332, %r5134, %r8121;

	dp4a.s32.s32 %r5138, %r5110, %r5140, %r7829;

	
	dp4a.s32.s32 %r5142, %r5113, %r5144, %r5138;

	
	dp4a.s32.s32 %r5146, %r5116, %r5148, %r5142;

	
	dp4a.s32.s32 %r5150, %r5119, %r5152, %r5146;

	mad.lo.s32 %r8333, %r5150, %r8123, %r8332;
mul.ftz.f32 %f1213, %f1041, %f1206;
cvt.rn.f32.s32 %f1214, %r8333;
fma.rn.ftz.f32 %f1723, %f1213, %f1214, %f1723;
add.s32 %r8334, %r7852, 2560;
shr.u32 %r8335, %r8334, 1;
add.s32 %r8336, %r662, %r8335;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5154,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5157,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5160,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5163,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5166,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5169,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5172,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5175,r; 
}

	ld.shared.u32 %r5348, [%r7927+10240];

	dp4a.s32.s32 %r5178, %r5154, %r5348, %r7829;

	ld.shared.u32 %r5352, [%r7927+10244];

	dp4a.s32.s32 %r5182, %r5157, %r5352, %r5178;

	ld.shared.u32 %r5356, [%r7927+10248];

	dp4a.s32.s32 %r5186, %r5160, %r5356, %r5182;

	ld.shared.u32 %r5360, [%r7927+10252];

	dp4a.s32.s32 %r5190, %r5163, %r5360, %r5186;

	mul.lo.s32 %r8337, %r5190, %r7929;
ld.shared.u32 %r5364, [%r7927+10256];

	dp4a.s32.s32 %r5194, %r5166, %r5364, %r7829;

	ld.shared.u32 %r5368, [%r7927+10260];

	dp4a.s32.s32 %r5198, %r5169, %r5368, %r5194;

	ld.shared.u32 %r5372, [%r7927+10264];

	dp4a.s32.s32 %r5202, %r5172, %r5372, %r5198;

	ld.shared.u32 %r5376, [%r7927+10268];

	dp4a.s32.s32 %r5206, %r5175, %r5376, %r5202;

	mad.lo.s32 %r8338, %r5206, %r7931, %r8337;
ld.shared.f32 %f1215, [%r8336];
mul.ftz.f32 %f1216, %f1032, %f1215;
cvt.rn.f32.s32 %f1217, %r8338;
fma.rn.ftz.f32 %f1818, %f1216, %f1217, %f1818;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5210,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5213,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5216,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5219,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5222,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5225,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5228,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5231,r; 
}

	
	dp4a.s32.s32 %r5234, %r5210, %r5348, %r7829;

	
	dp4a.s32.s32 %r5238, %r5213, %r5352, %r5234;

	
	dp4a.s32.s32 %r5242, %r5216, %r5356, %r5238;

	
	dp4a.s32.s32 %r5246, %r5219, %r5360, %r5242;

	mul.lo.s32 %r8339, %r5246, %r7993;

	dp4a.s32.s32 %r5250, %r5222, %r5364, %r7829;

	
	dp4a.s32.s32 %r5254, %r5225, %r5368, %r5250;

	
	dp4a.s32.s32 %r5258, %r5228, %r5372, %r5254;

	
	dp4a.s32.s32 %r5262, %r5231, %r5376, %r5258;

	mad.lo.s32 %r8340, %r5262, %r7995, %r8339;
mul.ftz.f32 %f1218, %f1035, %f1215;
cvt.rn.f32.s32 %f1219, %r8340;
fma.rn.ftz.f32 %f1786, %f1218, %f1219, %f1786;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5266,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5269,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5272,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5275,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5278,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5281,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5284,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5287,r; 
}

	
	dp4a.s32.s32 %r5290, %r5266, %r5348, %r7829;

	
	dp4a.s32.s32 %r5294, %r5269, %r5352, %r5290;

	
	dp4a.s32.s32 %r5298, %r5272, %r5356, %r5294;

	
	dp4a.s32.s32 %r5302, %r5275, %r5360, %r5298;

	mul.lo.s32 %r8341, %r5302, %r8057;

	dp4a.s32.s32 %r5306, %r5278, %r5364, %r7829;

	
	dp4a.s32.s32 %r5310, %r5281, %r5368, %r5306;

	
	dp4a.s32.s32 %r5314, %r5284, %r5372, %r5310;

	
	dp4a.s32.s32 %r5318, %r5287, %r5376, %r5314;

	mad.lo.s32 %r8342, %r5318, %r8059, %r8341;
mul.ftz.f32 %f1220, %f1038, %f1215;
cvt.rn.f32.s32 %f1221, %r8342;
fma.rn.ftz.f32 %f1754, %f1220, %f1221, %f1754;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5322,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5325,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5328,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5331,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5334,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5337,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5340,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5343,r; 
}

	
	dp4a.s32.s32 %r5346, %r5322, %r5348, %r7829;

	
	dp4a.s32.s32 %r5350, %r5325, %r5352, %r5346;

	
	dp4a.s32.s32 %r5354, %r5328, %r5356, %r5350;

	
	dp4a.s32.s32 %r5358, %r5331, %r5360, %r5354;

	mul.lo.s32 %r8343, %r5358, %r8121;

	dp4a.s32.s32 %r5362, %r5334, %r5364, %r7829;

	
	dp4a.s32.s32 %r5366, %r5337, %r5368, %r5362;

	
	dp4a.s32.s32 %r5370, %r5340, %r5372, %r5366;

	
	dp4a.s32.s32 %r5374, %r5343, %r5376, %r5370;

	mad.lo.s32 %r8344, %r5374, %r8123, %r8343;
mul.ftz.f32 %f1222, %f1041, %f1215;
cvt.rn.f32.s32 %f1223, %r8344;
fma.rn.ftz.f32 %f1722, %f1222, %f1223, %f1722;
add.s32 %r8345, %r7852, 2688;
shr.u32 %r8346, %r8345, 1;
add.s32 %r8347, %r662, %r8346;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5378,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5381,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5384,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5387,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5390,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5393,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5396,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5399,r; 
}

	ld.shared.u32 %r5572, [%r7927+10752];

	dp4a.s32.s32 %r5402, %r5378, %r5572, %r7829;

	ld.shared.u32 %r5576, [%r7927+10756];

	dp4a.s32.s32 %r5406, %r5381, %r5576, %r5402;

	ld.shared.u32 %r5580, [%r7927+10760];

	dp4a.s32.s32 %r5410, %r5384, %r5580, %r5406;

	ld.shared.u32 %r5584, [%r7927+10764];

	dp4a.s32.s32 %r5414, %r5387, %r5584, %r5410;

	mul.lo.s32 %r8348, %r5414, %r7929;
ld.shared.u32 %r5588, [%r7927+10768];

	dp4a.s32.s32 %r5418, %r5390, %r5588, %r7829;

	ld.shared.u32 %r5592, [%r7927+10772];

	dp4a.s32.s32 %r5422, %r5393, %r5592, %r5418;

	ld.shared.u32 %r5596, [%r7927+10776];

	dp4a.s32.s32 %r5426, %r5396, %r5596, %r5422;

	ld.shared.u32 %r5600, [%r7927+10780];

	dp4a.s32.s32 %r5430, %r5399, %r5600, %r5426;

	mad.lo.s32 %r8349, %r5430, %r7931, %r8348;
ld.shared.f32 %f1224, [%r8347];
mul.ftz.f32 %f1225, %f1032, %f1224;
cvt.rn.f32.s32 %f1226, %r8349;
fma.rn.ftz.f32 %f1817, %f1225, %f1226, %f1817;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5434,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5437,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5440,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5443,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5446,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5449,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5452,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5455,r; 
}

	
	dp4a.s32.s32 %r5458, %r5434, %r5572, %r7829;

	
	dp4a.s32.s32 %r5462, %r5437, %r5576, %r5458;

	
	dp4a.s32.s32 %r5466, %r5440, %r5580, %r5462;

	
	dp4a.s32.s32 %r5470, %r5443, %r5584, %r5466;

	mul.lo.s32 %r8350, %r5470, %r7993;

	dp4a.s32.s32 %r5474, %r5446, %r5588, %r7829;

	
	dp4a.s32.s32 %r5478, %r5449, %r5592, %r5474;

	
	dp4a.s32.s32 %r5482, %r5452, %r5596, %r5478;

	
	dp4a.s32.s32 %r5486, %r5455, %r5600, %r5482;

	mad.lo.s32 %r8351, %r5486, %r7995, %r8350;
mul.ftz.f32 %f1227, %f1035, %f1224;
cvt.rn.f32.s32 %f1228, %r8351;
fma.rn.ftz.f32 %f1785, %f1227, %f1228, %f1785;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5490,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5493,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5496,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5499,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5502,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5505,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5508,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5511,r; 
}

	
	dp4a.s32.s32 %r5514, %r5490, %r5572, %r7829;

	
	dp4a.s32.s32 %r5518, %r5493, %r5576, %r5514;

	
	dp4a.s32.s32 %r5522, %r5496, %r5580, %r5518;

	
	dp4a.s32.s32 %r5526, %r5499, %r5584, %r5522;

	mul.lo.s32 %r8352, %r5526, %r8057;

	dp4a.s32.s32 %r5530, %r5502, %r5588, %r7829;

	
	dp4a.s32.s32 %r5534, %r5505, %r5592, %r5530;

	
	dp4a.s32.s32 %r5538, %r5508, %r5596, %r5534;

	
	dp4a.s32.s32 %r5542, %r5511, %r5600, %r5538;

	mad.lo.s32 %r8353, %r5542, %r8059, %r8352;
mul.ftz.f32 %f1229, %f1038, %f1224;
cvt.rn.f32.s32 %f1230, %r8353;
fma.rn.ftz.f32 %f1753, %f1229, %f1230, %f1753;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5546,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5549,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5552,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5555,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5558,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5561,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5564,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5567,r; 
}

	
	dp4a.s32.s32 %r5570, %r5546, %r5572, %r7829;

	
	dp4a.s32.s32 %r5574, %r5549, %r5576, %r5570;

	
	dp4a.s32.s32 %r5578, %r5552, %r5580, %r5574;

	
	dp4a.s32.s32 %r5582, %r5555, %r5584, %r5578;

	mul.lo.s32 %r8354, %r5582, %r8121;

	dp4a.s32.s32 %r5586, %r5558, %r5588, %r7829;

	
	dp4a.s32.s32 %r5590, %r5561, %r5592, %r5586;

	
	dp4a.s32.s32 %r5594, %r5564, %r5596, %r5590;

	
	dp4a.s32.s32 %r5598, %r5567, %r5600, %r5594;

	mad.lo.s32 %r8355, %r5598, %r8123, %r8354;
mul.ftz.f32 %f1231, %f1041, %f1224;
cvt.rn.f32.s32 %f1232, %r8355;
fma.rn.ftz.f32 %f1721, %f1231, %f1232, %f1721;
add.s32 %r8356, %r7852, 2816;
shr.u32 %r8357, %r8356, 1;
add.s32 %r8358, %r662, %r8357;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5602,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5605,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5608,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5611,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5614,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5617,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5620,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5623,r; 
}

	ld.shared.u32 %r5796, [%r7927+11264];

	dp4a.s32.s32 %r5626, %r5602, %r5796, %r7829;

	ld.shared.u32 %r5800, [%r7927+11268];

	dp4a.s32.s32 %r5630, %r5605, %r5800, %r5626;

	ld.shared.u32 %r5804, [%r7927+11272];

	dp4a.s32.s32 %r5634, %r5608, %r5804, %r5630;

	ld.shared.u32 %r5808, [%r7927+11276];

	dp4a.s32.s32 %r5638, %r5611, %r5808, %r5634;

	mul.lo.s32 %r8359, %r5638, %r7929;
ld.shared.u32 %r5812, [%r7927+11280];

	dp4a.s32.s32 %r5642, %r5614, %r5812, %r7829;

	ld.shared.u32 %r5816, [%r7927+11284];

	dp4a.s32.s32 %r5646, %r5617, %r5816, %r5642;

	ld.shared.u32 %r5820, [%r7927+11288];

	dp4a.s32.s32 %r5650, %r5620, %r5820, %r5646;

	ld.shared.u32 %r5824, [%r7927+11292];

	dp4a.s32.s32 %r5654, %r5623, %r5824, %r5650;

	mad.lo.s32 %r8360, %r5654, %r7931, %r8359;
ld.shared.f32 %f1233, [%r8358];
mul.ftz.f32 %f1234, %f1032, %f1233;
cvt.rn.f32.s32 %f1235, %r8360;
fma.rn.ftz.f32 %f1816, %f1234, %f1235, %f1816;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5658,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5661,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5664,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5667,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5670,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5673,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5676,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5679,r; 
}

	
	dp4a.s32.s32 %r5682, %r5658, %r5796, %r7829;

	
	dp4a.s32.s32 %r5686, %r5661, %r5800, %r5682;

	
	dp4a.s32.s32 %r5690, %r5664, %r5804, %r5686;

	
	dp4a.s32.s32 %r5694, %r5667, %r5808, %r5690;

	mul.lo.s32 %r8361, %r5694, %r7993;

	dp4a.s32.s32 %r5698, %r5670, %r5812, %r7829;

	
	dp4a.s32.s32 %r5702, %r5673, %r5816, %r5698;

	
	dp4a.s32.s32 %r5706, %r5676, %r5820, %r5702;

	
	dp4a.s32.s32 %r5710, %r5679, %r5824, %r5706;

	mad.lo.s32 %r8362, %r5710, %r7995, %r8361;
mul.ftz.f32 %f1236, %f1035, %f1233;
cvt.rn.f32.s32 %f1237, %r8362;
fma.rn.ftz.f32 %f1784, %f1236, %f1237, %f1784;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5714,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5717,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5720,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5723,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5726,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5729,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5732,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5735,r; 
}

	
	dp4a.s32.s32 %r5738, %r5714, %r5796, %r7829;

	
	dp4a.s32.s32 %r5742, %r5717, %r5800, %r5738;

	
	dp4a.s32.s32 %r5746, %r5720, %r5804, %r5742;

	
	dp4a.s32.s32 %r5750, %r5723, %r5808, %r5746;

	mul.lo.s32 %r8363, %r5750, %r8057;

	dp4a.s32.s32 %r5754, %r5726, %r5812, %r7829;

	
	dp4a.s32.s32 %r5758, %r5729, %r5816, %r5754;

	
	dp4a.s32.s32 %r5762, %r5732, %r5820, %r5758;

	
	dp4a.s32.s32 %r5766, %r5735, %r5824, %r5762;

	mad.lo.s32 %r8364, %r5766, %r8059, %r8363;
mul.ftz.f32 %f1238, %f1038, %f1233;
cvt.rn.f32.s32 %f1239, %r8364;
fma.rn.ftz.f32 %f1752, %f1238, %f1239, %f1752;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5770,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5773,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5776,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5779,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5782,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5785,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5788,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5791,r; 
}

	
	dp4a.s32.s32 %r5794, %r5770, %r5796, %r7829;

	
	dp4a.s32.s32 %r5798, %r5773, %r5800, %r5794;

	
	dp4a.s32.s32 %r5802, %r5776, %r5804, %r5798;

	
	dp4a.s32.s32 %r5806, %r5779, %r5808, %r5802;

	mul.lo.s32 %r8365, %r5806, %r8121;

	dp4a.s32.s32 %r5810, %r5782, %r5812, %r7829;

	
	dp4a.s32.s32 %r5814, %r5785, %r5816, %r5810;

	
	dp4a.s32.s32 %r5818, %r5788, %r5820, %r5814;

	
	dp4a.s32.s32 %r5822, %r5791, %r5824, %r5818;

	mad.lo.s32 %r8366, %r5822, %r8123, %r8365;
mul.ftz.f32 %f1240, %f1041, %f1233;
cvt.rn.f32.s32 %f1241, %r8366;
fma.rn.ftz.f32 %f1720, %f1240, %f1241, %f1720;
add.s32 %r8367, %r7852, 2944;
shr.u32 %r8368, %r8367, 1;
add.s32 %r8369, %r662, %r8368;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5827; 
mov.b32 b,%r5828; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5826,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5830; 
mov.b32 b,%r5831; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5829,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5833; 
mov.b32 b,%r5834; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5832,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5836; 
mov.b32 b,%r5837; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5835,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5839; 
mov.b32 b,%r5840; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5838,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5842; 
mov.b32 b,%r5843; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5841,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5845; 
mov.b32 b,%r5846; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5844,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5848; 
mov.b32 b,%r5849; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5847,r; 
}

	ld.shared.u32 %r6020, [%r7927+11776];

	dp4a.s32.s32 %r5850, %r5826, %r6020, %r7829;

	ld.shared.u32 %r6024, [%r7927+11780];

	dp4a.s32.s32 %r5854, %r5829, %r6024, %r5850;

	ld.shared.u32 %r6028, [%r7927+11784];

	dp4a.s32.s32 %r5858, %r5832, %r6028, %r5854;

	ld.shared.u32 %r6032, [%r7927+11788];

	dp4a.s32.s32 %r5862, %r5835, %r6032, %r5858;

	mul.lo.s32 %r8370, %r5862, %r7929;
ld.shared.u32 %r6036, [%r7927+11792];

	dp4a.s32.s32 %r5866, %r5838, %r6036, %r7829;

	ld.shared.u32 %r6040, [%r7927+11796];

	dp4a.s32.s32 %r5870, %r5841, %r6040, %r5866;

	ld.shared.u32 %r6044, [%r7927+11800];

	dp4a.s32.s32 %r5874, %r5844, %r6044, %r5870;

	ld.shared.u32 %r6048, [%r7927+11804];

	dp4a.s32.s32 %r5878, %r5847, %r6048, %r5874;

	mad.lo.s32 %r8371, %r5878, %r7931, %r8370;
ld.shared.f32 %f1242, [%r8369];
mul.ftz.f32 %f1243, %f1032, %f1242;
cvt.rn.f32.s32 %f1244, %r8371;
fma.rn.ftz.f32 %f1815, %f1243, %f1244, %f1815;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5883; 
mov.b32 b,%r5884; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5882,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5886; 
mov.b32 b,%r5887; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5885,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5889; 
mov.b32 b,%r5890; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5888,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5892; 
mov.b32 b,%r5893; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5891,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5895; 
mov.b32 b,%r5896; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5894,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5898; 
mov.b32 b,%r5899; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5897,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5901; 
mov.b32 b,%r5902; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5900,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5904; 
mov.b32 b,%r5905; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5903,r; 
}

	
	dp4a.s32.s32 %r5906, %r5882, %r6020, %r7829;

	
	dp4a.s32.s32 %r5910, %r5885, %r6024, %r5906;

	
	dp4a.s32.s32 %r5914, %r5888, %r6028, %r5910;

	
	dp4a.s32.s32 %r5918, %r5891, %r6032, %r5914;

	mul.lo.s32 %r8372, %r5918, %r7993;

	dp4a.s32.s32 %r5922, %r5894, %r6036, %r7829;

	
	dp4a.s32.s32 %r5926, %r5897, %r6040, %r5922;

	
	dp4a.s32.s32 %r5930, %r5900, %r6044, %r5926;

	
	dp4a.s32.s32 %r5934, %r5903, %r6048, %r5930;

	mad.lo.s32 %r8373, %r5934, %r7995, %r8372;
mul.ftz.f32 %f1245, %f1035, %f1242;
cvt.rn.f32.s32 %f1246, %r8373;
fma.rn.ftz.f32 %f1783, %f1245, %f1246, %f1783;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5939; 
mov.b32 b,%r5940; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5938,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r5942; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5941,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5944,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5947,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5950,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5953,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5956,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5959,r; 
}

	
	dp4a.s32.s32 %r5962, %r5938, %r6020, %r7829;

	
	dp4a.s32.s32 %r5966, %r5941, %r6024, %r5962;

	
	dp4a.s32.s32 %r5970, %r5944, %r6028, %r5966;

	
	dp4a.s32.s32 %r5974, %r5947, %r6032, %r5970;

	mul.lo.s32 %r8374, %r5974, %r8057;

	dp4a.s32.s32 %r5978, %r5950, %r6036, %r7829;

	
	dp4a.s32.s32 %r5982, %r5953, %r6040, %r5978;

	
	dp4a.s32.s32 %r5986, %r5956, %r6044, %r5982;

	
	dp4a.s32.s32 %r5990, %r5959, %r6048, %r5986;

	mad.lo.s32 %r8375, %r5990, %r8059, %r8374;
mul.ftz.f32 %f1247, %f1038, %f1242;
cvt.rn.f32.s32 %f1248, %r8375;
fma.rn.ftz.f32 %f1751, %f1247, %f1248, %f1751;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5994,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5997,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6000,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6003,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6006,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6009,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6012,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6015,r; 
}

	
	dp4a.s32.s32 %r6018, %r5994, %r6020, %r7829;

	
	dp4a.s32.s32 %r6022, %r5997, %r6024, %r6018;

	
	dp4a.s32.s32 %r6026, %r6000, %r6028, %r6022;

	
	dp4a.s32.s32 %r6030, %r6003, %r6032, %r6026;

	mul.lo.s32 %r8376, %r6030, %r8121;

	dp4a.s32.s32 %r6034, %r6006, %r6036, %r7829;

	
	dp4a.s32.s32 %r6038, %r6009, %r6040, %r6034;

	
	dp4a.s32.s32 %r6042, %r6012, %r6044, %r6038;

	
	dp4a.s32.s32 %r6046, %r6015, %r6048, %r6042;

	mad.lo.s32 %r8377, %r6046, %r8123, %r8376;
mul.ftz.f32 %f1249, %f1041, %f1242;
cvt.rn.f32.s32 %f1250, %r8377;
fma.rn.ftz.f32 %f1719, %f1249, %f1250, %f1719;
add.s32 %r8378, %r7852, 3072;
shr.u32 %r8379, %r8378, 1;
add.s32 %r8380, %r662, %r8379;
ld.shared.u32 %r8381, [%r7871];
shr.s32 %r8382, %r8381, %r7844;
and.b32 %r7619, %r8382, 50529027;
ld.shared.u32 %r8383, [%r7876];
shr.s32 %r8384, %r8383, %r7878;
shl.b32 %r8385, %r8384, 2;
and.b32 %r7620, %r8385, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7619; 
mov.b32 b,%r7620; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6050,r; 
}

	ld.shared.u32 %r8386, [%r7871+4];
shr.s32 %r8387, %r8386, %r7844;
and.b32 %r7622, %r8387, 50529027;
ld.shared.u32 %r8388, [%r7876+4];
shr.s32 %r8389, %r8388, %r7884;
shl.b32 %r8390, %r8389, 2;
and.b32 %r7623, %r8390, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7622; 
mov.b32 b,%r7623; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6053,r; 
}

	ld.shared.u32 %r8391, [%r7871+8];
shr.s32 %r8392, %r8391, %r7844;
and.b32 %r7625, %r8392, 50529027;
ld.shared.u32 %r8393, [%r7876+8];
shr.s32 %r8394, %r8393, %r7884;
shl.b32 %r8395, %r8394, 2;
and.b32 %r7626, %r8395, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7625; 
mov.b32 b,%r7626; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6056,r; 
}

	ld.shared.u32 %r8396, [%r7871+12];
shr.s32 %r8397, %r8396, %r7844;
and.b32 %r7628, %r8397, 50529027;
ld.shared.u32 %r8398, [%r7876+12];
shr.s32 %r8399, %r8398, %r7884;
shl.b32 %r8400, %r8399, 2;
and.b32 %r7629, %r8400, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7628; 
mov.b32 b,%r7629; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6059,r; 
}

	ld.shared.u32 %r8401, [%r7871+16];
shr.s32 %r8402, %r8401, %r7844;
and.b32 %r7631, %r8402, 50529027;
ld.shared.u32 %r8403, [%r7876+16];
shr.s32 %r8404, %r8403, %r7884;
shl.b32 %r8405, %r8404, 2;
and.b32 %r7632, %r8405, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7631; 
mov.b32 b,%r7632; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6062,r; 
}

	ld.shared.u32 %r8406, [%r7871+20];
shr.s32 %r8407, %r8406, %r7844;
and.b32 %r7634, %r8407, 50529027;
ld.shared.u32 %r8408, [%r7876+20];
shr.s32 %r8409, %r8408, %r7884;
shl.b32 %r8410, %r8409, 2;
and.b32 %r7635, %r8410, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7634; 
mov.b32 b,%r7635; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6065,r; 
}

	ld.shared.u32 %r8411, [%r7871+24];
shr.s32 %r8412, %r8411, %r7844;
and.b32 %r7637, %r8412, 50529027;
ld.shared.u32 %r8413, [%r7876+24];
shr.s32 %r8414, %r8413, %r7884;
shl.b32 %r8415, %r8414, 2;
and.b32 %r7638, %r8415, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7637; 
mov.b32 b,%r7638; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6068,r; 
}

	ld.shared.u32 %r8416, [%r7871+28];
shr.s32 %r8417, %r8416, %r7844;
and.b32 %r7640, %r8417, 50529027;
ld.shared.u32 %r8418, [%r7876+28];
shr.s32 %r8419, %r8418, %r7884;
shl.b32 %r8420, %r8419, 2;
and.b32 %r7641, %r8420, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7640; 
mov.b32 b,%r7641; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6071,r; 
}

	ld.shared.u32 %r6244, [%r7927+12288];

	dp4a.s32.s32 %r6074, %r6050, %r6244, %r7829;

	ld.shared.u32 %r6248, [%r7927+12292];

	dp4a.s32.s32 %r6078, %r6053, %r6248, %r6074;

	ld.shared.u32 %r6252, [%r7927+12296];

	dp4a.s32.s32 %r6082, %r6056, %r6252, %r6078;

	ld.shared.u32 %r6256, [%r7927+12300];

	dp4a.s32.s32 %r6086, %r6059, %r6256, %r6082;

	ld.shared.s8 %r8421, [%r7928];
mul.lo.s32 %r8422, %r6086, %r8421;
ld.shared.u32 %r6260, [%r7927+12304];

	dp4a.s32.s32 %r6090, %r6062, %r6260, %r7829;

	ld.shared.u32 %r6264, [%r7927+12308];

	dp4a.s32.s32 %r6094, %r6065, %r6264, %r6090;

	ld.shared.u32 %r6268, [%r7927+12312];

	dp4a.s32.s32 %r6098, %r6068, %r6268, %r6094;

	ld.shared.u32 %r6272, [%r7927+12316];

	dp4a.s32.s32 %r6102, %r6071, %r6272, %r6098;

	ld.shared.s8 %r8423, [%r7928+1];
mad.lo.s32 %r8424, %r6102, %r8423, %r8422;
ld.shared.f32 %f1251, [%r8380];
ld.shared.f32 %f1252, [%r7924];
mul.ftz.f32 %f1253, %f1252, %f1251;
cvt.rn.f32.s32 %f1254, %r8424;
fma.rn.ftz.f32 %f1814, %f1253, %f1254, %f1814;
ld.shared.u32 %r8425, [%r7871+4224];
shr.s32 %r8426, %r8425, %r7844;
and.b32 %r7675, %r8426, 50529027;
ld.shared.u32 %r8427, [%r7947];
shr.s32 %r8428, %r8427, %r7878;
shl.b32 %r8429, %r8428, 2;
and.b32 %r7676, %r8429, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7675; 
mov.b32 b,%r7676; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6106,r; 
}

	ld.shared.u32 %r8430, [%r7871+4228];
shr.s32 %r8431, %r8430, %r7844;
and.b32 %r7678, %r8431, 50529027;
ld.shared.u32 %r8432, [%r7947+4];
shr.s32 %r8433, %r8432, %r7884;
shl.b32 %r8434, %r8433, 2;
and.b32 %r7679, %r8434, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7678; 
mov.b32 b,%r7679; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6109,r; 
}

	ld.shared.u32 %r8435, [%r7871+4232];
shr.s32 %r8436, %r8435, %r7844;
and.b32 %r7681, %r8436, 50529027;
ld.shared.u32 %r8437, [%r7947+8];
shr.s32 %r8438, %r8437, %r7884;
shl.b32 %r8439, %r8438, 2;
and.b32 %r7682, %r8439, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7681; 
mov.b32 b,%r7682; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6112,r; 
}

	ld.shared.u32 %r8440, [%r7871+4236];
shr.s32 %r8441, %r8440, %r7844;
and.b32 %r7684, %r8441, 50529027;
ld.shared.u32 %r8442, [%r7947+12];
shr.s32 %r8443, %r8442, %r7884;
shl.b32 %r8444, %r8443, 2;
and.b32 %r7685, %r8444, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7684; 
mov.b32 b,%r7685; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6115,r; 
}

	ld.shared.u32 %r8445, [%r7871+4240];
shr.s32 %r8446, %r8445, %r7844;
and.b32 %r7687, %r8446, 50529027;
ld.shared.u32 %r8447, [%r7947+16];
shr.s32 %r8448, %r8447, %r7884;
shl.b32 %r8449, %r8448, 2;
and.b32 %r7688, %r8449, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7687; 
mov.b32 b,%r7688; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6118,r; 
}

	ld.shared.u32 %r8450, [%r7871+4244];
shr.s32 %r8451, %r8450, %r7844;
and.b32 %r7690, %r8451, 50529027;
ld.shared.u32 %r8452, [%r7947+20];
shr.s32 %r8453, %r8452, %r7884;
shl.b32 %r8454, %r8453, 2;
and.b32 %r7691, %r8454, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7690; 
mov.b32 b,%r7691; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6121,r; 
}

	ld.shared.u32 %r8455, [%r7871+4248];
shr.s32 %r8456, %r8455, %r7844;
and.b32 %r7693, %r8456, 50529027;
ld.shared.u32 %r8457, [%r7947+24];
shr.s32 %r8458, %r8457, %r7884;
shl.b32 %r8459, %r8458, 2;
and.b32 %r7694, %r8459, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7693; 
mov.b32 b,%r7694; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6124,r; 
}

	ld.shared.u32 %r8460, [%r7871+4252];
shr.s32 %r8461, %r8460, %r7844;
and.b32 %r7696, %r8461, 50529027;
ld.shared.u32 %r8462, [%r7947+28];
shr.s32 %r8463, %r8462, %r7884;
shl.b32 %r8464, %r8463, 2;
and.b32 %r7697, %r8464, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7696; 
mov.b32 b,%r7697; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6127,r; 
}

	
	dp4a.s32.s32 %r6130, %r6106, %r6244, %r7829;

	
	dp4a.s32.s32 %r6134, %r6109, %r6248, %r6130;

	
	dp4a.s32.s32 %r6138, %r6112, %r6252, %r6134;

	
	dp4a.s32.s32 %r6142, %r6115, %r6256, %r6138;

	ld.shared.s8 %r8465, [%r7992];
mul.lo.s32 %r8466, %r6142, %r8465;

	dp4a.s32.s32 %r6146, %r6118, %r6260, %r7829;

	
	dp4a.s32.s32 %r6150, %r6121, %r6264, %r6146;

	
	dp4a.s32.s32 %r6154, %r6124, %r6268, %r6150;

	
	dp4a.s32.s32 %r6158, %r6127, %r6272, %r6154;

	ld.shared.s8 %r8467, [%r7992+1];
mad.lo.s32 %r8468, %r6158, %r8467, %r8466;
ld.shared.f32 %f1255, [%r7991];
mul.ftz.f32 %f1256, %f1255, %f1251;
cvt.rn.f32.s32 %f1257, %r8468;
fma.rn.ftz.f32 %f1782, %f1256, %f1257, %f1782;
ld.shared.u32 %r8469, [%r7871+8448];
shr.s32 %r8470, %r8469, %r7844;
and.b32 %r7731, %r8470, 50529027;
ld.shared.u32 %r8471, [%r8011];
shr.s32 %r8472, %r8471, %r7878;
shl.b32 %r8473, %r8472, 2;
and.b32 %r7732, %r8473, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7731; 
mov.b32 b,%r7732; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6162,r; 
}

	ld.shared.u32 %r8474, [%r7871+8452];
shr.s32 %r8475, %r8474, %r7844;
and.b32 %r7734, %r8475, 50529027;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7734; 
mov.b32 b,%r6167; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6165,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6169; 
mov.b32 b,%r6170; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6168,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6172; 
mov.b32 b,%r6173; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6171,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6175; 
mov.b32 b,%r6176; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6174,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6178; 
mov.b32 b,%r6179; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6177,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6181; 
mov.b32 b,%r6182; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6180,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6184; 
mov.b32 b,%r6185; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6183,r; 
}

	
	dp4a.s32.s32 %r6186, %r6162, %r6244, %r7829;

	
	dp4a.s32.s32 %r6190, %r6165, %r6248, %r6186;

	
	dp4a.s32.s32 %r6194, %r6168, %r6252, %r6190;

	
	dp4a.s32.s32 %r6198, %r6171, %r6256, %r6194;

	mul.lo.s32 %r8476, %r6198, %r8057;

	dp4a.s32.s32 %r6202, %r6174, %r6260, %r7829;

	
	dp4a.s32.s32 %r6206, %r6177, %r6264, %r6202;

	
	dp4a.s32.s32 %r6210, %r6180, %r6268, %r6206;

	
	dp4a.s32.s32 %r6214, %r6183, %r6272, %r6210;

	mad.lo.s32 %r8477, %r6214, %r8059, %r8476;
mul.ftz.f32 %f1258, %f1038, %f1251;
cvt.rn.f32.s32 %f1259, %r8477;
fma.rn.ftz.f32 %f1750, %f1258, %f1259, %f1750;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6219; 
mov.b32 b,%r6220; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6218,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6222; 
mov.b32 b,%r6223; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6221,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6225; 
mov.b32 b,%r6226; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6224,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6228; 
mov.b32 b,%r6229; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6227,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6231; 
mov.b32 b,%r6232; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6230,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6234; 
mov.b32 b,%r6235; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6233,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6237; 
mov.b32 b,%r6238; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6236,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6240; 
mov.b32 b,%r6241; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6239,r; 
}

	
	dp4a.s32.s32 %r6242, %r6218, %r6244, %r7829;

	
	dp4a.s32.s32 %r6246, %r6221, %r6248, %r6242;

	
	dp4a.s32.s32 %r6250, %r6224, %r6252, %r6246;

	
	dp4a.s32.s32 %r6254, %r6227, %r6256, %r6250;

	mul.lo.s32 %r8478, %r6254, %r8121;

	dp4a.s32.s32 %r6258, %r6230, %r6260, %r7829;

	
	dp4a.s32.s32 %r6262, %r6233, %r6264, %r6258;

	
	dp4a.s32.s32 %r6266, %r6236, %r6268, %r6262;

	
	dp4a.s32.s32 %r6270, %r6239, %r6272, %r6266;

	mad.lo.s32 %r8479, %r6270, %r8123, %r8478;
mul.ftz.f32 %f1260, %f1041, %f1251;
cvt.rn.f32.s32 %f1261, %r8479;
fma.rn.ftz.f32 %f1718, %f1260, %f1261, %f1718;
add.s32 %r8480, %r7852, 3200;
shr.u32 %r8481, %r8480, 1;
add.s32 %r8482, %r662, %r8481;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7619; 
mov.b32 b,%r7620; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6274,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7622; 
mov.b32 b,%r7623; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6277,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7625; 
mov.b32 b,%r7626; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6280,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7628; 
mov.b32 b,%r7629; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6283,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7631; 
mov.b32 b,%r7632; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6286,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7634; 
mov.b32 b,%r7635; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6289,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7637; 
mov.b32 b,%r7638; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6292,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7640; 
mov.b32 b,%r7641; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6295,r; 
}

	ld.shared.u32 %r6468, [%r7927+12800];

	dp4a.s32.s32 %r6298, %r6274, %r6468, %r7829;

	ld.shared.u32 %r6472, [%r7927+12804];

	dp4a.s32.s32 %r6302, %r6277, %r6472, %r6298;

	ld.shared.u32 %r6476, [%r7927+12808];

	dp4a.s32.s32 %r6306, %r6280, %r6476, %r6302;

	ld.shared.u32 %r6480, [%r7927+12812];

	dp4a.s32.s32 %r6310, %r6283, %r6480, %r6306;

	mul.lo.s32 %r8483, %r6310, %r8421;
ld.shared.u32 %r6484, [%r7927+12816];

	dp4a.s32.s32 %r6314, %r6286, %r6484, %r7829;

	ld.shared.u32 %r6488, [%r7927+12820];

	dp4a.s32.s32 %r6318, %r6289, %r6488, %r6314;

	ld.shared.u32 %r6492, [%r7927+12824];

	dp4a.s32.s32 %r6322, %r6292, %r6492, %r6318;

	ld.shared.u32 %r6496, [%r7927+12828];

	dp4a.s32.s32 %r6326, %r6295, %r6496, %r6322;

	mad.lo.s32 %r8484, %r6326, %r8423, %r8483;
ld.shared.f32 %f1262, [%r8482];
mul.ftz.f32 %f1263, %f1252, %f1262;
cvt.rn.f32.s32 %f1264, %r8484;
fma.rn.ftz.f32 %f1813, %f1263, %f1264, %f1813;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7675; 
mov.b32 b,%r7676; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6330,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7678; 
mov.b32 b,%r7679; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6333,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7681; 
mov.b32 b,%r7682; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6336,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7684; 
mov.b32 b,%r7685; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6339,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7687; 
mov.b32 b,%r7688; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6342,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7690; 
mov.b32 b,%r7691; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6345,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7693; 
mov.b32 b,%r7694; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6348,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7696; 
mov.b32 b,%r7697; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6351,r; 
}

	
	dp4a.s32.s32 %r6354, %r6330, %r6468, %r7829;

	
	dp4a.s32.s32 %r6358, %r6333, %r6472, %r6354;

	
	dp4a.s32.s32 %r6362, %r6336, %r6476, %r6358;

	
	dp4a.s32.s32 %r6366, %r6339, %r6480, %r6362;

	mul.lo.s32 %r8485, %r6366, %r8465;

	dp4a.s32.s32 %r6370, %r6342, %r6484, %r7829;

	
	dp4a.s32.s32 %r6374, %r6345, %r6488, %r6370;

	
	dp4a.s32.s32 %r6378, %r6348, %r6492, %r6374;

	
	dp4a.s32.s32 %r6382, %r6351, %r6496, %r6378;

	mad.lo.s32 %r8486, %r6382, %r8467, %r8485;
mul.ftz.f32 %f1265, %f1255, %f1262;
cvt.rn.f32.s32 %f1266, %r8486;
fma.rn.ftz.f32 %f1781, %f1265, %f1266, %f1781;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7731; 
mov.b32 b,%r7732; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6386,r; 
}

	ld.shared.u32 %r8487, [%r8011+4];
shr.s32 %r8488, %r8487, %r7884;
shl.b32 %r8489, %r8488, 2;
and.b32 %r7735, %r8489, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7734; 
mov.b32 b,%r7735; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6389,r; 
}

	ld.shared.u32 %r8490, [%r7871+8456];
shr.s32 %r8491, %r8490, %r7844;
and.b32 %r7737, %r8491, 50529027;
ld.shared.u32 %r8492, [%r8011+8];
shr.s32 %r8493, %r8492, %r7884;
shl.b32 %r8494, %r8493, 2;
and.b32 %r7738, %r8494, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7737; 
mov.b32 b,%r7738; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6392,r; 
}

	ld.shared.u32 %r8495, [%r7871+8460];
shr.s32 %r8496, %r8495, %r7844;
and.b32 %r7740, %r8496, 50529027;
ld.shared.u32 %r8497, [%r8011+12];
shr.s32 %r8498, %r8497, %r7884;
shl.b32 %r8499, %r8498, 2;
and.b32 %r7741, %r8499, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7740; 
mov.b32 b,%r7741; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6395,r; 
}

	ld.shared.u32 %r8500, [%r7871+8464];
shr.s32 %r8501, %r8500, %r7844;
and.b32 %r7743, %r8501, 50529027;
ld.shared.u32 %r8502, [%r8011+16];
shr.s32 %r8503, %r8502, %r7884;
shl.b32 %r8504, %r8503, 2;
and.b32 %r7744, %r8504, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7743; 
mov.b32 b,%r7744; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6398,r; 
}

	ld.shared.u32 %r8505, [%r7871+8468];
shr.s32 %r8506, %r8505, %r7844;
and.b32 %r7746, %r8506, 50529027;
ld.shared.u32 %r8507, [%r8011+20];
shr.s32 %r8508, %r8507, %r7884;
shl.b32 %r8509, %r8508, 2;
and.b32 %r7747, %r8509, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7746; 
mov.b32 b,%r7747; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6401,r; 
}

	ld.shared.u32 %r8510, [%r7871+8472];
shr.s32 %r8511, %r8510, %r7844;
and.b32 %r7749, %r8511, 50529027;
ld.shared.u32 %r8512, [%r8011+24];
shr.s32 %r8513, %r8512, %r7884;
shl.b32 %r8514, %r8513, 2;
and.b32 %r7750, %r8514, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7749; 
mov.b32 b,%r7750; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6404,r; 
}

	ld.shared.u32 %r8515, [%r7871+8476];
shr.s32 %r8516, %r8515, %r7844;
and.b32 %r7752, %r8516, 50529027;
ld.shared.u32 %r8517, [%r8011+28];
shr.s32 %r8518, %r8517, %r7884;
shl.b32 %r8519, %r8518, 2;
and.b32 %r7753, %r8519, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7752; 
mov.b32 b,%r7753; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6407,r; 
}

	
	dp4a.s32.s32 %r6410, %r6386, %r6468, %r7829;

	
	dp4a.s32.s32 %r6414, %r6389, %r6472, %r6410;

	
	dp4a.s32.s32 %r6418, %r6392, %r6476, %r6414;

	
	dp4a.s32.s32 %r6422, %r6395, %r6480, %r6418;

	ld.shared.s8 %r8520, [%r8056];
mul.lo.s32 %r8521, %r6422, %r8520;

	dp4a.s32.s32 %r6426, %r6398, %r6484, %r7829;

	
	dp4a.s32.s32 %r6430, %r6401, %r6488, %r6426;

	
	dp4a.s32.s32 %r6434, %r6404, %r6492, %r6430;

	
	dp4a.s32.s32 %r6438, %r6407, %r6496, %r6434;

	ld.shared.s8 %r8522, [%r8056+1];
mad.lo.s32 %r8523, %r6438, %r8522, %r8521;
ld.shared.f32 %f1267, [%r8055];
mul.ftz.f32 %f1268, %f1267, %f1262;
cvt.rn.f32.s32 %f1269, %r8523;
fma.rn.ftz.f32 %f1749, %f1268, %f1269, %f1749;
ld.shared.u32 %r8524, [%r7871+12672];
shr.s32 %r8525, %r8524, %r7844;
and.b32 %r7787, %r8525, 50529027;
ld.shared.u32 %r8526, [%r8075];
shr.s32 %r8527, %r8526, %r7878;
shl.b32 %r8528, %r8527, 2;
and.b32 %r7788, %r8528, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7787; 
mov.b32 b,%r7788; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6442,r; 
}

	ld.shared.u32 %r8529, [%r7871+12676];
shr.s32 %r8530, %r8529, %r7844;
and.b32 %r7790, %r8530, 50529027;
ld.shared.u32 %r8531, [%r8075+4];
shr.s32 %r8532, %r8531, %r7884;
shl.b32 %r8533, %r8532, 2;
and.b32 %r7791, %r8533, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7790; 
mov.b32 b,%r7791; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6445,r; 
}

	ld.shared.u32 %r8534, [%r7871+12680];
shr.s32 %r8535, %r8534, %r7844;
and.b32 %r7793, %r8535, 50529027;
ld.shared.u32 %r8536, [%r8075+8];
shr.s32 %r8537, %r8536, %r7884;
shl.b32 %r8538, %r8537, 2;
and.b32 %r7794, %r8538, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7793; 
mov.b32 b,%r7794; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6448,r; 
}

	ld.shared.u32 %r8539, [%r7871+12684];
shr.s32 %r8540, %r8539, %r7844;
and.b32 %r7796, %r8540, 50529027;
ld.shared.u32 %r8541, [%r8075+12];
shr.s32 %r8542, %r8541, %r7884;
shl.b32 %r8543, %r8542, 2;
and.b32 %r7797, %r8543, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7796; 
mov.b32 b,%r7797; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6451,r; 
}

	ld.shared.u32 %r8544, [%r7871+12688];
shr.s32 %r8545, %r8544, %r7844;
and.b32 %r7799, %r8545, 50529027;
ld.shared.u32 %r8546, [%r8075+16];
shr.s32 %r8547, %r8546, %r7884;
shl.b32 %r8548, %r8547, 2;
and.b32 %r7800, %r8548, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7799; 
mov.b32 b,%r7800; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6454,r; 
}

	ld.shared.u32 %r8549, [%r7871+12692];
shr.s32 %r8550, %r8549, %r7844;
and.b32 %r7802, %r8550, 50529027;
ld.shared.u32 %r8551, [%r8075+20];
shr.s32 %r8552, %r8551, %r7884;
shl.b32 %r8553, %r8552, 2;
and.b32 %r7803, %r8553, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7802; 
mov.b32 b,%r7803; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6457,r; 
}

	ld.shared.u32 %r8554, [%r7871+12696];
shr.s32 %r8555, %r8554, %r7844;
and.b32 %r7805, %r8555, 50529027;
ld.shared.u32 %r8556, [%r8075+24];
shr.s32 %r8557, %r8556, %r7884;
shl.b32 %r8558, %r8557, 2;
and.b32 %r7806, %r8558, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7805; 
mov.b32 b,%r7806; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6460,r; 
}

	ld.shared.u32 %r8559, [%r7871+12700];
shr.s32 %r8560, %r8559, %r7844;
and.b32 %r7808, %r8560, 50529027;
ld.shared.u32 %r8561, [%r8075+28];
shr.s32 %r8562, %r8561, %r7884;
shl.b32 %r8563, %r8562, 2;
and.b32 %r7809, %r8563, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7808; 
mov.b32 b,%r7809; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6463,r; 
}

	
	dp4a.s32.s32 %r6466, %r6442, %r6468, %r7829;

	
	dp4a.s32.s32 %r6470, %r6445, %r6472, %r6466;

	
	dp4a.s32.s32 %r6474, %r6448, %r6476, %r6470;

	
	dp4a.s32.s32 %r6478, %r6451, %r6480, %r6474;

	ld.shared.s8 %r8564, [%r8120];
mul.lo.s32 %r8565, %r6478, %r8564;

	dp4a.s32.s32 %r6482, %r6454, %r6484, %r7829;

	
	dp4a.s32.s32 %r6486, %r6457, %r6488, %r6482;

	
	dp4a.s32.s32 %r6490, %r6460, %r6492, %r6486;

	
	dp4a.s32.s32 %r6494, %r6463, %r6496, %r6490;

	ld.shared.s8 %r8566, [%r8120+1];
mad.lo.s32 %r8567, %r6494, %r8566, %r8565;
ld.shared.f32 %f1270, [%r8119];
mul.ftz.f32 %f1271, %f1270, %f1262;
cvt.rn.f32.s32 %f1272, %r8567;
fma.rn.ftz.f32 %f1717, %f1271, %f1272, %f1717;
add.s32 %r8568, %r7852, 3328;
shr.u32 %r8569, %r8568, 1;
add.s32 %r8570, %r662, %r8569;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7619; 
mov.b32 b,%r7620; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6498,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7622; 
mov.b32 b,%r7623; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6501,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7625; 
mov.b32 b,%r7626; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6504,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7628; 
mov.b32 b,%r7629; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6507,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7631; 
mov.b32 b,%r7632; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6510,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7634; 
mov.b32 b,%r7635; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6513,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7637; 
mov.b32 b,%r7638; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6516,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7640; 
mov.b32 b,%r7641; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6519,r; 
}

	ld.shared.u32 %r6692, [%r7927+13312];

	dp4a.s32.s32 %r6522, %r6498, %r6692, %r7829;

	ld.shared.u32 %r6696, [%r7927+13316];

	dp4a.s32.s32 %r6526, %r6501, %r6696, %r6522;

	ld.shared.u32 %r6700, [%r7927+13320];

	dp4a.s32.s32 %r6530, %r6504, %r6700, %r6526;

	ld.shared.u32 %r6704, [%r7927+13324];

	dp4a.s32.s32 %r6534, %r6507, %r6704, %r6530;

	mul.lo.s32 %r8571, %r6534, %r8421;
ld.shared.u32 %r6708, [%r7927+13328];

	dp4a.s32.s32 %r6538, %r6510, %r6708, %r7829;

	ld.shared.u32 %r6712, [%r7927+13332];

	dp4a.s32.s32 %r6542, %r6513, %r6712, %r6538;

	ld.shared.u32 %r6716, [%r7927+13336];

	dp4a.s32.s32 %r6546, %r6516, %r6716, %r6542;

	ld.shared.u32 %r6720, [%r7927+13340];

	dp4a.s32.s32 %r6550, %r6519, %r6720, %r6546;

	mad.lo.s32 %r8572, %r6550, %r8423, %r8571;
ld.shared.f32 %f1273, [%r8570];
mul.ftz.f32 %f1274, %f1252, %f1273;
cvt.rn.f32.s32 %f1275, %r8572;
fma.rn.ftz.f32 %f1812, %f1274, %f1275, %f1812;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7675; 
mov.b32 b,%r7676; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6554,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7678; 
mov.b32 b,%r7679; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6557,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7681; 
mov.b32 b,%r7682; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6560,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7684; 
mov.b32 b,%r7685; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6563,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7687; 
mov.b32 b,%r7688; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6566,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7690; 
mov.b32 b,%r7691; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6569,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7693; 
mov.b32 b,%r7694; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6572,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7696; 
mov.b32 b,%r7697; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6575,r; 
}

	
	dp4a.s32.s32 %r6578, %r6554, %r6692, %r7829;

	
	dp4a.s32.s32 %r6582, %r6557, %r6696, %r6578;

	
	dp4a.s32.s32 %r6586, %r6560, %r6700, %r6582;

	
	dp4a.s32.s32 %r6590, %r6563, %r6704, %r6586;

	mul.lo.s32 %r8573, %r6590, %r8465;

	dp4a.s32.s32 %r6594, %r6566, %r6708, %r7829;

	
	dp4a.s32.s32 %r6598, %r6569, %r6712, %r6594;

	
	dp4a.s32.s32 %r6602, %r6572, %r6716, %r6598;

	
	dp4a.s32.s32 %r6606, %r6575, %r6720, %r6602;

	mad.lo.s32 %r8574, %r6606, %r8467, %r8573;
mul.ftz.f32 %f1276, %f1255, %f1273;
cvt.rn.f32.s32 %f1277, %r8574;
fma.rn.ftz.f32 %f1780, %f1276, %f1277, %f1780;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7731; 
mov.b32 b,%r7732; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6610,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7734; 
mov.b32 b,%r7735; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6613,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7737; 
mov.b32 b,%r7738; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6616,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7740; 
mov.b32 b,%r7741; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6619,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7743; 
mov.b32 b,%r7744; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6622,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7746; 
mov.b32 b,%r7747; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6625,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7749; 
mov.b32 b,%r7750; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6628,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7752; 
mov.b32 b,%r7753; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6631,r; 
}

	
	dp4a.s32.s32 %r6634, %r6610, %r6692, %r7829;

	
	dp4a.s32.s32 %r6638, %r6613, %r6696, %r6634;

	
	dp4a.s32.s32 %r6642, %r6616, %r6700, %r6638;

	
	dp4a.s32.s32 %r6646, %r6619, %r6704, %r6642;

	mul.lo.s32 %r8575, %r6646, %r8520;

	dp4a.s32.s32 %r6650, %r6622, %r6708, %r7829;

	
	dp4a.s32.s32 %r6654, %r6625, %r6712, %r6650;

	
	dp4a.s32.s32 %r6658, %r6628, %r6716, %r6654;

	
	dp4a.s32.s32 %r6662, %r6631, %r6720, %r6658;

	mad.lo.s32 %r8576, %r6662, %r8522, %r8575;
mul.ftz.f32 %f1278, %f1267, %f1273;
cvt.rn.f32.s32 %f1279, %r8576;
fma.rn.ftz.f32 %f1748, %f1278, %f1279, %f1748;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7787; 
mov.b32 b,%r7788; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6666,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7790; 
mov.b32 b,%r7791; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6669,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7793; 
mov.b32 b,%r7794; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6672,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7796; 
mov.b32 b,%r7797; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6675,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7799; 
mov.b32 b,%r7800; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6678,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7802; 
mov.b32 b,%r7803; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6681,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7805; 
mov.b32 b,%r7806; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6684,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7808; 
mov.b32 b,%r7809; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6687,r; 
}

	
	dp4a.s32.s32 %r6690, %r6666, %r6692, %r7829;

	
	dp4a.s32.s32 %r6694, %r6669, %r6696, %r6690;

	
	dp4a.s32.s32 %r6698, %r6672, %r6700, %r6694;

	
	dp4a.s32.s32 %r6702, %r6675, %r6704, %r6698;

	mul.lo.s32 %r8577, %r6702, %r8564;

	dp4a.s32.s32 %r6706, %r6678, %r6708, %r7829;

	
	dp4a.s32.s32 %r6710, %r6681, %r6712, %r6706;

	
	dp4a.s32.s32 %r6714, %r6684, %r6716, %r6710;

	
	dp4a.s32.s32 %r6718, %r6687, %r6720, %r6714;

	mad.lo.s32 %r8578, %r6718, %r8566, %r8577;
mul.ftz.f32 %f1280, %f1270, %f1273;
cvt.rn.f32.s32 %f1281, %r8578;
fma.rn.ftz.f32 %f1716, %f1280, %f1281, %f1716;
add.s32 %r8579, %r7852, 3456;
shr.u32 %r8580, %r8579, 1;
add.s32 %r8581, %r662, %r8580;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7619; 
mov.b32 b,%r7620; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6722,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7622; 
mov.b32 b,%r7623; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6725,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7625; 
mov.b32 b,%r7626; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6728,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7628; 
mov.b32 b,%r7629; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6731,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7631; 
mov.b32 b,%r7632; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6734,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7634; 
mov.b32 b,%r7635; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6737,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7637; 
mov.b32 b,%r7638; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6740,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7640; 
mov.b32 b,%r7641; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6743,r; 
}

	ld.shared.u32 %r6916, [%r7927+13824];

	dp4a.s32.s32 %r6746, %r6722, %r6916, %r7829;

	ld.shared.u32 %r6920, [%r7927+13828];

	dp4a.s32.s32 %r6750, %r6725, %r6920, %r6746;

	ld.shared.u32 %r6924, [%r7927+13832];

	dp4a.s32.s32 %r6754, %r6728, %r6924, %r6750;

	ld.shared.u32 %r6928, [%r7927+13836];

	dp4a.s32.s32 %r6758, %r6731, %r6928, %r6754;

	mul.lo.s32 %r8582, %r6758, %r8421;
ld.shared.u32 %r6932, [%r7927+13840];

	dp4a.s32.s32 %r6762, %r6734, %r6932, %r7829;

	ld.shared.u32 %r6936, [%r7927+13844];

	dp4a.s32.s32 %r6766, %r6737, %r6936, %r6762;

	ld.shared.u32 %r6940, [%r7927+13848];

	dp4a.s32.s32 %r6770, %r6740, %r6940, %r6766;

	ld.shared.u32 %r6944, [%r7927+13852];

	dp4a.s32.s32 %r6774, %r6743, %r6944, %r6770;

	mad.lo.s32 %r8583, %r6774, %r8423, %r8582;
ld.shared.f32 %f1282, [%r8581];
mul.ftz.f32 %f1283, %f1252, %f1282;
cvt.rn.f32.s32 %f1284, %r8583;
fma.rn.ftz.f32 %f1811, %f1283, %f1284, %f1811;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7675; 
mov.b32 b,%r7676; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6778,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7678; 
mov.b32 b,%r7679; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6781,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7681; 
mov.b32 b,%r7682; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6784,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7684; 
mov.b32 b,%r7685; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6787,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7687; 
mov.b32 b,%r7688; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6790,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7690; 
mov.b32 b,%r7691; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6793,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7693; 
mov.b32 b,%r7694; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6796,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7696; 
mov.b32 b,%r7697; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6799,r; 
}

	
	dp4a.s32.s32 %r6802, %r6778, %r6916, %r7829;

	
	dp4a.s32.s32 %r6806, %r6781, %r6920, %r6802;

	
	dp4a.s32.s32 %r6810, %r6784, %r6924, %r6806;

	
	dp4a.s32.s32 %r6814, %r6787, %r6928, %r6810;

	mul.lo.s32 %r8584, %r6814, %r8465;

	dp4a.s32.s32 %r6818, %r6790, %r6932, %r7829;

	
	dp4a.s32.s32 %r6822, %r6793, %r6936, %r6818;

	
	dp4a.s32.s32 %r6826, %r6796, %r6940, %r6822;

	
	dp4a.s32.s32 %r6830, %r6799, %r6944, %r6826;

	mad.lo.s32 %r8585, %r6830, %r8467, %r8584;
mul.ftz.f32 %f1285, %f1255, %f1282;
cvt.rn.f32.s32 %f1286, %r8585;
fma.rn.ftz.f32 %f1779, %f1285, %f1286, %f1779;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7731; 
mov.b32 b,%r7732; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6834,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7734; 
mov.b32 b,%r7735; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6837,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7737; 
mov.b32 b,%r7738; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6840,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7740; 
mov.b32 b,%r7741; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6843,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7743; 
mov.b32 b,%r7744; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6846,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7746; 
mov.b32 b,%r7747; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6849,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7749; 
mov.b32 b,%r7750; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6852,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7752; 
mov.b32 b,%r7753; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6855,r; 
}

	
	dp4a.s32.s32 %r6858, %r6834, %r6916, %r7829;

	
	dp4a.s32.s32 %r6862, %r6837, %r6920, %r6858;

	
	dp4a.s32.s32 %r6866, %r6840, %r6924, %r6862;

	
	dp4a.s32.s32 %r6870, %r6843, %r6928, %r6866;

	mul.lo.s32 %r8586, %r6870, %r8520;

	dp4a.s32.s32 %r6874, %r6846, %r6932, %r7829;

	
	dp4a.s32.s32 %r6878, %r6849, %r6936, %r6874;

	
	dp4a.s32.s32 %r6882, %r6852, %r6940, %r6878;

	
	dp4a.s32.s32 %r6886, %r6855, %r6944, %r6882;

	mad.lo.s32 %r8587, %r6886, %r8522, %r8586;
mul.ftz.f32 %f1287, %f1267, %f1282;
cvt.rn.f32.s32 %f1288, %r8587;
fma.rn.ftz.f32 %f1747, %f1287, %f1288, %f1747;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7787; 
mov.b32 b,%r7788; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6890,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7790; 
mov.b32 b,%r7791; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6893,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7793; 
mov.b32 b,%r7794; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6896,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7796; 
mov.b32 b,%r7797; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6899,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7799; 
mov.b32 b,%r7800; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6902,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7802; 
mov.b32 b,%r7803; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6905,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7805; 
mov.b32 b,%r7806; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6908,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7808; 
mov.b32 b,%r7809; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6911,r; 
}

	
	dp4a.s32.s32 %r6914, %r6890, %r6916, %r7829;

	
	dp4a.s32.s32 %r6918, %r6893, %r6920, %r6914;

	
	dp4a.s32.s32 %r6922, %r6896, %r6924, %r6918;

	
	dp4a.s32.s32 %r6926, %r6899, %r6928, %r6922;

	mul.lo.s32 %r8588, %r6926, %r8564;

	dp4a.s32.s32 %r6930, %r6902, %r6932, %r7829;

	
	dp4a.s32.s32 %r6934, %r6905, %r6936, %r6930;

	
	dp4a.s32.s32 %r6938, %r6908, %r6940, %r6934;

	
	dp4a.s32.s32 %r6942, %r6911, %r6944, %r6938;

	mad.lo.s32 %r8589, %r6942, %r8566, %r8588;
mul.ftz.f32 %f1289, %f1270, %f1282;
cvt.rn.f32.s32 %f1290, %r8589;
fma.rn.ftz.f32 %f1715, %f1289, %f1290, %f1715;
add.s32 %r8590, %r7852, 3584;
shr.u32 %r8591, %r8590, 1;
add.s32 %r8592, %r662, %r8591;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7619; 
mov.b32 b,%r7620; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6946,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7622; 
mov.b32 b,%r7623; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6949,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7625; 
mov.b32 b,%r7626; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6952,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7628; 
mov.b32 b,%r7629; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6955,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7631; 
mov.b32 b,%r7632; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6958,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7634; 
mov.b32 b,%r7635; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6961,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7637; 
mov.b32 b,%r7638; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6964,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7640; 
mov.b32 b,%r7641; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6967,r; 
}

	ld.shared.u32 %r7140, [%r7927+14336];

	dp4a.s32.s32 %r6970, %r6946, %r7140, %r7829;

	ld.shared.u32 %r7144, [%r7927+14340];

	dp4a.s32.s32 %r6974, %r6949, %r7144, %r6970;

	ld.shared.u32 %r7148, [%r7927+14344];

	dp4a.s32.s32 %r6978, %r6952, %r7148, %r6974;

	ld.shared.u32 %r7152, [%r7927+14348];

	dp4a.s32.s32 %r6982, %r6955, %r7152, %r6978;

	mul.lo.s32 %r8593, %r6982, %r8421;
ld.shared.u32 %r7156, [%r7927+14352];

	dp4a.s32.s32 %r6986, %r6958, %r7156, %r7829;

	ld.shared.u32 %r7160, [%r7927+14356];

	dp4a.s32.s32 %r6990, %r6961, %r7160, %r6986;

	ld.shared.u32 %r7164, [%r7927+14360];

	dp4a.s32.s32 %r6994, %r6964, %r7164, %r6990;

	ld.shared.u32 %r7168, [%r7927+14364];

	dp4a.s32.s32 %r6998, %r6967, %r7168, %r6994;

	mad.lo.s32 %r8594, %r6998, %r8423, %r8593;
ld.shared.f32 %f1291, [%r8592];
mul.ftz.f32 %f1292, %f1252, %f1291;
cvt.rn.f32.s32 %f1293, %r8594;
fma.rn.ftz.f32 %f1810, %f1292, %f1293, %f1810;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7675; 
mov.b32 b,%r7676; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7002,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7678; 
mov.b32 b,%r7679; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7005,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7681; 
mov.b32 b,%r7682; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7008,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7684; 
mov.b32 b,%r7685; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7011,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7687; 
mov.b32 b,%r7688; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7014,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7690; 
mov.b32 b,%r7691; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7017,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7693; 
mov.b32 b,%r7694; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7020,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7696; 
mov.b32 b,%r7697; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7023,r; 
}

	
	dp4a.s32.s32 %r7026, %r7002, %r7140, %r7829;

	
	dp4a.s32.s32 %r7030, %r7005, %r7144, %r7026;

	
	dp4a.s32.s32 %r7034, %r7008, %r7148, %r7030;

	
	dp4a.s32.s32 %r7038, %r7011, %r7152, %r7034;

	mul.lo.s32 %r8595, %r7038, %r8465;

	dp4a.s32.s32 %r7042, %r7014, %r7156, %r7829;

	
	dp4a.s32.s32 %r7046, %r7017, %r7160, %r7042;

	
	dp4a.s32.s32 %r7050, %r7020, %r7164, %r7046;

	
	dp4a.s32.s32 %r7054, %r7023, %r7168, %r7050;

	mad.lo.s32 %r8596, %r7054, %r8467, %r8595;
mul.ftz.f32 %f1294, %f1255, %f1291;
cvt.rn.f32.s32 %f1295, %r8596;
fma.rn.ftz.f32 %f1778, %f1294, %f1295, %f1778;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7731; 
mov.b32 b,%r7732; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7058,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7734; 
mov.b32 b,%r7735; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7061,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7737; 
mov.b32 b,%r7738; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7064,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7740; 
mov.b32 b,%r7741; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7067,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7743; 
mov.b32 b,%r7744; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7070,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7746; 
mov.b32 b,%r7747; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7073,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7749; 
mov.b32 b,%r7750; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7076,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7752; 
mov.b32 b,%r7753; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7079,r; 
}

	
	dp4a.s32.s32 %r7082, %r7058, %r7140, %r7829;

	
	dp4a.s32.s32 %r7086, %r7061, %r7144, %r7082;

	
	dp4a.s32.s32 %r7090, %r7064, %r7148, %r7086;

	
	dp4a.s32.s32 %r7094, %r7067, %r7152, %r7090;

	mul.lo.s32 %r8597, %r7094, %r8520;

	dp4a.s32.s32 %r7098, %r7070, %r7156, %r7829;

	
	dp4a.s32.s32 %r7102, %r7073, %r7160, %r7098;

	
	dp4a.s32.s32 %r7106, %r7076, %r7164, %r7102;

	
	dp4a.s32.s32 %r7110, %r7079, %r7168, %r7106;

	mad.lo.s32 %r8598, %r7110, %r8522, %r8597;
mul.ftz.f32 %f1296, %f1267, %f1291;
cvt.rn.f32.s32 %f1297, %r8598;
fma.rn.ftz.f32 %f1746, %f1296, %f1297, %f1746;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7787; 
mov.b32 b,%r7788; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7114,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7790; 
mov.b32 b,%r7791; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7117,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7793; 
mov.b32 b,%r7794; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7120,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7796; 
mov.b32 b,%r7797; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7123,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7799; 
mov.b32 b,%r7800; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7126,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7802; 
mov.b32 b,%r7803; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7129,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7805; 
mov.b32 b,%r7806; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7132,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7808; 
mov.b32 b,%r7809; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7135,r; 
}

	
	dp4a.s32.s32 %r7138, %r7114, %r7140, %r7829;

	
	dp4a.s32.s32 %r7142, %r7117, %r7144, %r7138;

	
	dp4a.s32.s32 %r7146, %r7120, %r7148, %r7142;

	
	dp4a.s32.s32 %r7150, %r7123, %r7152, %r7146;

	mul.lo.s32 %r8599, %r7150, %r8564;

	dp4a.s32.s32 %r7154, %r7126, %r7156, %r7829;

	
	dp4a.s32.s32 %r7158, %r7129, %r7160, %r7154;

	
	dp4a.s32.s32 %r7162, %r7132, %r7164, %r7158;

	
	dp4a.s32.s32 %r7166, %r7135, %r7168, %r7162;

	mad.lo.s32 %r8600, %r7166, %r8566, %r8599;
mul.ftz.f32 %f1298, %f1270, %f1291;
cvt.rn.f32.s32 %f1299, %r8600;
fma.rn.ftz.f32 %f1714, %f1298, %f1299, %f1714;
add.s32 %r8601, %r7852, 3712;
shr.u32 %r8602, %r8601, 1;
add.s32 %r8603, %r662, %r8602;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7619; 
mov.b32 b,%r7620; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7170,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7622; 
mov.b32 b,%r7623; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7173,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7625; 
mov.b32 b,%r7626; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7176,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7628; 
mov.b32 b,%r7629; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7179,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7631; 
mov.b32 b,%r7632; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7182,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7634; 
mov.b32 b,%r7635; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7185,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7637; 
mov.b32 b,%r7638; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7188,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7640; 
mov.b32 b,%r7641; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7191,r; 
}

	ld.shared.u32 %r7364, [%r7927+14848];

	dp4a.s32.s32 %r7194, %r7170, %r7364, %r7829;

	ld.shared.u32 %r7368, [%r7927+14852];

	dp4a.s32.s32 %r7198, %r7173, %r7368, %r7194;

	ld.shared.u32 %r7372, [%r7927+14856];

	dp4a.s32.s32 %r7202, %r7176, %r7372, %r7198;

	ld.shared.u32 %r7376, [%r7927+14860];

	dp4a.s32.s32 %r7206, %r7179, %r7376, %r7202;

	mul.lo.s32 %r8604, %r7206, %r8421;
ld.shared.u32 %r7380, [%r7927+14864];

	dp4a.s32.s32 %r7210, %r7182, %r7380, %r7829;

	ld.shared.u32 %r7384, [%r7927+14868];

	dp4a.s32.s32 %r7214, %r7185, %r7384, %r7210;

	ld.shared.u32 %r7388, [%r7927+14872];

	dp4a.s32.s32 %r7218, %r7188, %r7388, %r7214;

	ld.shared.u32 %r7392, [%r7927+14876];

	dp4a.s32.s32 %r7222, %r7191, %r7392, %r7218;

	mad.lo.s32 %r8605, %r7222, %r8423, %r8604;
ld.shared.f32 %f1300, [%r8603];
mul.ftz.f32 %f1301, %f1252, %f1300;
cvt.rn.f32.s32 %f1302, %r8605;
fma.rn.ftz.f32 %f1809, %f1301, %f1302, %f1809;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7675; 
mov.b32 b,%r7676; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7226,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7678; 
mov.b32 b,%r7679; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7229,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7681; 
mov.b32 b,%r7682; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7232,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7684; 
mov.b32 b,%r7685; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7235,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7687; 
mov.b32 b,%r7688; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7238,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7690; 
mov.b32 b,%r7691; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7241,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7693; 
mov.b32 b,%r7694; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7244,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7696; 
mov.b32 b,%r7697; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7247,r; 
}

	
	dp4a.s32.s32 %r7250, %r7226, %r7364, %r7829;

	
	dp4a.s32.s32 %r7254, %r7229, %r7368, %r7250;

	
	dp4a.s32.s32 %r7258, %r7232, %r7372, %r7254;

	
	dp4a.s32.s32 %r7262, %r7235, %r7376, %r7258;

	mul.lo.s32 %r8606, %r7262, %r8465;

	dp4a.s32.s32 %r7266, %r7238, %r7380, %r7829;

	
	dp4a.s32.s32 %r7270, %r7241, %r7384, %r7266;

	
	dp4a.s32.s32 %r7274, %r7244, %r7388, %r7270;

	
	dp4a.s32.s32 %r7278, %r7247, %r7392, %r7274;

	mad.lo.s32 %r8607, %r7278, %r8467, %r8606;
mul.ftz.f32 %f1303, %f1255, %f1300;
cvt.rn.f32.s32 %f1304, %r8607;
fma.rn.ftz.f32 %f1777, %f1303, %f1304, %f1777;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7731; 
mov.b32 b,%r7732; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7282,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7734; 
mov.b32 b,%r7735; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7285,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7737; 
mov.b32 b,%r7738; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7288,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7740; 
mov.b32 b,%r7741; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7291,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7743; 
mov.b32 b,%r7744; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7294,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7746; 
mov.b32 b,%r7747; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7297,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7749; 
mov.b32 b,%r7750; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7300,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7752; 
mov.b32 b,%r7753; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7303,r; 
}

	
	dp4a.s32.s32 %r7306, %r7282, %r7364, %r7829;

	
	dp4a.s32.s32 %r7310, %r7285, %r7368, %r7306;

	
	dp4a.s32.s32 %r7314, %r7288, %r7372, %r7310;

	
	dp4a.s32.s32 %r7318, %r7291, %r7376, %r7314;

	mul.lo.s32 %r8608, %r7318, %r8520;

	dp4a.s32.s32 %r7322, %r7294, %r7380, %r7829;

	
	dp4a.s32.s32 %r7326, %r7297, %r7384, %r7322;

	
	dp4a.s32.s32 %r7330, %r7300, %r7388, %r7326;

	
	dp4a.s32.s32 %r7334, %r7303, %r7392, %r7330;

	mad.lo.s32 %r8609, %r7334, %r8522, %r8608;
mul.ftz.f32 %f1305, %f1267, %f1300;
cvt.rn.f32.s32 %f1306, %r8609;
fma.rn.ftz.f32 %f1745, %f1305, %f1306, %f1745;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7787; 
mov.b32 b,%r7788; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7338,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7790; 
mov.b32 b,%r7791; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7341,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7793; 
mov.b32 b,%r7794; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7344,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7796; 
mov.b32 b,%r7797; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7347,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7799; 
mov.b32 b,%r7800; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7350,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7802; 
mov.b32 b,%r7803; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7353,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7805; 
mov.b32 b,%r7806; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7356,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7808; 
mov.b32 b,%r7809; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7359,r; 
}

	
	dp4a.s32.s32 %r7362, %r7338, %r7364, %r7829;

	
	dp4a.s32.s32 %r7366, %r7341, %r7368, %r7362;

	
	dp4a.s32.s32 %r7370, %r7344, %r7372, %r7366;

	
	dp4a.s32.s32 %r7374, %r7347, %r7376, %r7370;

	mul.lo.s32 %r8610, %r7374, %r8564;

	dp4a.s32.s32 %r7378, %r7350, %r7380, %r7829;

	
	dp4a.s32.s32 %r7382, %r7353, %r7384, %r7378;

	
	dp4a.s32.s32 %r7386, %r7356, %r7388, %r7382;

	
	dp4a.s32.s32 %r7390, %r7359, %r7392, %r7386;

	mad.lo.s32 %r8611, %r7390, %r8566, %r8610;
mul.ftz.f32 %f1307, %f1270, %f1300;
cvt.rn.f32.s32 %f1308, %r8611;
fma.rn.ftz.f32 %f1713, %f1307, %f1308, %f1713;
add.s32 %r8612, %r7852, 3840;
shr.u32 %r8613, %r8612, 1;
add.s32 %r8614, %r662, %r8613;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7619; 
mov.b32 b,%r7620; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7394,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7622; 
mov.b32 b,%r7623; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7397,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7625; 
mov.b32 b,%r7626; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7400,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7628; 
mov.b32 b,%r7629; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7403,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7631; 
mov.b32 b,%r7632; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7406,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7634; 
mov.b32 b,%r7635; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7409,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7637; 
mov.b32 b,%r7638; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7412,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7640; 
mov.b32 b,%r7641; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7415,r; 
}

	ld.shared.u32 %r7588, [%r7927+15360];

	dp4a.s32.s32 %r7418, %r7394, %r7588, %r7829;

	ld.shared.u32 %r7592, [%r7927+15364];

	dp4a.s32.s32 %r7422, %r7397, %r7592, %r7418;

	ld.shared.u32 %r7596, [%r7927+15368];

	dp4a.s32.s32 %r7426, %r7400, %r7596, %r7422;

	ld.shared.u32 %r7600, [%r7927+15372];

	dp4a.s32.s32 %r7430, %r7403, %r7600, %r7426;

	mul.lo.s32 %r8615, %r7430, %r8421;
ld.shared.u32 %r7604, [%r7927+15376];

	dp4a.s32.s32 %r7434, %r7406, %r7604, %r7829;

	ld.shared.u32 %r7608, [%r7927+15380];

	dp4a.s32.s32 %r7438, %r7409, %r7608, %r7434;

	ld.shared.u32 %r7612, [%r7927+15384];

	dp4a.s32.s32 %r7442, %r7412, %r7612, %r7438;

	ld.shared.u32 %r7616, [%r7927+15388];

	dp4a.s32.s32 %r7446, %r7415, %r7616, %r7442;

	mad.lo.s32 %r8616, %r7446, %r8423, %r8615;
ld.shared.f32 %f1309, [%r8614];
mul.ftz.f32 %f1310, %f1252, %f1309;
cvt.rn.f32.s32 %f1311, %r8616;
fma.rn.ftz.f32 %f1808, %f1310, %f1311, %f1808;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7675; 
mov.b32 b,%r7676; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7450,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7678; 
mov.b32 b,%r7679; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7453,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7681; 
mov.b32 b,%r7682; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7456,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7684; 
mov.b32 b,%r7685; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7459,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7687; 
mov.b32 b,%r7688; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7462,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7690; 
mov.b32 b,%r7691; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7465,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7693; 
mov.b32 b,%r7694; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7468,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7696; 
mov.b32 b,%r7697; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7471,r; 
}

	
	dp4a.s32.s32 %r7474, %r7450, %r7588, %r7829;

	
	dp4a.s32.s32 %r7478, %r7453, %r7592, %r7474;

	
	dp4a.s32.s32 %r7482, %r7456, %r7596, %r7478;

	
	dp4a.s32.s32 %r7486, %r7459, %r7600, %r7482;

	mul.lo.s32 %r8617, %r7486, %r8465;

	dp4a.s32.s32 %r7490, %r7462, %r7604, %r7829;

	
	dp4a.s32.s32 %r7494, %r7465, %r7608, %r7490;

	
	dp4a.s32.s32 %r7498, %r7468, %r7612, %r7494;

	
	dp4a.s32.s32 %r7502, %r7471, %r7616, %r7498;

	mad.lo.s32 %r8618, %r7502, %r8467, %r8617;
mul.ftz.f32 %f1312, %f1255, %f1309;
cvt.rn.f32.s32 %f1313, %r8618;
fma.rn.ftz.f32 %f1776, %f1312, %f1313, %f1776;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7731; 
mov.b32 b,%r7732; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7506,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7734; 
mov.b32 b,%r7735; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7509,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7737; 
mov.b32 b,%r7738; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7512,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7740; 
mov.b32 b,%r7741; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7515,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7743; 
mov.b32 b,%r7744; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7518,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7746; 
mov.b32 b,%r7747; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7521,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7749; 
mov.b32 b,%r7750; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7524,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7752; 
mov.b32 b,%r7753; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7527,r; 
}

	
	dp4a.s32.s32 %r7530, %r7506, %r7588, %r7829;

	
	dp4a.s32.s32 %r7534, %r7509, %r7592, %r7530;

	
	dp4a.s32.s32 %r7538, %r7512, %r7596, %r7534;

	
	dp4a.s32.s32 %r7542, %r7515, %r7600, %r7538;

	mul.lo.s32 %r8619, %r7542, %r8520;

	dp4a.s32.s32 %r7546, %r7518, %r7604, %r7829;

	
	dp4a.s32.s32 %r7550, %r7521, %r7608, %r7546;

	
	dp4a.s32.s32 %r7554, %r7524, %r7612, %r7550;

	
	dp4a.s32.s32 %r7558, %r7527, %r7616, %r7554;

	mad.lo.s32 %r8620, %r7558, %r8522, %r8619;
mul.ftz.f32 %f1314, %f1267, %f1309;
cvt.rn.f32.s32 %f1315, %r8620;
fma.rn.ftz.f32 %f1744, %f1314, %f1315, %f1744;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7787; 
mov.b32 b,%r7788; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7562,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7790; 
mov.b32 b,%r7791; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7565,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7793; 
mov.b32 b,%r7794; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7568,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7796; 
mov.b32 b,%r7797; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7571,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7799; 
mov.b32 b,%r7800; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7574,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7802; 
mov.b32 b,%r7803; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7577,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7805; 
mov.b32 b,%r7806; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7580,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7808; 
mov.b32 b,%r7809; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7583,r; 
}

	
	dp4a.s32.s32 %r7586, %r7562, %r7588, %r7829;

	
	dp4a.s32.s32 %r7590, %r7565, %r7592, %r7586;

	
	dp4a.s32.s32 %r7594, %r7568, %r7596, %r7590;

	
	dp4a.s32.s32 %r7598, %r7571, %r7600, %r7594;

	mul.lo.s32 %r8621, %r7598, %r8564;

	dp4a.s32.s32 %r7602, %r7574, %r7604, %r7829;

	
	dp4a.s32.s32 %r7606, %r7577, %r7608, %r7602;

	
	dp4a.s32.s32 %r7610, %r7580, %r7612, %r7606;

	
	dp4a.s32.s32 %r7614, %r7583, %r7616, %r7610;

	mad.lo.s32 %r8622, %r7614, %r8566, %r8621;
mul.ftz.f32 %f1316, %f1270, %f1309;
cvt.rn.f32.s32 %f1317, %r8622;
fma.rn.ftz.f32 %f1712, %f1316, %f1317, %f1712;
add.s32 %r8623, %r7852, 3968;
shr.u32 %r8624, %r8623, 1;
add.s32 %r8625, %r662, %r8624;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7619; 
mov.b32 b,%r7620; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7618,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7622; 
mov.b32 b,%r7623; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7621,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7625; 
mov.b32 b,%r7626; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7624,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7628; 
mov.b32 b,%r7629; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7627,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7631; 
mov.b32 b,%r7632; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7630,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7634; 
mov.b32 b,%r7635; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7633,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7637; 
mov.b32 b,%r7638; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7636,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7640; 
mov.b32 b,%r7641; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7639,r; 
}

	ld.shared.u32 %r7812, [%r7927+15872];

	dp4a.s32.s32 %r7642, %r7618, %r7812, %r7829;

	ld.shared.u32 %r7816, [%r7927+15876];

	dp4a.s32.s32 %r7646, %r7621, %r7816, %r7642;

	ld.shared.u32 %r7820, [%r7927+15880];

	dp4a.s32.s32 %r7650, %r7624, %r7820, %r7646;

	ld.shared.u32 %r7824, [%r7927+15884];

	dp4a.s32.s32 %r7654, %r7627, %r7824, %r7650;

	mul.lo.s32 %r8626, %r7654, %r8421;
ld.shared.u32 %r7828, [%r7927+15888];

	dp4a.s32.s32 %r7658, %r7630, %r7828, %r7829;

	ld.shared.u32 %r7832, [%r7927+15892];

	dp4a.s32.s32 %r7662, %r7633, %r7832, %r7658;

	ld.shared.u32 %r7836, [%r7927+15896];

	dp4a.s32.s32 %r7666, %r7636, %r7836, %r7662;

	ld.shared.u32 %r7840, [%r7927+15900];

	dp4a.s32.s32 %r7670, %r7639, %r7840, %r7666;

	mad.lo.s32 %r8627, %r7670, %r8423, %r8626;
ld.shared.f32 %f1318, [%r8625];
mul.ftz.f32 %f1319, %f1252, %f1318;
cvt.rn.f32.s32 %f1320, %r8627;
fma.rn.ftz.f32 %f1807, %f1319, %f1320, %f1807;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7675; 
mov.b32 b,%r7676; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7674,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7678; 
mov.b32 b,%r7679; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7677,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7681; 
mov.b32 b,%r7682; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7680,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7684; 
mov.b32 b,%r7685; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7683,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7687; 
mov.b32 b,%r7688; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7686,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7690; 
mov.b32 b,%r7691; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7689,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7693; 
mov.b32 b,%r7694; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7692,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7696; 
mov.b32 b,%r7697; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7695,r; 
}

	
	dp4a.s32.s32 %r7698, %r7674, %r7812, %r7829;

	
	dp4a.s32.s32 %r7702, %r7677, %r7816, %r7698;

	
	dp4a.s32.s32 %r7706, %r7680, %r7820, %r7702;

	
	dp4a.s32.s32 %r7710, %r7683, %r7824, %r7706;

	mul.lo.s32 %r8628, %r7710, %r8465;

	dp4a.s32.s32 %r7714, %r7686, %r7828, %r7829;

	
	dp4a.s32.s32 %r7718, %r7689, %r7832, %r7714;

	
	dp4a.s32.s32 %r7722, %r7692, %r7836, %r7718;

	
	dp4a.s32.s32 %r7726, %r7695, %r7840, %r7722;

	mad.lo.s32 %r8629, %r7726, %r8467, %r8628;
mul.ftz.f32 %f1321, %f1255, %f1318;
cvt.rn.f32.s32 %f1322, %r8629;
fma.rn.ftz.f32 %f1775, %f1321, %f1322, %f1775;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7731; 
mov.b32 b,%r7732; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7730,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7734; 
mov.b32 b,%r7735; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7733,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7737; 
mov.b32 b,%r7738; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7736,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7740; 
mov.b32 b,%r7741; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7739,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7743; 
mov.b32 b,%r7744; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7742,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7746; 
mov.b32 b,%r7747; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7745,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7749; 
mov.b32 b,%r7750; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7748,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7752; 
mov.b32 b,%r7753; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7751,r; 
}

	
	dp4a.s32.s32 %r7754, %r7730, %r7812, %r7829;

	
	dp4a.s32.s32 %r7758, %r7733, %r7816, %r7754;

	
	dp4a.s32.s32 %r7762, %r7736, %r7820, %r7758;

	
	dp4a.s32.s32 %r7766, %r7739, %r7824, %r7762;

	mul.lo.s32 %r8630, %r7766, %r8520;

	dp4a.s32.s32 %r7770, %r7742, %r7828, %r7829;

	
	dp4a.s32.s32 %r7774, %r7745, %r7832, %r7770;

	
	dp4a.s32.s32 %r7778, %r7748, %r7836, %r7774;

	
	dp4a.s32.s32 %r7782, %r7751, %r7840, %r7778;

	mad.lo.s32 %r8631, %r7782, %r8522, %r8630;
mul.ftz.f32 %f1323, %f1267, %f1318;
cvt.rn.f32.s32 %f1324, %r8631;
fma.rn.ftz.f32 %f1743, %f1323, %f1324, %f1743;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7787; 
mov.b32 b,%r7788; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7786,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7790; 
mov.b32 b,%r7791; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7789,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7793; 
mov.b32 b,%r7794; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7792,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7796; 
mov.b32 b,%r7797; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7795,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7799; 
mov.b32 b,%r7800; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7798,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7802; 
mov.b32 b,%r7803; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7801,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7805; 
mov.b32 b,%r7806; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7804,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7808; 
mov.b32 b,%r7809; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7807,r; 
}

	
	dp4a.s32.s32 %r7810, %r7786, %r7812, %r7829;

	
	dp4a.s32.s32 %r7814, %r7789, %r7816, %r7810;

	
	dp4a.s32.s32 %r7818, %r7792, %r7820, %r7814;

	
	dp4a.s32.s32 %r7822, %r7795, %r7824, %r7818;

	mul.lo.s32 %r8632, %r7822, %r8564;

	dp4a.s32.s32 %r7826, %r7798, %r7828, %r7829;

	
	dp4a.s32.s32 %r7830, %r7801, %r7832, %r7826;

	
	dp4a.s32.s32 %r7834, %r7804, %r7836, %r7830;

	
	dp4a.s32.s32 %r7838, %r7807, %r7840, %r7834;

	mad.lo.s32 %r8633, %r7838, %r8566, %r8632;
mul.ftz.f32 %f1325, %f1270, %f1318;
cvt.rn.f32.s32 %f1326, %r8633;
fma.rn.ftz.f32 %f1711, %f1325, %f1326, %f1711;
add.s32 %r8724, %r8724, 2;
setp.lt.s32 %p3, %r8724, %r5;
@%p3 bra $L__BB53_5;

$L__BB53_6:
bar.sync 0;
add.s32 %r8723, %r8723, 1;
setp.lt.u32 %p4, %r8723, 4;
@%p4 bra $L__BB53_4;

add.s32 %r8722, %r8722, 2;
setp.lt.s32 %p5, %r8722, %r1;
@%p5 bra $L__BB53_3;
bra.uni $L__BB53_8;

$L__BB53_1:
mov.f32 %f1711, 0f00000000;
mov.f32 %f1712, %f1711;
mov.f32 %f1713, %f1711;
mov.f32 %f1714, %f1711;
mov.f32 %f1715, %f1711;
mov.f32 %f1716, %f1711;
mov.f32 %f1717, %f1711;
mov.f32 %f1718, %f1711;
mov.f32 %f1719, %f1711;
mov.f32 %f1720, %f1711;
mov.f32 %f1721, %f1711;
mov.f32 %f1722, %f1711;
mov.f32 %f1723, %f1711;
mov.f32 %f1724, %f1711;
mov.f32 %f1725, %f1711;
mov.f32 %f1726, %f1711;
mov.f32 %f1727, %f1711;
mov.f32 %f1728, %f1711;
mov.f32 %f1729, %f1711;
mov.f32 %f1730, %f1711;
mov.f32 %f1731, %f1711;
mov.f32 %f1732, %f1711;
mov.f32 %f1733, %f1711;
mov.f32 %f1734, %f1711;
mov.f32 %f1735, %f1711;
mov.f32 %f1736, %f1711;
mov.f32 %f1737, %f1711;
mov.f32 %f1738, %f1711;
mov.f32 %f1739, %f1711;
mov.f32 %f1740, %f1711;
mov.f32 %f1741, %f1711;
mov.f32 %f1742, %f1711;
mov.f32 %f1743, %f1711;
mov.f32 %f1744, %f1711;
mov.f32 %f1745, %f1711;
mov.f32 %f1746, %f1711;
mov.f32 %f1747, %f1711;
mov.f32 %f1748, %f1711;
mov.f32 %f1749, %f1711;
mov.f32 %f1750, %f1711;
mov.f32 %f1751, %f1711;
mov.f32 %f1752, %f1711;
mov.f32 %f1753, %f1711;
mov.f32 %f1754, %f1711;
mov.f32 %f1755, %f1711;
mov.f32 %f1756, %f1711;
mov.f32 %f1757, %f1711;
mov.f32 %f1758, %f1711;
mov.f32 %f1759, %f1711;
mov.f32 %f1760, %f1711;
mov.f32 %f1761, %f1711;
mov.f32 %f1762, %f1711;
mov.f32 %f1763, %f1711;
mov.f32 %f1764, %f1711;
mov.f32 %f1765, %f1711;
mov.f32 %f1766, %f1711;
mov.f32 %f1767, %f1711;
mov.f32 %f1768, %f1711;
mov.f32 %f1769, %f1711;
mov.f32 %f1770, %f1711;
mov.f32 %f1771, %f1711;
mov.f32 %f1772, %f1711;
mov.f32 %f1773, %f1711;
mov.f32 %f1774, %f1711;
mov.f32 %f1775, %f1711;
mov.f32 %f1776, %f1711;
mov.f32 %f1777, %f1711;
mov.f32 %f1778, %f1711;
mov.f32 %f1779, %f1711;
mov.f32 %f1780, %f1711;
mov.f32 %f1781, %f1711;
mov.f32 %f1782, %f1711;
mov.f32 %f1783, %f1711;
mov.f32 %f1784, %f1711;
mov.f32 %f1785, %f1711;
mov.f32 %f1786, %f1711;
mov.f32 %f1787, %f1711;
mov.f32 %f1788, %f1711;
mov.f32 %f1789, %f1711;
mov.f32 %f1790, %f1711;
mov.f32 %f1791, %f1711;
mov.f32 %f1792, %f1711;
mov.f32 %f1793, %f1711;
mov.f32 %f1794, %f1711;
mov.f32 %f1795, %f1711;
mov.f32 %f1796, %f1711;
mov.f32 %f1797, %f1711;
mov.f32 %f1798, %f1711;
mov.f32 %f1799, %f1711;
mov.f32 %f1800, %f1711;
mov.f32 %f1801, %f1711;
mov.f32 %f1802, %f1711;
mov.f32 %f1803, %f1711;
mov.f32 %f1804, %f1711;
mov.f32 %f1805, %f1711;
mov.f32 %f1806, %f1711;
mov.f32 %f1807, %f1711;
mov.f32 %f1808, %f1711;
mov.f32 %f1809, %f1711;
mov.f32 %f1810, %f1711;
mov.f32 %f1811, %f1711;
mov.f32 %f1812, %f1711;
mov.f32 %f1813, %f1711;
mov.f32 %f1814, %f1711;
mov.f32 %f1815, %f1711;
mov.f32 %f1816, %f1711;
mov.f32 %f1817, %f1711;
mov.f32 %f1818, %f1711;
mov.f32 %f1819, %f1711;
mov.f32 %f1820, %f1711;
mov.f32 %f1821, %f1711;
mov.f32 %f1822, %f1711;
mov.f32 %f1823, %f1711;
mov.f32 %f1824, %f1711;
mov.f32 %f1825, %f1711;
mov.f32 %f1826, %f1711;
mov.f32 %f1827, %f1711;
mov.f32 %f1828, %f1711;
mov.f32 %f1829, %f1711;
mov.f32 %f1830, %f1711;
mov.f32 %f1831, %f1711;
mov.f32 %f1832, %f1711;
mov.f32 %f1833, %f1711;
mov.f32 %f1834, %f1711;
mov.f32 %f1835, %f1711;
mov.f32 %f1836, %f1711;
mov.f32 %f1837, %f1711;
mov.f32 %f1838, %f1711;

$L__BB53_8:
mov.u32 %r8634, %ctaid.y;
shl.b32 %r8635, %r8634, 7;
mov.u32 %r8636, %tid.y;
add.s32 %r11, %r8635, %r8636;
mov.u32 %r8637, %ctaid.x;
shl.b32 %r8638, %r8637, 7;
mov.u32 %r8639, %tid.x;
add.s32 %r12, %r8638, %r8639;
setp.ge.s32 %p6, %r11, %r48;
@%p6 bra $L__BB53_296;

ld.param.u64 %rd479, [_Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_2];
ld.param.u32 %r8706, [_Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_7];
mul.lo.s32 %r13, %r11, %r8706;
add.s32 %r8640, %r12, %r13;
cvta.to.global.u64 %rd415, %rd479;
mul.wide.s32 %rd416, %r8640, 4;
add.s64 %rd1, %rd415, %rd416;
setp.ge.s32 %p7, %r12, %r8706;
@%p7 bra $L__BB53_11;

st.global.f32 [%rd1], %f1838;

$L__BB53_11:
ld.param.u32 %r8707, [_Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_7];
add.s32 %r14, %r12, 32;
setp.ge.s32 %p8, %r14, %r8707;
@%p8 bra $L__BB53_13;

st.global.f32 [%rd1+128], %f1806;

$L__BB53_13:
ld.param.u32 %r8708, [_Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_7];
add.s32 %r15, %r12, 64;
setp.ge.s32 %p9, %r15, %r8708;
@%p9 bra $L__BB53_15;

st.global.f32 [%rd1+256], %f1774;

$L__BB53_15:
ld.param.u32 %r8709, [_Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_7];
add.s32 %r16, %r12, 96;
setp.ge.s32 %p10, %r16, %r8709;
@%p10 bra $L__BB53_17;

st.global.f32 [%rd1+384], %f1742;

$L__BB53_17:
add.s32 %r8641, %r11, 4;
setp.ge.s32 %p11, %r8641, %r48;
@%p11 bra $L__BB53_296;

ld.param.u32 %r8710, [_Z12mul_mat_q3_KILb0EEvPKvS1_Pfiiiii_param_7];
shl.b32 %r17, %r8710, 2;
add.s32 %r18, %r13, %r17;
add.s32 %r8642, %r12, %r18;
mul.wide.s32 %rd418, %r8642, 4;
add.s64 %rd2, %rd415, %rd418;
@%p7 bra $L__BB53_20;

st.global.f32 [%rd2], %f1837;

$L__BB53_20:
@%p8 bra $L__BB53_22;

st.global.f32 [%rd2+128], %f1805;

$L__BB53_22:
@%p9 bra $L__BB53_24;

st.global.f32 [%rd2+256], %f1773;

$L__BB53_24:
@%p10 bra $L__BB53_26;

st.global.f32 [%rd2+384], %f1741;

$L__BB53_26:
add.s32 %r8643, %r11, 8;
setp.ge.s32 %p16, %r8643, %r48;
@%p16 bra $L__BB53_296;

add.s32 %r19, %r18, %r17;
add.s32 %r8644, %r12, %r19;
mul.wide.s32 %rd420, %r8644, 4;
add.s64 %rd3, %rd415, %rd420;
@%p7 bra $L__BB53_29;

st.global.f32 [%rd3], %f1836;

$L__BB53_29:
@%p8 bra $L__BB53_31;

st.global.f32 [%rd3+128], %f1804;

$L__BB53_31:
@%p9 bra $L__BB53_33;

st.global.f32 [%rd3+256], %f1772;

$L__BB53_33:
@%p10 bra $L__BB53_35;

st.global.f32 [%rd3+384], %f1740;

$L__BB53_35:
add.s32 %r8645, %r11, 12;
setp.ge.s32 %p21, %r8645, %r48;
@%p21 bra $L__BB53_296;

add.s32 %r20, %r19, %r17;
add.s32 %r8646, %r12, %r20;
mul.wide.s32 %rd422, %r8646, 4;
add.s64 %rd4, %rd415, %rd422;
@%p7 bra $L__BB53_38;

st.global.f32 [%rd4], %f1835;

$L__BB53_38:
@%p8 bra $L__BB53_40;

st.global.f32 [%rd4+128], %f1803;

$L__BB53_40:
@%p9 bra $L__BB53_42;

st.global.f32 [%rd4+256], %f1771;

$L__BB53_42:
@%p10 bra $L__BB53_44;

st.global.f32 [%rd4+384], %f1739;

$L__BB53_44:
add.s32 %r8647, %r11, 16;
setp.ge.s32 %p26, %r8647, %r48;
@%p26 bra $L__BB53_296;

add.s32 %r21, %r20, %r17;
add.s32 %r8648, %r12, %r21;
mul.wide.s32 %rd424, %r8648, 4;
add.s64 %rd5, %rd415, %rd424;
@%p7 bra $L__BB53_47;

st.global.f32 [%rd5], %f1834;

$L__BB53_47:
@%p8 bra $L__BB53_49;

st.global.f32 [%rd5+128], %f1802;

$L__BB53_49:
@%p9 bra $L__BB53_51;

st.global.f32 [%rd5+256], %f1770;

$L__BB53_51:
@%p10 bra $L__BB53_53;

st.global.f32 [%rd5+384], %f1738;

$L__BB53_53:
add.s32 %r8649, %r11, 20;
setp.ge.s32 %p31, %r8649, %r48;
@%p31 bra $L__BB53_296;

add.s32 %r22, %r21, %r17;
add.s32 %r8650, %r12, %r22;
mul.wide.s32 %rd426, %r8650, 4;
add.s64 %rd6, %rd415, %rd426;
@%p7 bra $L__BB53_56;

st.global.f32 [%rd6], %f1833;

$L__BB53_56:
@%p8 bra $L__BB53_58;

st.global.f32 [%rd6+128], %f1801;

$L__BB53_58:
@%p9 bra $L__BB53_60;

st.global.f32 [%rd6+256], %f1769;

$L__BB53_60:
@%p10 bra $L__BB53_62;

st.global.f32 [%rd6+384], %f1737;

$L__BB53_62:
add.s32 %r8651, %r11, 24;
setp.ge.s32 %p36, %r8651, %r48;
@%p36 bra $L__BB53_296;

add.s32 %r23, %r22, %r17;
add.s32 %r8652, %r12, %r23;
mul.wide.s32 %rd428, %r8652, 4;
add.s64 %rd7, %rd415, %rd428;
@%p7 bra $L__BB53_65;

st.global.f32 [%rd7], %f1832;

$L__BB53_65:
@%p8 bra $L__BB53_67;

st.global.f32 [%rd7+128], %f1800;

$L__BB53_67:
@%p9 bra $L__BB53_69;

st.global.f32 [%rd7+256], %f1768;

$L__BB53_69:
@%p10 bra $L__BB53_71;

st.global.f32 [%rd7+384], %f1736;

$L__BB53_71:
add.s32 %r8653, %r11, 28;
setp.ge.s32 %p41, %r8653, %r48;
@%p41 bra $L__BB53_296;

add.s32 %r24, %r23, %r17;
add.s32 %r8654, %r12, %r24;
mul.wide.s32 %rd430, %r8654, 4;
add.s64 %rd8, %rd415, %rd430;
@%p7 bra $L__BB53_74;

st.global.f32 [%rd8], %f1831;

$L__BB53_74:
@%p8 bra $L__BB53_76;

st.global.f32 [%rd8+128], %f1799;

$L__BB53_76:
@%p9 bra $L__BB53_78;

st.global.f32 [%rd8+256], %f1767;

$L__BB53_78:
@%p10 bra $L__BB53_80;

st.global.f32 [%rd8+384], %f1735;

$L__BB53_80:
add.s32 %r8655, %r11, 32;
setp.ge.s32 %p46, %r8655, %r48;
@%p46 bra $L__BB53_296;

add.s32 %r25, %r24, %r17;
add.s32 %r8656, %r12, %r25;
mul.wide.s32 %rd432, %r8656, 4;
add.s64 %rd9, %rd415, %rd432;
@%p7 bra $L__BB53_83;

st.global.f32 [%rd9], %f1830;

$L__BB53_83:
@%p8 bra $L__BB53_85;

st.global.f32 [%rd9+128], %f1798;

$L__BB53_85:
@%p9 bra $L__BB53_87;

st.global.f32 [%rd9+256], %f1766;

$L__BB53_87:
@%p10 bra $L__BB53_89;

st.global.f32 [%rd9+384], %f1734;

$L__BB53_89:
add.s32 %r8657, %r11, 36;
setp.ge.s32 %p51, %r8657, %r48;
@%p51 bra $L__BB53_296;

add.s32 %r26, %r25, %r17;
add.s32 %r8658, %r12, %r26;
mul.wide.s32 %rd434, %r8658, 4;
add.s64 %rd10, %rd415, %rd434;
@%p7 bra $L__BB53_92;

st.global.f32 [%rd10], %f1829;

$L__BB53_92:
@%p8 bra $L__BB53_94;

st.global.f32 [%rd10+128], %f1797;

$L__BB53_94:
@%p9 bra $L__BB53_96;

st.global.f32 [%rd10+256], %f1765;

$L__BB53_96:
@%p10 bra $L__BB53_98;

st.global.f32 [%rd10+384], %f1733;

$L__BB53_98:
add.s32 %r8659, %r11, 40;
setp.ge.s32 %p56, %r8659, %r48;
@%p56 bra $L__BB53_296;

add.s32 %r27, %r26, %r17;
add.s32 %r8660, %r12, %r27;
mul.wide.s32 %rd436, %r8660, 4;
add.s64 %rd11, %rd415, %rd436;
@%p7 bra $L__BB53_101;

st.global.f32 [%rd11], %f1828;

$L__BB53_101:
@%p8 bra $L__BB53_103;

st.global.f32 [%rd11+128], %f1796;

$L__BB53_103:
@%p9 bra $L__BB53_105;

st.global.f32 [%rd11+256], %f1764;

$L__BB53_105:
@%p10 bra $L__BB53_107;

st.global.f32 [%rd11+384], %f1732;

$L__BB53_107:
add.s32 %r8661, %r11, 44;
setp.ge.s32 %p61, %r8661, %r48;
@%p61 bra $L__BB53_296;

add.s32 %r28, %r27, %r17;
add.s32 %r8662, %r12, %r28;
mul.wide.s32 %rd438, %r8662, 4;
add.s64 %rd12, %rd415, %rd438;
@%p7 bra $L__BB53_110;

st.global.f32 [%rd12], %f1827;

$L__BB53_110:
@%p8 bra $L__BB53_112;

st.global.f32 [%rd12+128], %f1795;

$L__BB53_112:
@%p9 bra $L__BB53_114;

st.global.f32 [%rd12+256], %f1763;

$L__BB53_114:
@%p10 bra $L__BB53_116;

st.global.f32 [%rd12+384], %f1731;

$L__BB53_116:
add.s32 %r8663, %r11, 48;
setp.ge.s32 %p66, %r8663, %r48;
@%p66 bra $L__BB53_296;

add.s32 %r29, %r28, %r17;
add.s32 %r8664, %r12, %r29;
mul.wide.s32 %rd440, %r8664, 4;
add.s64 %rd13, %rd415, %rd440;
@%p7 bra $L__BB53_119;

st.global.f32 [%rd13], %f1826;

$L__BB53_119:
@%p8 bra $L__BB53_121;

st.global.f32 [%rd13+128], %f1794;

$L__BB53_121:
@%p9 bra $L__BB53_123;

st.global.f32 [%rd13+256], %f1762;

$L__BB53_123:
@%p10 bra $L__BB53_125;

st.global.f32 [%rd13+384], %f1730;

$L__BB53_125:
add.s32 %r8665, %r11, 52;
setp.ge.s32 %p71, %r8665, %r48;
@%p71 bra $L__BB53_296;

add.s32 %r30, %r29, %r17;
add.s32 %r8666, %r12, %r30;
mul.wide.s32 %rd442, %r8666, 4;
add.s64 %rd14, %rd415, %rd442;
@%p7 bra $L__BB53_128;

st.global.f32 [%rd14], %f1825;

$L__BB53_128:
@%p8 bra $L__BB53_130;

st.global.f32 [%rd14+128], %f1793;

$L__BB53_130:
@%p9 bra $L__BB53_132;

st.global.f32 [%rd14+256], %f1761;

$L__BB53_132:
@%p10 bra $L__BB53_134;

st.global.f32 [%rd14+384], %f1729;

$L__BB53_134:
add.s32 %r8667, %r11, 56;
setp.ge.s32 %p76, %r8667, %r48;
@%p76 bra $L__BB53_296;

add.s32 %r31, %r30, %r17;
add.s32 %r8668, %r12, %r31;
mul.wide.s32 %rd444, %r8668, 4;
add.s64 %rd15, %rd415, %rd444;
@%p7 bra $L__BB53_137;

st.global.f32 [%rd15], %f1824;

$L__BB53_137:
@%p8 bra $L__BB53_139;

st.global.f32 [%rd15+128], %f1792;

$L__BB53_139:
@%p9 bra $L__BB53_141;

st.global.f32 [%rd15+256], %f1760;

$L__BB53_141:
@%p10 bra $L__BB53_143;

st.global.f32 [%rd15+384], %f1728;

$L__BB53_143:
add.s32 %r8669, %r11, 60;
setp.ge.s32 %p81, %r8669, %r48;
@%p81 bra $L__BB53_296;

add.s32 %r32, %r31, %r17;
add.s32 %r8670, %r12, %r32;
mul.wide.s32 %rd446, %r8670, 4;
add.s64 %rd16, %rd415, %rd446;
@%p7 bra $L__BB53_146;

st.global.f32 [%rd16], %f1823;

$L__BB53_146:
@%p8 bra $L__BB53_148;

st.global.f32 [%rd16+128], %f1791;

$L__BB53_148:
@%p9 bra $L__BB53_150;

st.global.f32 [%rd16+256], %f1759;

$L__BB53_150:
@%p10 bra $L__BB53_152;

st.global.f32 [%rd16+384], %f1727;

$L__BB53_152:
add.s32 %r8671, %r11, 64;
setp.ge.s32 %p86, %r8671, %r48;
@%p86 bra $L__BB53_296;

add.s32 %r33, %r32, %r17;
add.s32 %r8672, %r12, %r33;
mul.wide.s32 %rd448, %r8672, 4;
add.s64 %rd17, %rd415, %rd448;
@%p7 bra $L__BB53_155;

st.global.f32 [%rd17], %f1822;

$L__BB53_155:
@%p8 bra $L__BB53_157;

st.global.f32 [%rd17+128], %f1790;

$L__BB53_157:
@%p9 bra $L__BB53_159;

st.global.f32 [%rd17+256], %f1758;

$L__BB53_159:
@%p10 bra $L__BB53_161;

st.global.f32 [%rd17+384], %f1726;

$L__BB53_161:
add.s32 %r8673, %r11, 68;
setp.ge.s32 %p91, %r8673, %r48;
@%p91 bra $L__BB53_296;

add.s32 %r34, %r33, %r17;
add.s32 %r8674, %r12, %r34;
mul.wide.s32 %rd450, %r8674, 4;
add.s64 %rd18, %rd415, %rd450;
@%p7 bra $L__BB53_164;

st.global.f32 [%rd18], %f1821;

$L__BB53_164:
@%p8 bra $L__BB53_166;

st.global.f32 [%rd18+128], %f1789;

$L__BB53_166:
@%p9 bra $L__BB53_168;

st.global.f32 [%rd18+256], %f1757;

$L__BB53_168:
@%p10 bra $L__BB53_170;

st.global.f32 [%rd18+384], %f1725;

$L__BB53_170:
add.s32 %r8675, %r11, 72;
setp.ge.s32 %p96, %r8675, %r48;
@%p96 bra $L__BB53_296;

add.s32 %r35, %r34, %r17;
add.s32 %r8676, %r12, %r35;
mul.wide.s32 %rd452, %r8676, 4;
add.s64 %rd19, %rd415, %rd452;
@%p7 bra $L__BB53_173;

st.global.f32 [%rd19], %f1820;

$L__BB53_173:
@%p8 bra $L__BB53_175;

st.global.f32 [%rd19+128], %f1788;

$L__BB53_175:
@%p9 bra $L__BB53_177;

st.global.f32 [%rd19+256], %f1756;

$L__BB53_177:
@%p10 bra $L__BB53_179;

st.global.f32 [%rd19+384], %f1724;

$L__BB53_179:
add.s32 %r8677, %r11, 76;
setp.ge.s32 %p101, %r8677, %r48;
@%p101 bra $L__BB53_296;

add.s32 %r36, %r35, %r17;
add.s32 %r8678, %r12, %r36;
mul.wide.s32 %rd454, %r8678, 4;
add.s64 %rd20, %rd415, %rd454;
@%p7 bra $L__BB53_182;

st.global.f32 [%rd20], %f1819;

$L__BB53_182:
@%p8 bra $L__BB53_184;

st.global.f32 [%rd20+128], %f1787;

$L__BB53_184:
@%p9 bra $L__BB53_186;

st.global.f32 [%rd20+256], %f1755;

$L__BB53_186:
@%p10 bra $L__BB53_188;

st.global.f32 [%rd20+384], %f1723;

$L__BB53_188:
add.s32 %r8679, %r11, 80;
setp.ge.s32 %p106, %r8679, %r48;
@%p106 bra $L__BB53_296;

add.s32 %r37, %r36, %r17;
add.s32 %r8680, %r12, %r37;
mul.wide.s32 %rd456, %r8680, 4;
add.s64 %rd21, %rd415, %rd456;
@%p7 bra $L__BB53_191;

st.global.f32 [%rd21], %f1818;

$L__BB53_191:
@%p8 bra $L__BB53_193;

st.global.f32 [%rd21+128], %f1786;

$L__BB53_193:
@%p9 bra $L__BB53_195;

st.global.f32 [%rd21+256], %f1754;

$L__BB53_195:
@%p10 bra $L__BB53_197;

st.global.f32 [%rd21+384], %f1722;

$L__BB53_197:
add.s32 %r8681, %r11, 84;
setp.ge.s32 %p111, %r8681, %r48;
@%p111 bra $L__BB53_296;

add.s32 %r38, %r37, %r17;
add.s32 %r8682, %r12, %r38;
mul.wide.s32 %rd458, %r8682, 4;
add.s64 %rd22, %rd415, %rd458;
@%p7 bra $L__BB53_200;

st.global.f32 [%rd22], %f1817;

$L__BB53_200:
@%p8 bra $L__BB53_202;

st.global.f32 [%rd22+128], %f1785;

$L__BB53_202:
@%p9 bra $L__BB53_204;

st.global.f32 [%rd22+256], %f1753;

$L__BB53_204:
@%p10 bra $L__BB53_206;

st.global.f32 [%rd22+384], %f1721;

$L__BB53_206:
add.s32 %r8683, %r11, 88;
setp.ge.s32 %p116, %r8683, %r48;
@%p116 bra $L__BB53_296;

add.s32 %r39, %r38, %r17;
add.s32 %r8684, %r12, %r39;
mul.wide.s32 %rd460, %r8684, 4;
add.s64 %rd23, %rd415, %rd460;
@%p7 bra $L__BB53_209;

st.global.f32 [%rd23], %f1816;

$L__BB53_209:
@%p8 bra $L__BB53_211;

st.global.f32 [%rd23+128], %f1784;

$L__BB53_211:
@%p9 bra $L__BB53_213;

st.global.f32 [%rd23+256], %f1752;

$L__BB53_213:
@%p10 bra $L__BB53_215;

st.global.f32 [%rd23+384], %f1720;

$L__BB53_215:
add.s32 %r8685, %r11, 92;
setp.ge.s32 %p121, %r8685, %r48;
@%p121 bra $L__BB53_296;

add.s32 %r40, %r39, %r17;
add.s32 %r8686, %r12, %r40;
mul.wide.s32 %rd462, %r8686, 4;
add.s64 %rd24, %rd415, %rd462;
@%p7 bra $L__BB53_218;

st.global.f32 [%rd24], %f1815;

$L__BB53_218:
@%p8 bra $L__BB53_220;

st.global.f32 [%rd24+128], %f1783;

$L__BB53_220:
@%p9 bra $L__BB53_222;

st.global.f32 [%rd24+256], %f1751;

$L__BB53_222:
@%p10 bra $L__BB53_224;

st.global.f32 [%rd24+384], %f1719;

$L__BB53_224:
add.s32 %r8687, %r11, 96;
setp.ge.s32 %p126, %r8687, %r48;
@%p126 bra $L__BB53_296;

add.s32 %r41, %r40, %r17;
add.s32 %r8688, %r12, %r41;
mul.wide.s32 %rd464, %r8688, 4;
add.s64 %rd25, %rd415, %rd464;
@%p7 bra $L__BB53_227;

st.global.f32 [%rd25], %f1814;

$L__BB53_227:
@%p8 bra $L__BB53_229;

st.global.f32 [%rd25+128], %f1782;

$L__BB53_229:
@%p9 bra $L__BB53_231;

st.global.f32 [%rd25+256], %f1750;

$L__BB53_231:
@%p10 bra $L__BB53_233;

st.global.f32 [%rd25+384], %f1718;

$L__BB53_233:
add.s32 %r8689, %r11, 100;
setp.ge.s32 %p131, %r8689, %r48;
@%p131 bra $L__BB53_296;

add.s32 %r42, %r41, %r17;
add.s32 %r8690, %r12, %r42;
mul.wide.s32 %rd466, %r8690, 4;
add.s64 %rd26, %rd415, %rd466;
@%p7 bra $L__BB53_236;

st.global.f32 [%rd26], %f1813;

$L__BB53_236:
@%p8 bra $L__BB53_238;

st.global.f32 [%rd26+128], %f1781;

$L__BB53_238:
@%p9 bra $L__BB53_240;

st.global.f32 [%rd26+256], %f1749;

$L__BB53_240:
@%p10 bra $L__BB53_242;

st.global.f32 [%rd26+384], %f1717;

$L__BB53_242:
add.s32 %r8691, %r11, 104;
setp.ge.s32 %p136, %r8691, %r48;
@%p136 bra $L__BB53_296;

add.s32 %r43, %r42, %r17;
add.s32 %r8692, %r12, %r43;
mul.wide.s32 %rd468, %r8692, 4;
add.s64 %rd27, %rd415, %rd468;
@%p7 bra $L__BB53_245;

st.global.f32 [%rd27], %f1812;

$L__BB53_245:
@%p8 bra $L__BB53_247;

st.global.f32 [%rd27+128], %f1780;

$L__BB53_247:
@%p9 bra $L__BB53_249;

st.global.f32 [%rd27+256], %f1748;

$L__BB53_249:
@%p10 bra $L__BB53_251;

st.global.f32 [%rd27+384], %f1716;

$L__BB53_251:
add.s32 %r8693, %r11, 108;
setp.ge.s32 %p141, %r8693, %r48;
@%p141 bra $L__BB53_296;

add.s32 %r44, %r43, %r17;
add.s32 %r8694, %r12, %r44;
mul.wide.s32 %rd470, %r8694, 4;
add.s64 %rd28, %rd415, %rd470;
@%p7 bra $L__BB53_254;

st.global.f32 [%rd28], %f1811;

$L__BB53_254:
@%p8 bra $L__BB53_256;

st.global.f32 [%rd28+128], %f1779;

$L__BB53_256:
@%p9 bra $L__BB53_258;

st.global.f32 [%rd28+256], %f1747;

$L__BB53_258:
@%p10 bra $L__BB53_260;

st.global.f32 [%rd28+384], %f1715;

$L__BB53_260:
add.s32 %r8695, %r11, 112;
setp.ge.s32 %p146, %r8695, %r48;
@%p146 bra $L__BB53_296;

add.s32 %r45, %r44, %r17;
add.s32 %r8696, %r12, %r45;
mul.wide.s32 %rd472, %r8696, 4;
add.s64 %rd29, %rd415, %rd472;
@%p7 bra $L__BB53_263;

st.global.f32 [%rd29], %f1810;

$L__BB53_263:
@%p8 bra $L__BB53_265;

st.global.f32 [%rd29+128], %f1778;

$L__BB53_265:
@%p9 bra $L__BB53_267;

st.global.f32 [%rd29+256], %f1746;

$L__BB53_267:
@%p10 bra $L__BB53_269;

st.global.f32 [%rd29+384], %f1714;

$L__BB53_269:
add.s32 %r8697, %r11, 116;
setp.ge.s32 %p151, %r8697, %r48;
@%p151 bra $L__BB53_296;

add.s32 %r46, %r45, %r17;
add.s32 %r8698, %r12, %r46;
mul.wide.s32 %rd474, %r8698, 4;
add.s64 %rd30, %rd415, %rd474;
@%p7 bra $L__BB53_272;

st.global.f32 [%rd30], %f1809;

$L__BB53_272:
@%p8 bra $L__BB53_274;

st.global.f32 [%rd30+128], %f1777;

$L__BB53_274:
@%p9 bra $L__BB53_276;

st.global.f32 [%rd30+256], %f1745;

$L__BB53_276:
@%p10 bra $L__BB53_278;

st.global.f32 [%rd30+384], %f1713;

$L__BB53_278:
add.s32 %r8699, %r11, 120;
setp.ge.s32 %p156, %r8699, %r48;
@%p156 bra $L__BB53_296;

add.s32 %r47, %r46, %r17;
add.s32 %r8700, %r12, %r47;
mul.wide.s32 %rd476, %r8700, 4;
add.s64 %rd31, %rd415, %rd476;
@%p7 bra $L__BB53_281;

st.global.f32 [%rd31], %f1808;

$L__BB53_281:
@%p8 bra $L__BB53_283;

st.global.f32 [%rd31+128], %f1776;

$L__BB53_283:
@%p9 bra $L__BB53_285;

st.global.f32 [%rd31+256], %f1744;

$L__BB53_285:
@%p10 bra $L__BB53_287;

st.global.f32 [%rd31+384], %f1712;

$L__BB53_287:
add.s32 %r8701, %r11, 124;
setp.ge.s32 %p161, %r8701, %r48;
@%p161 bra $L__BB53_296;

add.s32 %r8702, %r47, %r17;
add.s32 %r8703, %r12, %r8702;
mul.wide.s32 %rd478, %r8703, 4;
add.s64 %rd32, %rd415, %rd478;
@%p7 bra $L__BB53_290;

st.global.f32 [%rd32], %f1807;

$L__BB53_290:
@%p8 bra $L__BB53_292;

st.global.f32 [%rd32+128], %f1775;

$L__BB53_292:
@%p9 bra $L__BB53_294;

st.global.f32 [%rd32+256], %f1743;

$L__BB53_294:
@%p10 bra $L__BB53_296;

st.global.f32 [%rd32+384], %f1711;

$L__BB53_296:
ret;

}
