.entry _Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii
.param .u64 _Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_0,
.param .u64 _Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_1,
.param .u64 _Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_2,
.param .u32 _Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_3,
.param .u32 _Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_4,
.param .u32 _Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_5,
.param .u32 _Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_6,
.param .u32 _Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_7
)
{
.reg .pred %p<166>;
.reg .b16 %rs<139>;
.reg .f32 %f<1967>;
.reg .b32 %r<9017>;
.reg .b64 %rd<509>;

	.shared .align 4 .b8 _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a69mul_mat_qILi256ELi4ELi16ELb0E10block_q3_KLi128ELi128ELi4EXadL_ZNS_19allocate_tiles_q3_KILi128EEEvPPiPP7__half2S4_S4_EEXadL_ZNS_15load_tiles_q3_KILi128ELi4ELb1EEEvPKvS3_S6_S3_S3_RKiSC_SC_SC_EELi2EXadL_ZNS_25vec_dot_q3_K_q8_1_mul_matEPSB_PKS5_SD_SD_SD_SF_SC_SC_SC_EEEEvSA_SA_PfiiiiiE9tile_y_qs[16384];

	.shared .align 4 .b8 _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a69mul_mat_qILi256ELi4ELi16ELb0E10block_q3_KLi128ELi128ELi4EXadL_ZNS_19allocate_tiles_q3_KILi128EEEvPPiPP7__half2S4_S4_EEXadL_ZNS_15load_tiles_q3_KILi128ELi4ELb1EEEvPKvS3_S6_S3_S3_RKiSC_SC_SC_EELi2EXadL_ZNS_25vec_dot_q3_K_q8_1_mul_matEPSB_PKS5_SD_SD_SD_SF_SC_SC_SC_EEEEvSA_SA_PfiiiiiE9tile_y_ds[2048];

ld.param.u64 %rd33, [_Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_0];
ld.param.u64 %rd34, [_Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_1];
ld.param.u32 %r78, [_Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_3];
ld.param.u32 %r74, [_Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_4];
ld.param.u32 %r75, [_Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_5];
ld.param.u32 %r76, [_Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_6];
shr.s32 %r79, %r78, 31;
shr.u32 %r80, %r79, 24;
add.s32 %r81, %r78, %r80;
shr.s32 %r1, %r81, 8;
setp.gt.s32 %p1, %r78, 255;
@%p1 bra $L__BB54_2;
bra.uni $L__BB54_1;

$L__BB54_2:
shr.s32 %r83, %r76, 31;
shr.u32 %r84, %r83, 27;
add.s32 %r85, %r76, %r84;
shr.s32 %r2, %r85, 5;
mov.u32 %r86, %tid.y;
mov.u32 %r87, %ctaid.x;
shl.b32 %r88, %r87, 7;
not.b32 %r89, %r88;
add.s32 %r90, %r89, %r74;
mov.u32 %r91, %tid.x;
shr.u32 %r92, %r91, 4;
and.b32 %r93, %r91, 15;
and.b32 %r94, %r91, 1;
shl.b32 %r95, %r86, 4;
shr.u32 %r96, %r91, 1;
add.s32 %r97, %r96, %r95;
shl.b32 %r98, %r86, 2;
shr.u32 %r99, %r91, 3;
add.s32 %r100, %r99, %r98;
and.b32 %r101, %r91, 7;
min.s32 %r102, %r97, %r90;
shl.b32 %r103, %r102, 1;
shr.s32 %r104, %r102, 31;
shr.u32 %r105, %r104, 28;
add.s32 %r106, %r102, %r105;
shr.s32 %r107, %r106, 4;
add.s32 %r108, %r107, %r94;
add.s32 %r109, %r108, %r103;
shl.b32 %r110, %r109, 2;
mov.u32 %r111, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a619allocate_tiles_q3_KILi128EEEvPPiPP7__half2S2_S2_E9tile_x_dm;
add.s32 %r3, %r111, %r110;
add.s32 %r112, %r97, 64;
min.s32 %r113, %r112, %r90;
shl.b32 %r114, %r113, 1;
shr.s32 %r115, %r113, 31;
shr.u32 %r116, %r115, 28;
add.s32 %r117, %r113, %r116;
shr.s32 %r118, %r117, 4;
add.s32 %r119, %r118, %r94;
add.s32 %r120, %r119, %r114;
shl.b32 %r121, %r120, 2;
add.s32 %r4, %r111, %r121;
shl.b32 %r122, %r86, 1;
add.s32 %r123, %r92, %r122;
min.s32 %r124, %r123, %r90;
shl.b32 %r125, %r124, 4;
shr.u32 %r126, %r124, 31;
add.s32 %r127, %r124, %r126;
shr.u32 %r128, %r127, 1;
add.s32 %r129, %r128, %r93;
add.s32 %r130, %r129, %r125;
shl.b32 %r131, %r130, 2;
mov.u32 %r132, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a619allocate_tiles_q3_KILi128EEEvPPiPP7__half2S2_S2_E9tile_x_qh;
add.s32 %r5, %r132, %r131;
add.s32 %r133, %r123, 8;
min.s32 %r134, %r133, %r90;
shl.b32 %r135, %r134, 4;
shr.u32 %r136, %r134, 31;
add.s32 %r137, %r134, %r136;
shr.u32 %r138, %r137, 1;
add.s32 %r139, %r138, %r93;
add.s32 %r140, %r139, %r135;
shl.b32 %r141, %r140, 2;
add.s32 %r6, %r132, %r141;
add.s32 %r142, %r123, 16;
min.s32 %r143, %r142, %r90;
shl.b32 %r144, %r143, 4;
shr.u32 %r145, %r143, 31;
add.s32 %r146, %r143, %r145;
shr.u32 %r147, %r146, 1;
add.s32 %r148, %r147, %r93;
add.s32 %r149, %r148, %r144;
shl.b32 %r150, %r149, 2;
add.s32 %r7, %r132, %r150;
add.s32 %r151, %r123, 24;
min.s32 %r152, %r151, %r90;
shl.b32 %r153, %r152, 4;
shr.u32 %r154, %r152, 31;
add.s32 %r155, %r152, %r154;
shr.u32 %r156, %r155, 1;
add.s32 %r157, %r156, %r93;
add.s32 %r158, %r157, %r153;
shl.b32 %r159, %r158, 2;
add.s32 %r8, %r132, %r159;
add.s32 %r160, %r123, 32;
min.s32 %r161, %r160, %r90;
shl.b32 %r162, %r161, 4;
shr.u32 %r163, %r161, 31;
add.s32 %r164, %r161, %r163;
shr.u32 %r165, %r164, 1;
add.s32 %r166, %r165, %r93;
add.s32 %r167, %r166, %r162;
shl.b32 %r168, %r167, 2;
add.s32 %r9, %r132, %r168;
add.s32 %r169, %r123, 40;
min.s32 %r170, %r169, %r90;
shl.b32 %r171, %r170, 4;
shr.u32 %r172, %r170, 31;
add.s32 %r173, %r170, %r172;
shr.u32 %r174, %r173, 1;
add.s32 %r175, %r174, %r93;
add.s32 %r176, %r175, %r171;
shl.b32 %r177, %r176, 2;
add.s32 %r10, %r132, %r177;
add.s32 %r178, %r123, 48;
min.s32 %r179, %r178, %r90;
shl.b32 %r180, %r179, 4;
shr.u32 %r181, %r179, 31;
add.s32 %r182, %r179, %r181;
shr.u32 %r183, %r182, 1;
add.s32 %r184, %r183, %r93;
add.s32 %r185, %r184, %r180;
shl.b32 %r186, %r185, 2;
add.s32 %r11, %r132, %r186;
add.s32 %r187, %r123, 56;
min.s32 %r188, %r187, %r90;
shl.b32 %r189, %r188, 4;
shr.u32 %r190, %r188, 31;
add.s32 %r191, %r188, %r190;
shr.u32 %r192, %r191, 1;
add.s32 %r193, %r192, %r93;
add.s32 %r194, %r193, %r189;
shl.b32 %r195, %r194, 2;
add.s32 %r12, %r132, %r195;
add.s32 %r196, %r123, 64;
min.s32 %r197, %r196, %r90;
shl.b32 %r198, %r197, 4;
shr.u32 %r199, %r197, 31;
add.s32 %r200, %r197, %r199;
shr.u32 %r201, %r200, 1;
add.s32 %r202, %r201, %r93;
add.s32 %r203, %r202, %r198;
shl.b32 %r204, %r203, 2;
add.s32 %r13, %r132, %r204;
add.s32 %r205, %r123, 72;
min.s32 %r206, %r205, %r90;
shl.b32 %r207, %r206, 4;
shr.u32 %r208, %r206, 31;
add.s32 %r209, %r206, %r208;
shr.u32 %r210, %r209, 1;
add.s32 %r211, %r210, %r93;
add.s32 %r212, %r211, %r207;
shl.b32 %r213, %r212, 2;
add.s32 %r14, %r132, %r213;
add.s32 %r214, %r123, 80;
min.s32 %r215, %r214, %r90;
shl.b32 %r216, %r215, 4;
shr.u32 %r217, %r215, 31;
add.s32 %r218, %r215, %r217;
shr.u32 %r219, %r218, 1;
add.s32 %r220, %r219, %r93;
add.s32 %r221, %r220, %r216;
shl.b32 %r222, %r221, 2;
add.s32 %r15, %r132, %r222;
add.s32 %r223, %r123, 88;
min.s32 %r224, %r223, %r90;
shl.b32 %r225, %r224, 4;
shr.u32 %r226, %r224, 31;
add.s32 %r227, %r224, %r226;
shr.u32 %r228, %r227, 1;
add.s32 %r229, %r228, %r93;
add.s32 %r230, %r229, %r225;
shl.b32 %r231, %r230, 2;
add.s32 %r16, %r132, %r231;
add.s32 %r232, %r123, 96;
min.s32 %r233, %r232, %r90;
shl.b32 %r234, %r233, 4;
shr.u32 %r235, %r233, 31;
add.s32 %r236, %r233, %r235;
shr.u32 %r237, %r236, 1;
add.s32 %r238, %r237, %r93;
add.s32 %r239, %r238, %r234;
shl.b32 %r240, %r239, 2;
add.s32 %r17, %r132, %r240;
add.s32 %r241, %r123, 104;
min.s32 %r242, %r241, %r90;
shl.b32 %r243, %r242, 4;
shr.u32 %r244, %r242, 31;
add.s32 %r245, %r242, %r244;
shr.u32 %r246, %r245, 1;
add.s32 %r247, %r246, %r93;
add.s32 %r248, %r247, %r243;
shl.b32 %r249, %r248, 2;
add.s32 %r18, %r132, %r249;
add.s32 %r250, %r123, 112;
min.s32 %r251, %r250, %r90;
shl.b32 %r252, %r251, 4;
shr.u32 %r253, %r251, 31;
add.s32 %r254, %r251, %r253;
shr.u32 %r255, %r254, 1;
add.s32 %r256, %r255, %r93;
add.s32 %r257, %r256, %r252;
shl.b32 %r258, %r257, 2;
add.s32 %r19, %r132, %r258;
add.s32 %r259, %r123, 120;
min.s32 %r260, %r259, %r90;
shl.b32 %r261, %r260, 4;
shr.u32 %r262, %r260, 31;
add.s32 %r263, %r260, %r262;
shr.u32 %r264, %r263, 1;
add.s32 %r265, %r264, %r93;
add.s32 %r266, %r265, %r261;
shl.b32 %r267, %r266, 2;
add.s32 %r20, %r132, %r267;
min.s32 %r268, %r100, %r90;
shl.b32 %r269, %r268, 3;
shr.s32 %r270, %r268, 31;
shr.u32 %r271, %r270, 30;
add.s32 %r272, %r268, %r271;
shr.u32 %r273, %r272, 2;
add.s32 %r274, %r273, %r101;
add.s32 %r275, %r274, %r269;
shl.b32 %r276, %r275, 2;
mov.u32 %r277, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a619allocate_tiles_q3_KILi128EEEvPPiPP7__half2S2_S2_E9tile_x_sc;
add.s32 %r21, %r277, %r276;
add.s32 %r278, %r100, 16;
min.s32 %r279, %r278, %r90;
shl.b32 %r280, %r279, 3;
shr.s32 %r281, %r279, 31;
shr.u32 %r282, %r281, 30;
add.s32 %r283, %r279, %r282;
shr.u32 %r284, %r283, 2;
add.s32 %r285, %r284, %r101;
add.s32 %r286, %r285, %r280;
shl.b32 %r287, %r286, 2;
add.s32 %r22, %r277, %r287;
add.s32 %r288, %r100, 32;
min.s32 %r289, %r288, %r90;
shl.b32 %r290, %r289, 3;
shr.s32 %r291, %r289, 31;
shr.u32 %r292, %r291, 30;
add.s32 %r293, %r289, %r292;
shr.u32 %r294, %r293, 2;
add.s32 %r295, %r294, %r101;
add.s32 %r296, %r295, %r290;
shl.b32 %r297, %r296, 2;
add.s32 %r23, %r277, %r297;
add.s32 %r298, %r100, 48;
min.s32 %r299, %r298, %r90;
shl.b32 %r300, %r299, 3;
shr.s32 %r301, %r299, 31;
shr.u32 %r302, %r301, 30;
add.s32 %r303, %r299, %r302;
shr.u32 %r304, %r303, 2;
add.s32 %r305, %r304, %r101;
add.s32 %r306, %r305, %r300;
shl.b32 %r307, %r306, 2;
add.s32 %r24, %r277, %r307;
add.s32 %r308, %r100, 64;
min.s32 %r309, %r308, %r90;
shl.b32 %r310, %r309, 3;
shr.s32 %r311, %r309, 31;
shr.u32 %r312, %r311, 30;
add.s32 %r313, %r309, %r312;
shr.u32 %r314, %r313, 2;
add.s32 %r315, %r314, %r101;
add.s32 %r316, %r315, %r310;
shl.b32 %r317, %r316, 2;
add.s32 %r25, %r277, %r317;
add.s32 %r318, %r100, 80;
min.s32 %r319, %r318, %r90;
shl.b32 %r320, %r319, 3;
shr.s32 %r321, %r319, 31;
shr.u32 %r322, %r321, 30;
add.s32 %r323, %r319, %r322;
shr.u32 %r324, %r323, 2;
add.s32 %r325, %r324, %r101;
add.s32 %r326, %r325, %r320;
shl.b32 %r327, %r326, 2;
add.s32 %r26, %r277, %r327;
add.s32 %r328, %r100, 96;
min.s32 %r329, %r328, %r90;
shl.b32 %r330, %r329, 3;
shr.s32 %r331, %r329, 31;
shr.u32 %r332, %r331, 30;
add.s32 %r333, %r329, %r332;
shr.u32 %r334, %r333, 2;
add.s32 %r335, %r334, %r101;
add.s32 %r336, %r335, %r330;
shl.b32 %r337, %r336, 2;
add.s32 %r27, %r277, %r337;
add.s32 %r338, %r100, 112;
min.s32 %r339, %r338, %r90;
shl.b32 %r340, %r339, 3;
shr.s32 %r341, %r339, 31;
shr.u32 %r342, %r341, 30;
add.s32 %r343, %r339, %r342;
shr.u32 %r344, %r343, 2;
add.s32 %r345, %r344, %r101;
add.s32 %r346, %r345, %r340;
shl.b32 %r347, %r346, 2;
add.s32 %r28, %r277, %r347;
mov.u32 %r82, 0;
mov.f32 %f1711, 0f00000000;
cvta.to.global.u64 %rd36, %rd33;
cvta.to.global.u64 %rd337, %rd34;
mov.f32 %f1712, %f1711;
mov.f32 %f1713, %f1711;
mov.f32 %f1714, %f1711;
mov.f32 %f1715, %f1711;
mov.f32 %f1716, %f1711;
mov.f32 %f1717, %f1711;
mov.f32 %f1718, %f1711;
mov.f32 %f1719, %f1711;
mov.f32 %f1720, %f1711;
mov.f32 %f1721, %f1711;
mov.f32 %f1722, %f1711;
mov.f32 %f1723, %f1711;
mov.f32 %f1724, %f1711;
mov.f32 %f1725, %f1711;
mov.f32 %f1726, %f1711;
mov.f32 %f1727, %f1711;
mov.f32 %f1728, %f1711;
mov.f32 %f1729, %f1711;
mov.f32 %f1730, %f1711;
mov.f32 %f1731, %f1711;
mov.f32 %f1732, %f1711;
mov.f32 %f1733, %f1711;
mov.f32 %f1734, %f1711;
mov.f32 %f1735, %f1711;
mov.f32 %f1736, %f1711;
mov.f32 %f1737, %f1711;
mov.f32 %f1738, %f1711;
mov.f32 %f1739, %f1711;
mov.f32 %f1740, %f1711;
mov.f32 %f1741, %f1711;
mov.f32 %f1742, %f1711;
mov.f32 %f1743, %f1711;
mov.f32 %f1744, %f1711;
mov.f32 %f1745, %f1711;
mov.f32 %f1746, %f1711;
mov.f32 %f1747, %f1711;
mov.f32 %f1748, %f1711;
mov.f32 %f1749, %f1711;
mov.f32 %f1750, %f1711;
mov.f32 %f1751, %f1711;
mov.f32 %f1752, %f1711;
mov.f32 %f1753, %f1711;
mov.f32 %f1754, %f1711;
mov.f32 %f1755, %f1711;
mov.f32 %f1756, %f1711;
mov.f32 %f1757, %f1711;
mov.f32 %f1758, %f1711;
mov.f32 %f1759, %f1711;
mov.f32 %f1760, %f1711;
mov.f32 %f1761, %f1711;
mov.f32 %f1762, %f1711;
mov.f32 %f1763, %f1711;
mov.f32 %f1764, %f1711;
mov.f32 %f1765, %f1711;
mov.f32 %f1766, %f1711;
mov.f32 %f1767, %f1711;
mov.f32 %f1768, %f1711;
mov.f32 %f1769, %f1711;
mov.f32 %f1770, %f1711;
mov.f32 %f1771, %f1711;
mov.f32 %f1772, %f1711;
mov.f32 %f1773, %f1711;
mov.f32 %f1774, %f1711;
mov.f32 %f1775, %f1711;
mov.f32 %f1776, %f1711;
mov.f32 %f1777, %f1711;
mov.f32 %f1778, %f1711;
mov.f32 %f1779, %f1711;
mov.f32 %f1780, %f1711;
mov.f32 %f1781, %f1711;
mov.f32 %f1782, %f1711;
mov.f32 %f1783, %f1711;
mov.f32 %f1784, %f1711;
mov.f32 %f1785, %f1711;
mov.f32 %f1786, %f1711;
mov.f32 %f1787, %f1711;
mov.f32 %f1788, %f1711;
mov.f32 %f1789, %f1711;
mov.f32 %f1790, %f1711;
mov.f32 %f1791, %f1711;
mov.f32 %f1792, %f1711;
mov.f32 %f1793, %f1711;
mov.f32 %f1794, %f1711;
mov.f32 %f1795, %f1711;
mov.f32 %f1796, %f1711;
mov.f32 %f1797, %f1711;
mov.f32 %f1798, %f1711;
mov.f32 %f1799, %f1711;
mov.f32 %f1800, %f1711;
mov.f32 %f1801, %f1711;
mov.f32 %f1802, %f1711;
mov.f32 %f1803, %f1711;
mov.f32 %f1804, %f1711;
mov.f32 %f1805, %f1711;
mov.f32 %f1806, %f1711;
mov.f32 %f1807, %f1711;
mov.f32 %f1808, %f1711;
mov.f32 %f1809, %f1711;
mov.f32 %f1810, %f1711;
mov.f32 %f1811, %f1711;
mov.f32 %f1812, %f1711;
mov.f32 %f1813, %f1711;
mov.f32 %f1814, %f1711;
mov.f32 %f1815, %f1711;
mov.f32 %f1816, %f1711;
mov.f32 %f1817, %f1711;
mov.f32 %f1818, %f1711;
mov.f32 %f1819, %f1711;
mov.f32 %f1820, %f1711;
mov.f32 %f1821, %f1711;
mov.f32 %f1822, %f1711;
mov.f32 %f1823, %f1711;
mov.f32 %f1824, %f1711;
mov.f32 %f1825, %f1711;
mov.f32 %f1826, %f1711;
mov.f32 %f1827, %f1711;
mov.f32 %f1828, %f1711;
mov.f32 %f1829, %f1711;
mov.f32 %f1830, %f1711;
mov.f32 %f1831, %f1711;
mov.f32 %f1832, %f1711;
mov.f32 %f1833, %f1711;
mov.f32 %f1834, %f1711;
mov.f32 %f1835, %f1711;
mov.f32 %f1836, %f1711;
mov.f32 %f1837, %f1711;
mov.f32 %f1838, %f1711;
mov.u32 %r9014, %r82;

$L__BB54_3:
mul.lo.s32 %r377, %r1, %r88;
cvt.s64.s32 %rd37, %r377;
cvt.s64.s32 %rd38, %r9014;
add.s64 %rd39, %rd38, %rd37;
mul.lo.s64 %rd40, %rd39, 110;
add.s64 %rd41, %rd36, %rd40;
min.s32 %r380, %r86, %r90;
mul.lo.s32 %r381, %r380, %r1;
cvt.s64.s32 %rd42, %r381;
cvt.u64.u32 %rd43, %r92;
add.s64 %rd44, %rd42, %rd43;
shl.b32 %r383, %r91, 2;
and.b32 %r384, %r383, 60;
cvt.u64.u32 %rd45, %r384;
mul.lo.s64 %rd46, %rd44, 110;
add.s64 %rd47, %rd41, %rd46;
add.s64 %rd48, %rd47, %rd45;
ld.global.nc.u16 %rs3, [%rd48+32];
ld.global.nc.u16 %rs4, [%rd48+34];
mov.b32 %r385, {%rs3, %rs4};
mad.lo.s32 %r386, %r380, 33, %r91;
shl.b32 %r387, %r386, 2;
mov.u32 %r388, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a619allocate_tiles_q3_KILi128EEEvPPiPP7__half2S2_S2_E9tile_x_ql;
add.s32 %r389, %r388, %r387;
st.shared.u32 [%r389], %r385;
add.s32 %r390, %r86, 4;
min.s32 %r391, %r390, %r90;
mul.lo.s32 %r392, %r391, %r1;
cvt.s64.s32 %rd49, %r392;
add.s64 %rd50, %rd49, %rd43;
mul.lo.s64 %rd51, %rd50, 110;
add.s64 %rd52, %rd41, %rd51;
add.s64 %rd53, %rd52, %rd45;
ld.global.nc.u16 %rs5, [%rd53+32];
ld.global.nc.u16 %rs6, [%rd53+34];
mov.b32 %r393, {%rs5, %rs6};
mad.lo.s32 %r394, %r391, 33, %r91;
shl.b32 %r395, %r394, 2;
add.s32 %r396, %r388, %r395;
st.shared.u32 [%r396], %r393;
add.s32 %r397, %r86, 8;
min.s32 %r398, %r397, %r90;
mul.lo.s32 %r399, %r398, %r1;
cvt.s64.s32 %rd54, %r399;
add.s64 %rd55, %rd54, %rd43;
mul.lo.s64 %rd56, %rd55, 110;
add.s64 %rd57, %rd41, %rd56;
add.s64 %rd58, %rd57, %rd45;
ld.global.nc.u16 %rs7, [%rd58+32];
ld.global.nc.u16 %rs8, [%rd58+34];
mov.b32 %r400, {%rs7, %rs8};
mad.lo.s32 %r401, %r398, 33, %r91;
shl.b32 %r402, %r401, 2;
add.s32 %r403, %r388, %r402;
st.shared.u32 [%r403], %r400;
add.s32 %r404, %r86, 12;
min.s32 %r405, %r404, %r90;
mul.lo.s32 %r406, %r405, %r1;
cvt.s64.s32 %rd59, %r406;
add.s64 %rd60, %rd59, %rd43;
mul.lo.s64 %rd61, %rd60, 110;
add.s64 %rd62, %rd41, %rd61;
add.s64 %rd63, %rd62, %rd45;
ld.global.nc.u16 %rs9, [%rd63+32];
ld.global.nc.u16 %rs10, [%rd63+34];
mov.b32 %r407, {%rs9, %rs10};
mad.lo.s32 %r408, %r405, 33, %r91;
shl.b32 %r409, %r408, 2;
add.s32 %r410, %r388, %r409;
st.shared.u32 [%r410], %r407;
add.s32 %r411, %r86, 16;
min.s32 %r412, %r411, %r90;
mul.lo.s32 %r413, %r412, %r1;
cvt.s64.s32 %rd64, %r413;
add.s64 %rd65, %rd64, %rd43;
mul.lo.s64 %rd66, %rd65, 110;
add.s64 %rd67, %rd41, %rd66;
add.s64 %rd68, %rd67, %rd45;
ld.global.nc.u16 %rs11, [%rd68+32];
ld.global.nc.u16 %rs12, [%rd68+34];
mov.b32 %r414, {%rs11, %rs12};
mad.lo.s32 %r415, %r412, 33, %r91;
shl.b32 %r416, %r415, 2;
add.s32 %r417, %r388, %r416;
st.shared.u32 [%r417], %r414;
add.s32 %r418, %r86, 20;
min.s32 %r419, %r418, %r90;
mul.lo.s32 %r420, %r419, %r1;
cvt.s64.s32 %rd69, %r420;
add.s64 %rd70, %rd69, %rd43;
mul.lo.s64 %rd71, %rd70, 110;
add.s64 %rd72, %rd41, %rd71;
add.s64 %rd73, %rd72, %rd45;
ld.global.nc.u16 %rs13, [%rd73+32];
ld.global.nc.u16 %rs14, [%rd73+34];
mov.b32 %r421, {%rs13, %rs14};
mad.lo.s32 %r422, %r419, 33, %r91;
shl.b32 %r423, %r422, 2;
add.s32 %r424, %r388, %r423;
st.shared.u32 [%r424], %r421;
add.s32 %r425, %r86, 24;
min.s32 %r426, %r425, %r90;
mul.lo.s32 %r427, %r426, %r1;
cvt.s64.s32 %rd74, %r427;
add.s64 %rd75, %rd74, %rd43;
mul.lo.s64 %rd76, %rd75, 110;
add.s64 %rd77, %rd41, %rd76;
add.s64 %rd78, %rd77, %rd45;
ld.global.nc.u16 %rs15, [%rd78+32];
ld.global.nc.u16 %rs16, [%rd78+34];
mov.b32 %r428, {%rs15, %rs16};
mad.lo.s32 %r429, %r426, 33, %r91;
shl.b32 %r430, %r429, 2;
add.s32 %r431, %r388, %r430;
st.shared.u32 [%r431], %r428;
add.s32 %r432, %r86, 28;
min.s32 %r433, %r432, %r90;
mul.lo.s32 %r434, %r433, %r1;
cvt.s64.s32 %rd79, %r434;
add.s64 %rd80, %rd79, %rd43;
mul.lo.s64 %rd81, %rd80, 110;
add.s64 %rd82, %rd41, %rd81;
add.s64 %rd83, %rd82, %rd45;
ld.global.nc.u16 %rs17, [%rd83+32];
ld.global.nc.u16 %rs18, [%rd83+34];
mov.b32 %r435, {%rs17, %rs18};
mad.lo.s32 %r436, %r433, 33, %r91;
shl.b32 %r437, %r436, 2;
add.s32 %r438, %r388, %r437;
st.shared.u32 [%r438], %r435;
add.s32 %r439, %r86, 32;
min.s32 %r440, %r439, %r90;
mul.lo.s32 %r441, %r440, %r1;
cvt.s64.s32 %rd84, %r441;
add.s64 %rd85, %rd84, %rd43;
mul.lo.s64 %rd86, %rd85, 110;
add.s64 %rd87, %rd41, %rd86;
add.s64 %rd88, %rd87, %rd45;
ld.global.nc.u16 %rs19, [%rd88+32];
ld.global.nc.u16 %rs20, [%rd88+34];
mov.b32 %r442, {%rs19, %rs20};
mad.lo.s32 %r443, %r440, 33, %r91;
shl.b32 %r444, %r443, 2;
add.s32 %r445, %r388, %r444;
st.shared.u32 [%r445], %r442;
add.s32 %r446, %r86, 36;
min.s32 %r447, %r446, %r90;
mul.lo.s32 %r448, %r447, %r1;
cvt.s64.s32 %rd89, %r448;
add.s64 %rd90, %rd89, %rd43;
mul.lo.s64 %rd91, %rd90, 110;
add.s64 %rd92, %rd41, %rd91;
add.s64 %rd93, %rd92, %rd45;
ld.global.nc.u16 %rs21, [%rd93+32];
ld.global.nc.u16 %rs22, [%rd93+34];
mov.b32 %r449, {%rs21, %rs22};
mad.lo.s32 %r450, %r447, 33, %r91;
shl.b32 %r451, %r450, 2;
add.s32 %r452, %r388, %r451;
st.shared.u32 [%r452], %r449;
add.s32 %r453, %r86, 40;
min.s32 %r454, %r453, %r90;
mul.lo.s32 %r455, %r454, %r1;
cvt.s64.s32 %rd94, %r455;
add.s64 %rd95, %rd94, %rd43;
mul.lo.s64 %rd96, %rd95, 110;
add.s64 %rd97, %rd41, %rd96;
add.s64 %rd98, %rd97, %rd45;
ld.global.nc.u16 %rs23, [%rd98+32];
ld.global.nc.u16 %rs24, [%rd98+34];
mov.b32 %r456, {%rs23, %rs24};
mad.lo.s32 %r457, %r454, 33, %r91;
shl.b32 %r458, %r457, 2;
add.s32 %r459, %r388, %r458;
st.shared.u32 [%r459], %r456;
add.s32 %r460, %r86, 44;
min.s32 %r461, %r460, %r90;
mul.lo.s32 %r462, %r461, %r1;
cvt.s64.s32 %rd99, %r462;
add.s64 %rd100, %rd99, %rd43;
mul.lo.s64 %rd101, %rd100, 110;
add.s64 %rd102, %rd41, %rd101;
add.s64 %rd103, %rd102, %rd45;
ld.global.nc.u16 %rs25, [%rd103+32];
ld.global.nc.u16 %rs26, [%rd103+34];
mov.b32 %r463, {%rs25, %rs26};
mad.lo.s32 %r464, %r461, 33, %r91;
shl.b32 %r465, %r464, 2;
add.s32 %r466, %r388, %r465;
st.shared.u32 [%r466], %r463;
add.s32 %r467, %r86, 48;
min.s32 %r468, %r467, %r90;
mul.lo.s32 %r469, %r468, %r1;
cvt.s64.s32 %rd104, %r469;
add.s64 %rd105, %rd104, %rd43;
mul.lo.s64 %rd106, %rd105, 110;
add.s64 %rd107, %rd41, %rd106;
add.s64 %rd108, %rd107, %rd45;
ld.global.nc.u16 %rs27, [%rd108+32];
ld.global.nc.u16 %rs28, [%rd108+34];
mov.b32 %r470, {%rs27, %rs28};
mad.lo.s32 %r471, %r468, 33, %r91;
shl.b32 %r472, %r471, 2;
add.s32 %r473, %r388, %r472;
st.shared.u32 [%r473], %r470;
add.s32 %r474, %r86, 52;
min.s32 %r475, %r474, %r90;
mul.lo.s32 %r476, %r475, %r1;
cvt.s64.s32 %rd109, %r476;
add.s64 %rd110, %rd109, %rd43;
mul.lo.s64 %rd111, %rd110, 110;
add.s64 %rd112, %rd41, %rd111;
add.s64 %rd113, %rd112, %rd45;
ld.global.nc.u16 %rs29, [%rd113+32];
ld.global.nc.u16 %rs30, [%rd113+34];
mov.b32 %r477, {%rs29, %rs30};
mad.lo.s32 %r478, %r475, 33, %r91;
shl.b32 %r479, %r478, 2;
add.s32 %r480, %r388, %r479;
st.shared.u32 [%r480], %r477;
add.s32 %r481, %r86, 56;
min.s32 %r482, %r481, %r90;
mul.lo.s32 %r483, %r482, %r1;
cvt.s64.s32 %rd114, %r483;
add.s64 %rd115, %rd114, %rd43;
mul.lo.s64 %rd116, %rd115, 110;
add.s64 %rd117, %rd41, %rd116;
add.s64 %rd118, %rd117, %rd45;
ld.global.nc.u16 %rs31, [%rd118+32];
ld.global.nc.u16 %rs32, [%rd118+34];
mov.b32 %r484, {%rs31, %rs32};
mad.lo.s32 %r485, %r482, 33, %r91;
shl.b32 %r486, %r485, 2;
add.s32 %r487, %r388, %r486;
st.shared.u32 [%r487], %r484;
add.s32 %r488, %r86, 60;
min.s32 %r489, %r488, %r90;
mul.lo.s32 %r490, %r489, %r1;
cvt.s64.s32 %rd119, %r490;
add.s64 %rd120, %rd119, %rd43;
mul.lo.s64 %rd121, %rd120, 110;
add.s64 %rd122, %rd41, %rd121;
add.s64 %rd123, %rd122, %rd45;
ld.global.nc.u16 %rs33, [%rd123+32];
ld.global.nc.u16 %rs34, [%rd123+34];
mov.b32 %r491, {%rs33, %rs34};
mad.lo.s32 %r492, %r489, 33, %r91;
shl.b32 %r493, %r492, 2;
add.s32 %r494, %r388, %r493;
st.shared.u32 [%r494], %r491;
add.s32 %r495, %r86, 64;
min.s32 %r496, %r495, %r90;
mul.lo.s32 %r497, %r496, %r1;
cvt.s64.s32 %rd124, %r497;
add.s64 %rd125, %rd124, %rd43;
mul.lo.s64 %rd126, %rd125, 110;
add.s64 %rd127, %rd41, %rd126;
add.s64 %rd128, %rd127, %rd45;
ld.global.nc.u16 %rs35, [%rd128+32];
ld.global.nc.u16 %rs36, [%rd128+34];
mov.b32 %r498, {%rs35, %rs36};
mad.lo.s32 %r499, %r496, 33, %r91;
shl.b32 %r500, %r499, 2;
add.s32 %r501, %r388, %r500;
st.shared.u32 [%r501], %r498;
add.s32 %r502, %r86, 68;
min.s32 %r503, %r502, %r90;
mul.lo.s32 %r504, %r503, %r1;
cvt.s64.s32 %rd129, %r504;
add.s64 %rd130, %rd129, %rd43;
mul.lo.s64 %rd131, %rd130, 110;
add.s64 %rd132, %rd41, %rd131;
add.s64 %rd133, %rd132, %rd45;
ld.global.nc.u16 %rs37, [%rd133+32];
ld.global.nc.u16 %rs38, [%rd133+34];
mov.b32 %r505, {%rs37, %rs38};
mad.lo.s32 %r506, %r503, 33, %r91;
shl.b32 %r507, %r506, 2;
add.s32 %r508, %r388, %r507;
st.shared.u32 [%r508], %r505;
add.s32 %r509, %r86, 72;
min.s32 %r510, %r509, %r90;
mul.lo.s32 %r511, %r510, %r1;
cvt.s64.s32 %rd134, %r511;
add.s64 %rd135, %rd134, %rd43;
mul.lo.s64 %rd136, %rd135, 110;
add.s64 %rd137, %rd41, %rd136;
add.s64 %rd138, %rd137, %rd45;
ld.global.nc.u16 %rs39, [%rd138+32];
ld.global.nc.u16 %rs40, [%rd138+34];
mov.b32 %r512, {%rs39, %rs40};
mad.lo.s32 %r513, %r510, 33, %r91;
shl.b32 %r514, %r513, 2;
add.s32 %r515, %r388, %r514;
st.shared.u32 [%r515], %r512;
add.s32 %r516, %r86, 76;
min.s32 %r517, %r516, %r90;
mul.lo.s32 %r518, %r517, %r1;
cvt.s64.s32 %rd139, %r518;
add.s64 %rd140, %rd139, %rd43;
mul.lo.s64 %rd141, %rd140, 110;
add.s64 %rd142, %rd41, %rd141;
add.s64 %rd143, %rd142, %rd45;
ld.global.nc.u16 %rs41, [%rd143+32];
ld.global.nc.u16 %rs42, [%rd143+34];
mov.b32 %r519, {%rs41, %rs42};
mad.lo.s32 %r520, %r517, 33, %r91;
shl.b32 %r521, %r520, 2;
add.s32 %r522, %r388, %r521;
st.shared.u32 [%r522], %r519;
add.s32 %r523, %r86, 80;
min.s32 %r524, %r523, %r90;
mul.lo.s32 %r525, %r524, %r1;
cvt.s64.s32 %rd144, %r525;
add.s64 %rd145, %rd144, %rd43;
mul.lo.s64 %rd146, %rd145, 110;
add.s64 %rd147, %rd41, %rd146;
add.s64 %rd148, %rd147, %rd45;
ld.global.nc.u16 %rs43, [%rd148+32];
ld.global.nc.u16 %rs44, [%rd148+34];
mov.b32 %r526, {%rs43, %rs44};
mad.lo.s32 %r527, %r524, 33, %r91;
shl.b32 %r528, %r527, 2;
add.s32 %r529, %r388, %r528;
st.shared.u32 [%r529], %r526;
add.s32 %r530, %r86, 84;
min.s32 %r531, %r530, %r90;
mul.lo.s32 %r532, %r531, %r1;
cvt.s64.s32 %rd149, %r532;
add.s64 %rd150, %rd149, %rd43;
mul.lo.s64 %rd151, %rd150, 110;
add.s64 %rd152, %rd41, %rd151;
add.s64 %rd153, %rd152, %rd45;
ld.global.nc.u16 %rs45, [%rd153+32];
ld.global.nc.u16 %rs46, [%rd153+34];
mov.b32 %r533, {%rs45, %rs46};
mad.lo.s32 %r534, %r531, 33, %r91;
shl.b32 %r535, %r534, 2;
add.s32 %r536, %r388, %r535;
st.shared.u32 [%r536], %r533;
add.s32 %r537, %r86, 88;
min.s32 %r538, %r537, %r90;
mul.lo.s32 %r539, %r538, %r1;
cvt.s64.s32 %rd154, %r539;
add.s64 %rd155, %rd154, %rd43;
mul.lo.s64 %rd156, %rd155, 110;
add.s64 %rd157, %rd41, %rd156;
add.s64 %rd158, %rd157, %rd45;
ld.global.nc.u16 %rs47, [%rd158+32];
ld.global.nc.u16 %rs48, [%rd158+34];
mov.b32 %r540, {%rs47, %rs48};
mad.lo.s32 %r541, %r538, 33, %r91;
shl.b32 %r542, %r541, 2;
add.s32 %r543, %r388, %r542;
st.shared.u32 [%r543], %r540;
add.s32 %r544, %r86, 92;
min.s32 %r545, %r544, %r90;
mul.lo.s32 %r546, %r545, %r1;
cvt.s64.s32 %rd159, %r546;
add.s64 %rd160, %rd159, %rd43;
mul.lo.s64 %rd161, %rd160, 110;
add.s64 %rd162, %rd41, %rd161;
add.s64 %rd163, %rd162, %rd45;
ld.global.nc.u16 %rs49, [%rd163+32];
ld.global.nc.u16 %rs50, [%rd163+34];
mov.b32 %r547, {%rs49, %rs50};
mad.lo.s32 %r548, %r545, 33, %r91;
shl.b32 %r549, %r548, 2;
add.s32 %r550, %r388, %r549;
st.shared.u32 [%r550], %r547;
add.s32 %r551, %r86, 96;
min.s32 %r552, %r551, %r90;
mul.lo.s32 %r553, %r552, %r1;
cvt.s64.s32 %rd164, %r553;
add.s64 %rd165, %rd164, %rd43;
mul.lo.s64 %rd166, %rd165, 110;
add.s64 %rd167, %rd41, %rd166;
add.s64 %rd168, %rd167, %rd45;
ld.global.nc.u16 %rs51, [%rd168+32];
ld.global.nc.u16 %rs52, [%rd168+34];
mov.b32 %r554, {%rs51, %rs52};
mad.lo.s32 %r555, %r552, 33, %r91;
shl.b32 %r556, %r555, 2;
add.s32 %r557, %r388, %r556;
st.shared.u32 [%r557], %r554;
add.s32 %r558, %r86, 100;
min.s32 %r559, %r558, %r90;
mul.lo.s32 %r560, %r559, %r1;
cvt.s64.s32 %rd169, %r560;
add.s64 %rd170, %rd169, %rd43;
mul.lo.s64 %rd171, %rd170, 110;
add.s64 %rd172, %rd41, %rd171;
add.s64 %rd173, %rd172, %rd45;
ld.global.nc.u16 %rs53, [%rd173+32];
ld.global.nc.u16 %rs54, [%rd173+34];
mov.b32 %r561, {%rs53, %rs54};
mad.lo.s32 %r562, %r559, 33, %r91;
shl.b32 %r563, %r562, 2;
add.s32 %r564, %r388, %r563;
st.shared.u32 [%r564], %r561;
add.s32 %r565, %r86, 104;
min.s32 %r566, %r565, %r90;
mul.lo.s32 %r567, %r566, %r1;
cvt.s64.s32 %rd174, %r567;
add.s64 %rd175, %rd174, %rd43;
mul.lo.s64 %rd176, %rd175, 110;
add.s64 %rd177, %rd41, %rd176;
add.s64 %rd178, %rd177, %rd45;
ld.global.nc.u16 %rs55, [%rd178+32];
ld.global.nc.u16 %rs56, [%rd178+34];
mov.b32 %r568, {%rs55, %rs56};
mad.lo.s32 %r569, %r566, 33, %r91;
shl.b32 %r570, %r569, 2;
add.s32 %r571, %r388, %r570;
st.shared.u32 [%r571], %r568;
add.s32 %r572, %r86, 108;
min.s32 %r573, %r572, %r90;
mul.lo.s32 %r574, %r573, %r1;
cvt.s64.s32 %rd179, %r574;
add.s64 %rd180, %rd179, %rd43;
mul.lo.s64 %rd181, %rd180, 110;
add.s64 %rd182, %rd41, %rd181;
add.s64 %rd183, %rd182, %rd45;
ld.global.nc.u16 %rs57, [%rd183+32];
ld.global.nc.u16 %rs58, [%rd183+34];
mov.b32 %r575, {%rs57, %rs58};
mad.lo.s32 %r576, %r573, 33, %r91;
shl.b32 %r577, %r576, 2;
add.s32 %r578, %r388, %r577;
st.shared.u32 [%r578], %r575;
add.s32 %r579, %r86, 112;
min.s32 %r580, %r579, %r90;
mul.lo.s32 %r581, %r580, %r1;
cvt.s64.s32 %rd184, %r581;
add.s64 %rd185, %rd184, %rd43;
mul.lo.s64 %rd186, %rd185, 110;
add.s64 %rd187, %rd41, %rd186;
add.s64 %rd188, %rd187, %rd45;
ld.global.nc.u16 %rs59, [%rd188+32];
ld.global.nc.u16 %rs60, [%rd188+34];
mov.b32 %r582, {%rs59, %rs60};
mad.lo.s32 %r583, %r580, 33, %r91;
shl.b32 %r584, %r583, 2;
add.s32 %r585, %r388, %r584;
st.shared.u32 [%r585], %r582;
add.s32 %r586, %r86, 116;
min.s32 %r587, %r586, %r90;
mul.lo.s32 %r588, %r587, %r1;
cvt.s64.s32 %rd189, %r588;
add.s64 %rd190, %rd189, %rd43;
mul.lo.s64 %rd191, %rd190, 110;
add.s64 %rd192, %rd41, %rd191;
add.s64 %rd193, %rd192, %rd45;
ld.global.nc.u16 %rs61, [%rd193+32];
ld.global.nc.u16 %rs62, [%rd193+34];
mov.b32 %r589, {%rs61, %rs62};
mad.lo.s32 %r590, %r587, 33, %r91;
shl.b32 %r591, %r590, 2;
add.s32 %r592, %r388, %r591;
st.shared.u32 [%r592], %r589;
add.s32 %r593, %r86, 120;
min.s32 %r594, %r593, %r90;
mul.lo.s32 %r595, %r594, %r1;
cvt.s64.s32 %rd194, %r595;
add.s64 %rd195, %rd194, %rd43;
mul.lo.s64 %rd196, %rd195, 110;
add.s64 %rd197, %rd41, %rd196;
add.s64 %rd198, %rd197, %rd45;
ld.global.nc.u16 %rs63, [%rd198+32];
ld.global.nc.u16 %rs64, [%rd198+34];
mov.b32 %r596, {%rs63, %rs64};
mad.lo.s32 %r597, %r594, 33, %r91;
shl.b32 %r598, %r597, 2;
add.s32 %r599, %r388, %r598;
st.shared.u32 [%r599], %r596;
add.s32 %r600, %r86, 124;
min.s32 %r601, %r600, %r90;
mul.lo.s32 %r602, %r601, %r1;
cvt.s64.s32 %rd199, %r602;
add.s64 %rd200, %rd199, %rd43;
mul.lo.s64 %rd201, %rd200, 110;
add.s64 %rd202, %rd41, %rd201;
add.s64 %rd203, %rd202, %rd45;
ld.global.nc.u16 %rs65, [%rd203+32];
ld.global.nc.u16 %rs66, [%rd203+34];
mov.b32 %r603, {%rs65, %rs66};
mad.lo.s32 %r604, %r601, 33, %r91;
shl.b32 %r605, %r604, 2;
add.s32 %r606, %r388, %r605;
st.shared.u32 [%r606], %r603;
mul.lo.s32 %r611, %r102, %r1;
cvt.s64.s32 %rd204, %r611;
cvt.u64.u32 %rd205, %r94;
add.s64 %rd206, %rd204, %rd205;
mul.lo.s64 %rd207, %rd206, 110;
add.s64 %rd208, %rd41, %rd207;
ld.global.nc.u16 %rs1, [%rd208+108];

	{ cvt.f32.f16 %f1025, %rs1;}


	st.shared.f32 [%r3], %f1025;
mul.lo.s32 %r615, %r113, %r1;
cvt.s64.s32 %rd209, %r615;
add.s64 %rd210, %rd209, %rd205;
mul.lo.s64 %rd211, %rd210, 110;
add.s64 %rd212, %rd41, %rd211;
ld.global.nc.u16 %rs2, [%rd212+108];

	{ cvt.f32.f16 %f1026, %rs2;}


	st.shared.f32 [%r4], %f1026;
mul.lo.s32 %r619, %r124, %r1;
cvt.s64.s32 %rd213, %r619;
and.b32 %r620, %r91, 8;
shr.u32 %r621, %r620, 3;
cvt.u64.u32 %rd214, %r621;
add.s64 %rd215, %rd213, %rd214;
and.b32 %r622, %r383, 28;
cvt.u64.u32 %rd216, %r622;
mul.lo.s64 %rd217, %rd215, 110;
add.s64 %rd218, %rd41, %rd217;
add.s64 %rd219, %rd218, %rd216;
ld.global.nc.u16 %rs67, [%rd219];
ld.global.nc.u16 %rs68, [%rd219+2];
mov.b32 %r623, {%rs67, %rs68};
not.b32 %r624, %r623;
st.shared.u32 [%r5], %r624;
mul.lo.s32 %r627, %r134, %r1;
cvt.s64.s32 %rd220, %r627;
add.s64 %rd221, %rd220, %rd214;
mul.lo.s64 %rd222, %rd221, 110;
add.s64 %rd223, %rd41, %rd222;
add.s64 %rd224, %rd223, %rd216;
ld.global.nc.u16 %rs69, [%rd224];
ld.global.nc.u16 %rs70, [%rd224+2];
mov.b32 %r628, {%rs69, %rs70};
not.b32 %r629, %r628;
st.shared.u32 [%r6], %r629;
mul.lo.s32 %r632, %r143, %r1;
cvt.s64.s32 %rd225, %r632;
add.s64 %rd226, %rd225, %rd214;
mul.lo.s64 %rd227, %rd226, 110;
add.s64 %rd228, %rd41, %rd227;
add.s64 %rd229, %rd228, %rd216;
ld.global.nc.u16 %rs71, [%rd229];
ld.global.nc.u16 %rs72, [%rd229+2];
mov.b32 %r633, {%rs71, %rs72};
not.b32 %r634, %r633;
st.shared.u32 [%r7], %r634;
mul.lo.s32 %r637, %r152, %r1;
cvt.s64.s32 %rd230, %r637;
add.s64 %rd231, %rd230, %rd214;
mul.lo.s64 %rd232, %rd231, 110;
add.s64 %rd233, %rd41, %rd232;
add.s64 %rd234, %rd233, %rd216;
ld.global.nc.u16 %rs73, [%rd234];
ld.global.nc.u16 %rs74, [%rd234+2];
mov.b32 %r638, {%rs73, %rs74};
not.b32 %r639, %r638;
st.shared.u32 [%r8], %r639;
mul.lo.s32 %r642, %r161, %r1;
cvt.s64.s32 %rd235, %r642;
add.s64 %rd236, %rd235, %rd214;
mul.lo.s64 %rd237, %rd236, 110;
add.s64 %rd238, %rd41, %rd237;
add.s64 %rd239, %rd238, %rd216;
ld.global.nc.u16 %rs75, [%rd239];
ld.global.nc.u16 %rs76, [%rd239+2];
mov.b32 %r643, {%rs75, %rs76};
not.b32 %r644, %r643;
st.shared.u32 [%r9], %r644;
mul.lo.s32 %r647, %r170, %r1;
cvt.s64.s32 %rd240, %r647;
add.s64 %rd241, %rd240, %rd214;
mul.lo.s64 %rd242, %rd241, 110;
add.s64 %rd243, %rd41, %rd242;
add.s64 %rd244, %rd243, %rd216;
ld.global.nc.u16 %rs77, [%rd244];
ld.global.nc.u16 %rs78, [%rd244+2];
mov.b32 %r648, {%rs77, %rs78};
not.b32 %r649, %r648;
st.shared.u32 [%r10], %r649;
mul.lo.s32 %r652, %r179, %r1;
cvt.s64.s32 %rd245, %r652;
add.s64 %rd246, %rd245, %rd214;
mul.lo.s64 %rd247, %rd246, 110;
add.s64 %rd248, %rd41, %rd247;
add.s64 %rd249, %rd248, %rd216;
ld.global.nc.u16 %rs79, [%rd249];
ld.global.nc.u16 %rs80, [%rd249+2];
mov.b32 %r653, {%rs79, %rs80};
not.b32 %r654, %r653;
st.shared.u32 [%r11], %r654;
mul.lo.s32 %r657, %r188, %r1;
cvt.s64.s32 %rd250, %r657;
add.s64 %rd251, %rd250, %rd214;
mul.lo.s64 %rd252, %rd251, 110;
add.s64 %rd253, %rd41, %rd252;
add.s64 %rd254, %rd253, %rd216;
ld.global.nc.u16 %rs81, [%rd254];
ld.global.nc.u16 %rs82, [%rd254+2];
mov.b32 %r658, {%rs81, %rs82};
not.b32 %r659, %r658;
st.shared.u32 [%r12], %r659;
mul.lo.s32 %r662, %r197, %r1;
cvt.s64.s32 %rd255, %r662;
add.s64 %rd256, %rd255, %rd214;
mul.lo.s64 %rd257, %rd256, 110;
add.s64 %rd258, %rd41, %rd257;
add.s64 %rd259, %rd258, %rd216;
ld.global.nc.u16 %rs83, [%rd259];
ld.global.nc.u16 %rs84, [%rd259+2];
mov.b32 %r663, {%rs83, %rs84};
not.b32 %r664, %r663;
st.shared.u32 [%r13], %r664;
mul.lo.s32 %r667, %r206, %r1;
cvt.s64.s32 %rd260, %r667;
add.s64 %rd261, %rd260, %rd214;
mul.lo.s64 %rd262, %rd261, 110;
add.s64 %rd263, %rd41, %rd262;
add.s64 %rd264, %rd263, %rd216;
ld.global.nc.u16 %rs85, [%rd264];
ld.global.nc.u16 %rs86, [%rd264+2];
mov.b32 %r668, {%rs85, %rs86};
not.b32 %r669, %r668;
st.shared.u32 [%r14], %r669;
mul.lo.s32 %r672, %r215, %r1;
cvt.s64.s32 %rd265, %r672;
add.s64 %rd266, %rd265, %rd214;
mul.lo.s64 %rd267, %rd266, 110;
add.s64 %rd268, %rd41, %rd267;
add.s64 %rd269, %rd268, %rd216;
ld.global.nc.u16 %rs87, [%rd269];
ld.global.nc.u16 %rs88, [%rd269+2];
mov.b32 %r673, {%rs87, %rs88};
not.b32 %r674, %r673;
st.shared.u32 [%r15], %r674;
mul.lo.s32 %r677, %r224, %r1;
cvt.s64.s32 %rd270, %r677;
add.s64 %rd271, %rd270, %rd214;
mul.lo.s64 %rd272, %rd271, 110;
add.s64 %rd273, %rd41, %rd272;
add.s64 %rd274, %rd273, %rd216;
ld.global.nc.u16 %rs89, [%rd274];
ld.global.nc.u16 %rs90, [%rd274+2];
mov.b32 %r678, {%rs89, %rs90};
not.b32 %r679, %r678;
st.shared.u32 [%r16], %r679;
mul.lo.s32 %r682, %r233, %r1;
cvt.s64.s32 %rd275, %r682;
add.s64 %rd276, %rd275, %rd214;
mul.lo.s64 %rd277, %rd276, 110;
add.s64 %rd278, %rd41, %rd277;
add.s64 %rd279, %rd278, %rd216;
ld.global.nc.u16 %rs91, [%rd279];
ld.global.nc.u16 %rs92, [%rd279+2];
mov.b32 %r683, {%rs91, %rs92};
not.b32 %r684, %r683;
st.shared.u32 [%r17], %r684;
mul.lo.s32 %r687, %r242, %r1;
cvt.s64.s32 %rd280, %r687;
add.s64 %rd281, %rd280, %rd214;
mul.lo.s64 %rd282, %rd281, 110;
add.s64 %rd283, %rd41, %rd282;
add.s64 %rd284, %rd283, %rd216;
ld.global.nc.u16 %rs93, [%rd284];
ld.global.nc.u16 %rs94, [%rd284+2];
mov.b32 %r688, {%rs93, %rs94};
not.b32 %r689, %r688;
st.shared.u32 [%r18], %r689;
mul.lo.s32 %r692, %r251, %r1;
cvt.s64.s32 %rd285, %r692;
add.s64 %rd286, %rd285, %rd214;
mul.lo.s64 %rd287, %rd286, 110;
add.s64 %rd288, %rd41, %rd287;
add.s64 %rd289, %rd288, %rd216;
ld.global.nc.u16 %rs95, [%rd289];
ld.global.nc.u16 %rs96, [%rd289+2];
mov.b32 %r693, {%rs95, %rs96};
not.b32 %r694, %r693;
st.shared.u32 [%r19], %r694;
mul.lo.s32 %r697, %r260, %r1;
cvt.s64.s32 %rd290, %r697;
add.s64 %rd291, %rd290, %rd214;
mul.lo.s64 %rd292, %rd291, 110;
add.s64 %rd293, %rd41, %rd292;
add.s64 %rd294, %rd293, %rd216;
ld.global.nc.u16 %rs97, [%rd294];
ld.global.nc.u16 %rs98, [%rd294+2];
mov.b32 %r698, {%rs97, %rs98};
not.b32 %r699, %r698;
st.shared.u32 [%r20], %r699;
mul.lo.s32 %r704, %r268, %r1;
cvt.s64.s32 %rd295, %r704;
and.b32 %r705, %r91, 4;
shr.u32 %r706, %r705, 2;
cvt.u64.u32 %rd296, %r706;
add.s64 %rd297, %rd295, %rd296;
and.b32 %r707, %r383, 4;
cvt.u64.u32 %rd298, %r707;
mul.lo.s64 %rd299, %rd297, 110;
add.s64 %rd300, %rd41, %rd299;
add.s64 %rd301, %rd300, %rd298;
ld.global.nc.u16 %rs99, [%rd301+96];
ld.global.nc.u16 %rs100, [%rd301+98];
mov.b32 %r708, {%rs99, %rs100};
shl.b32 %r709, %r91, 1;
and.b32 %r710, %r709, 4;
shr.s32 %r711, %r708, %r710;
and.b32 %r712, %r711, 252645135;
ld.global.nc.u16 %rs101, [%rd300+104];
ld.global.nc.u16 %rs102, [%rd300+106];
mov.b32 %r713, {%rs101, %rs102};
and.b32 %r714, %r709, 6;
shr.s32 %r715, %r713, %r714;
shl.b32 %r716, %r715, 4;
and.b32 %r717, %r716, 808464432;
or.b32 %r349, %r717, %r712;
mov.u32 %r371, 538976288;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r349; 
mov.b32 b,%r371; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r348,r; 
}

	st.shared.u32 [%r21], %r348;
mul.lo.s32 %r720, %r279, %r1;
cvt.s64.s32 %rd302, %r720;
add.s64 %rd303, %rd302, %rd296;
mul.lo.s64 %rd304, %rd303, 110;
add.s64 %rd305, %rd41, %rd304;
add.s64 %rd306, %rd305, %rd298;
ld.global.nc.u16 %rs103, [%rd306+96];
ld.global.nc.u16 %rs104, [%rd306+98];
mov.b32 %r721, {%rs103, %rs104};
shr.s32 %r722, %r721, %r710;
and.b32 %r723, %r722, 252645135;
ld.global.nc.u16 %rs105, [%rd305+104];
ld.global.nc.u16 %rs106, [%rd305+106];
mov.b32 %r724, {%rs105, %rs106};
shr.s32 %r725, %r724, %r714;
shl.b32 %r726, %r725, 4;
and.b32 %r727, %r726, 808464432;
or.b32 %r352, %r727, %r723;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r352; 
mov.b32 b,%r371; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r351,r; 
}

	st.shared.u32 [%r22], %r351;
mul.lo.s32 %r730, %r289, %r1;
cvt.s64.s32 %rd307, %r730;
add.s64 %rd308, %rd307, %rd296;
mul.lo.s64 %rd309, %rd308, 110;
add.s64 %rd310, %rd41, %rd309;
add.s64 %rd311, %rd310, %rd298;
ld.global.nc.u16 %rs107, [%rd311+96];
ld.global.nc.u16 %rs108, [%rd311+98];
mov.b32 %r731, {%rs107, %rs108};
shr.s32 %r732, %r731, %r710;
and.b32 %r733, %r732, 252645135;
ld.global.nc.u16 %rs109, [%rd310+104];
ld.global.nc.u16 %rs110, [%rd310+106];
mov.b32 %r734, {%rs109, %rs110};
shr.s32 %r735, %r734, %r714;
shl.b32 %r736, %r735, 4;
and.b32 %r737, %r736, 808464432;
or.b32 %r355, %r737, %r733;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r355; 
mov.b32 b,%r371; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r354,r; 
}

	st.shared.u32 [%r23], %r354;
mul.lo.s32 %r740, %r299, %r1;
cvt.s64.s32 %rd312, %r740;
add.s64 %rd313, %rd312, %rd296;
mul.lo.s64 %rd314, %rd313, 110;
add.s64 %rd315, %rd41, %rd314;
add.s64 %rd316, %rd315, %rd298;
ld.global.nc.u16 %rs111, [%rd316+96];
ld.global.nc.u16 %rs112, [%rd316+98];
mov.b32 %r741, {%rs111, %rs112};
shr.s32 %r742, %r741, %r710;
and.b32 %r743, %r742, 252645135;
ld.global.nc.u16 %rs113, [%rd315+104];
ld.global.nc.u16 %rs114, [%rd315+106];
mov.b32 %r744, {%rs113, %rs114};
shr.s32 %r745, %r744, %r714;
shl.b32 %r746, %r745, 4;
and.b32 %r747, %r746, 808464432;
or.b32 %r358, %r747, %r743;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r358; 
mov.b32 b,%r371; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r357,r; 
}

	st.shared.u32 [%r24], %r357;
mul.lo.s32 %r750, %r309, %r1;
cvt.s64.s32 %rd317, %r750;
add.s64 %rd318, %rd317, %rd296;
mul.lo.s64 %rd319, %rd318, 110;
add.s64 %rd320, %rd41, %rd319;
add.s64 %rd321, %rd320, %rd298;
ld.global.nc.u16 %rs115, [%rd321+96];
ld.global.nc.u16 %rs116, [%rd321+98];
mov.b32 %r751, {%rs115, %rs116};
shr.s32 %r752, %r751, %r710;
and.b32 %r753, %r752, 252645135;
ld.global.nc.u16 %rs117, [%rd320+104];
ld.global.nc.u16 %rs118, [%rd320+106];
mov.b32 %r754, {%rs117, %rs118};
shr.s32 %r755, %r754, %r714;
shl.b32 %r756, %r755, 4;
and.b32 %r757, %r756, 808464432;
or.b32 %r361, %r757, %r753;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r361; 
mov.b32 b,%r371; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r360,r; 
}

	st.shared.u32 [%r25], %r360;
mul.lo.s32 %r760, %r319, %r1;
cvt.s64.s32 %rd322, %r760;
add.s64 %rd323, %rd322, %rd296;
mul.lo.s64 %rd324, %rd323, 110;
add.s64 %rd325, %rd41, %rd324;
add.s64 %rd326, %rd325, %rd298;
ld.global.nc.u16 %rs119, [%rd326+96];
ld.global.nc.u16 %rs120, [%rd326+98];
mov.b32 %r761, {%rs119, %rs120};
shr.s32 %r762, %r761, %r710;
and.b32 %r763, %r762, 252645135;
ld.global.nc.u16 %rs121, [%rd325+104];
ld.global.nc.u16 %rs122, [%rd325+106];
mov.b32 %r764, {%rs121, %rs122};
shr.s32 %r765, %r764, %r714;
shl.b32 %r766, %r765, 4;
and.b32 %r767, %r766, 808464432;
or.b32 %r364, %r767, %r763;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r364; 
mov.b32 b,%r371; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r363,r; 
}

	st.shared.u32 [%r26], %r363;
mul.lo.s32 %r770, %r329, %r1;
cvt.s64.s32 %rd327, %r770;
add.s64 %rd328, %rd327, %rd296;
mul.lo.s64 %rd329, %rd328, 110;
add.s64 %rd330, %rd41, %rd329;
add.s64 %rd331, %rd330, %rd298;
ld.global.nc.u16 %rs123, [%rd331+96];
ld.global.nc.u16 %rs124, [%rd331+98];
mov.b32 %r771, {%rs123, %rs124};
shr.s32 %r772, %r771, %r710;
and.b32 %r773, %r772, 252645135;
ld.global.nc.u16 %rs125, [%rd330+104];
ld.global.nc.u16 %rs126, [%rd330+106];
mov.b32 %r774, {%rs125, %rs126};
shr.s32 %r775, %r774, %r714;
shl.b32 %r776, %r775, 4;
and.b32 %r777, %r776, 808464432;
or.b32 %r367, %r777, %r773;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r367; 
mov.b32 b,%r371; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r366,r; 
}

	st.shared.u32 [%r27], %r366;
mul.lo.s32 %r780, %r339, %r1;
cvt.s64.s32 %rd332, %r780;
add.s64 %rd333, %rd332, %rd296;
mul.lo.s64 %rd334, %rd333, 110;
add.s64 %rd335, %rd41, %rd334;
add.s64 %rd336, %rd335, %rd298;
ld.global.nc.u16 %rs127, [%rd336+96];
ld.global.nc.u16 %rs128, [%rd336+98];
mov.b32 %r781, {%rs127, %rs128};
shr.s32 %r782, %r781, %r710;
and.b32 %r783, %r782, 252645135;
ld.global.nc.u16 %rs129, [%rd335+104];
ld.global.nc.u16 %rs130, [%rd335+106];
mov.b32 %r784, {%rs129, %rs130};
shr.s32 %r785, %r784, %r714;
shl.b32 %r786, %r785, 4;
and.b32 %r787, %r786, 808464432;
or.b32 %r370, %r787, %r783;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r370; 
mov.b32 b,%r371; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r369,r; 
}

	st.shared.u32 [%r28], %r369;
mov.u32 %r9015, %r82;

$L__BB54_4:
shl.b32 %r9013, %r91, 2;
and.b32 %r9012, %r9013, 28;
cvt.u64.u32 %rd508, %r9012;
shl.b32 %r793, %r9015, 5;
add.s32 %r794, %r793, %r91;
shr.s32 %r795, %r794, 31;
shr.u32 %r796, %r795, 29;
add.s32 %r797, %r794, %r796;
shr.s32 %r798, %r797, 3;
mov.u32 %r799, %ctaid.y;
shl.b32 %r800, %r799, 7;
add.s32 %r802, %r800, %r86;
add.s32 %r803, %r75, -1;
min.u32 %r804, %r802, %r803;
shl.b32 %r805, %r9014, 3;
add.s32 %r806, %r798, %r805;
mad.lo.s32 %r807, %r804, %r2, %r806;
shr.u32 %r808, %r795, 27;
add.s32 %r809, %r794, %r808;
and.b32 %r810, %r809, 1073741792;
sub.s32 %r811, %r794, %r810;
shl.b32 %r812, %r86, 5;
add.s32 %r813, %r812, %r811;
mul.wide.s32 %rd339, %r807, 36;
add.s64 %rd340, %rd337, %rd339;
add.s64 %rd341, %rd340, %rd508;
ld.global.nc.u32 %r816, [%rd341+4];
shl.b32 %r817, %r813, 2;
mov.u32 %r818, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a69mul_mat_qILi256ELi4ELi16ELb0E10block_q3_KLi128ELi128ELi4EXadL_ZNS_19allocate_tiles_q3_KILi128EEEvPPiPP7__half2S4_S4_EEXadL_ZNS_15load_tiles_q3_KILi128ELi4ELb1EEEvPKvS3_S6_S3_S3_RKiSC_SC_SC_EELi2EXadL_ZNS_25vec_dot_q3_K_q8_1_mul_matEPSB_PKS5_SD_SD_SD_SF_SC_SC_SC_EEEEvSA_SA_PfiiiiiE9tile_y_qs;
add.s32 %r819, %r818, %r817;
st.shared.u32 [%r819], %r816;
add.s32 %r820, %r802, 4;
min.u32 %r821, %r820, %r803;
mad.lo.s32 %r822, %r821, %r2, %r806;
mul.wide.s32 %rd342, %r822, 36;
add.s64 %rd343, %rd337, %rd342;
add.s64 %rd344, %rd343, %rd508;
ld.global.nc.u32 %r823, [%rd344+4];
st.shared.u32 [%r819+512], %r823;
add.s32 %r824, %r802, 8;
min.u32 %r825, %r824, %r803;
mad.lo.s32 %r826, %r825, %r2, %r806;
mul.wide.s32 %rd345, %r826, 36;
add.s64 %rd346, %rd337, %rd345;
add.s64 %rd347, %rd346, %rd508;
ld.global.nc.u32 %r827, [%rd347+4];
st.shared.u32 [%r819+1024], %r827;
add.s32 %r828, %r802, 12;
min.u32 %r829, %r828, %r803;
mad.lo.s32 %r830, %r829, %r2, %r806;
mul.wide.s32 %rd348, %r830, 36;
add.s64 %rd349, %rd337, %rd348;
add.s64 %rd350, %rd349, %rd508;
ld.global.nc.u32 %r831, [%rd350+4];
st.shared.u32 [%r819+1536], %r831;
add.s32 %r832, %r802, 16;
min.u32 %r833, %r832, %r803;
mad.lo.s32 %r834, %r833, %r2, %r806;
mul.wide.s32 %rd351, %r834, 36;
add.s64 %rd352, %rd337, %rd351;
add.s64 %rd353, %rd352, %rd508;
ld.global.nc.u32 %r835, [%rd353+4];
st.shared.u32 [%r819+2048], %r835;
add.s32 %r836, %r802, 20;
min.u32 %r837, %r836, %r803;
mad.lo.s32 %r838, %r837, %r2, %r806;
mul.wide.s32 %rd354, %r838, 36;
add.s64 %rd355, %rd337, %rd354;
add.s64 %rd356, %rd355, %rd508;
ld.global.nc.u32 %r839, [%rd356+4];
st.shared.u32 [%r819+2560], %r839;
add.s32 %r840, %r802, 24;
min.u32 %r841, %r840, %r803;
mad.lo.s32 %r842, %r841, %r2, %r806;
mul.wide.s32 %rd357, %r842, 36;
add.s64 %rd358, %rd337, %rd357;
add.s64 %rd359, %rd358, %rd508;
ld.global.nc.u32 %r843, [%rd359+4];
st.shared.u32 [%r819+3072], %r843;
add.s32 %r844, %r802, 28;
min.u32 %r845, %r844, %r803;
mad.lo.s32 %r846, %r845, %r2, %r806;
mul.wide.s32 %rd360, %r846, 36;
add.s64 %rd361, %rd337, %rd360;
add.s64 %rd362, %rd361, %rd508;
ld.global.nc.u32 %r847, [%rd362+4];
st.shared.u32 [%r819+3584], %r847;
add.s32 %r848, %r802, 32;
min.u32 %r849, %r848, %r803;
mad.lo.s32 %r850, %r849, %r2, %r806;
mul.wide.s32 %rd363, %r850, 36;
add.s64 %rd364, %rd337, %rd363;
add.s64 %rd365, %rd364, %rd508;
ld.global.nc.u32 %r851, [%rd365+4];
st.shared.u32 [%r819+4096], %r851;
add.s32 %r852, %r802, 36;
min.u32 %r853, %r852, %r803;
mad.lo.s32 %r854, %r853, %r2, %r806;
mul.wide.s32 %rd366, %r854, 36;
add.s64 %rd367, %rd337, %rd366;
add.s64 %rd368, %rd367, %rd508;
ld.global.nc.u32 %r855, [%rd368+4];
st.shared.u32 [%r819+4608], %r855;
add.s32 %r856, %r802, 40;
min.u32 %r857, %r856, %r803;
mad.lo.s32 %r858, %r857, %r2, %r806;
mul.wide.s32 %rd369, %r858, 36;
add.s64 %rd370, %rd337, %rd369;
add.s64 %rd371, %rd370, %rd508;
ld.global.nc.u32 %r859, [%rd371+4];
st.shared.u32 [%r819+5120], %r859;
add.s32 %r860, %r802, 44;
min.u32 %r861, %r860, %r803;
mad.lo.s32 %r862, %r861, %r2, %r806;
mul.wide.s32 %rd372, %r862, 36;
add.s64 %rd373, %rd337, %rd372;
add.s64 %rd374, %rd373, %rd508;
ld.global.nc.u32 %r863, [%rd374+4];
st.shared.u32 [%r819+5632], %r863;
add.s32 %r864, %r802, 48;
min.u32 %r865, %r864, %r803;
mad.lo.s32 %r866, %r865, %r2, %r806;
mul.wide.s32 %rd375, %r866, 36;
add.s64 %rd376, %rd337, %rd375;
add.s64 %rd377, %rd376, %rd508;
ld.global.nc.u32 %r867, [%rd377+4];
st.shared.u32 [%r819+6144], %r867;
add.s32 %r868, %r802, 52;
min.u32 %r869, %r868, %r803;
mad.lo.s32 %r870, %r869, %r2, %r806;
mul.wide.s32 %rd378, %r870, 36;
add.s64 %rd379, %rd337, %rd378;
add.s64 %rd380, %rd379, %rd508;
ld.global.nc.u32 %r871, [%rd380+4];
st.shared.u32 [%r819+6656], %r871;
add.s32 %r872, %r802, 56;
min.u32 %r873, %r872, %r803;
mad.lo.s32 %r874, %r873, %r2, %r806;
mul.wide.s32 %rd381, %r874, 36;
add.s64 %rd382, %rd337, %rd381;
add.s64 %rd383, %rd382, %rd508;
ld.global.nc.u32 %r875, [%rd383+4];
st.shared.u32 [%r819+7168], %r875;
add.s32 %r876, %r802, 60;
min.u32 %r877, %r876, %r803;
mad.lo.s32 %r878, %r877, %r2, %r806;
mul.wide.s32 %rd384, %r878, 36;
add.s64 %rd385, %rd337, %rd384;
add.s64 %rd386, %rd385, %rd508;
ld.global.nc.u32 %r879, [%rd386+4];
st.shared.u32 [%r819+7680], %r879;
add.s32 %r880, %r802, 64;
min.u32 %r881, %r880, %r803;
mad.lo.s32 %r882, %r881, %r2, %r806;
mul.wide.s32 %rd387, %r882, 36;
add.s64 %rd388, %rd337, %rd387;
add.s64 %rd389, %rd388, %rd508;
ld.global.nc.u32 %r883, [%rd389+4];
st.shared.u32 [%r819+8192], %r883;
add.s32 %r884, %r802, 68;
min.u32 %r885, %r884, %r803;
mad.lo.s32 %r886, %r885, %r2, %r806;
mul.wide.s32 %rd390, %r886, 36;
add.s64 %rd391, %rd337, %rd390;
add.s64 %rd392, %rd391, %rd508;
ld.global.nc.u32 %r887, [%rd392+4];
st.shared.u32 [%r819+8704], %r887;
add.s32 %r888, %r802, 72;
min.u32 %r889, %r888, %r803;
mad.lo.s32 %r890, %r889, %r2, %r806;
mul.wide.s32 %rd393, %r890, 36;
add.s64 %rd394, %rd337, %rd393;
add.s64 %rd395, %rd394, %rd508;
ld.global.nc.u32 %r891, [%rd395+4];
st.shared.u32 [%r819+9216], %r891;
add.s32 %r892, %r802, 76;
min.u32 %r893, %r892, %r803;
mad.lo.s32 %r894, %r893, %r2, %r806;
mul.wide.s32 %rd396, %r894, 36;
add.s64 %rd397, %rd337, %rd396;
add.s64 %rd398, %rd397, %rd508;
ld.global.nc.u32 %r895, [%rd398+4];
st.shared.u32 [%r819+9728], %r895;
add.s32 %r896, %r802, 80;
min.u32 %r897, %r896, %r803;
mad.lo.s32 %r898, %r897, %r2, %r806;
mul.wide.s32 %rd399, %r898, 36;
add.s64 %rd400, %rd337, %rd399;
add.s64 %rd401, %rd400, %rd508;
ld.global.nc.u32 %r899, [%rd401+4];
st.shared.u32 [%r819+10240], %r899;
add.s32 %r900, %r802, 84;
min.u32 %r901, %r900, %r803;
mad.lo.s32 %r902, %r901, %r2, %r806;
mul.wide.s32 %rd402, %r902, 36;
add.s64 %rd403, %rd337, %rd402;
add.s64 %rd404, %rd403, %rd508;
ld.global.nc.u32 %r903, [%rd404+4];
st.shared.u32 [%r819+10752], %r903;
add.s32 %r904, %r802, 88;
min.u32 %r905, %r904, %r803;
mad.lo.s32 %r906, %r905, %r2, %r806;
mul.wide.s32 %rd405, %r906, 36;
add.s64 %rd406, %rd337, %rd405;
add.s64 %rd407, %rd406, %rd508;
ld.global.nc.u32 %r907, [%rd407+4];
st.shared.u32 [%r819+11264], %r907;
add.s32 %r908, %r802, 92;
min.u32 %r909, %r908, %r803;
mad.lo.s32 %r910, %r909, %r2, %r806;
mul.wide.s32 %rd408, %r910, 36;
add.s64 %rd409, %rd337, %rd408;
add.s64 %rd410, %rd409, %rd508;
ld.global.nc.u32 %r911, [%rd410+4];
st.shared.u32 [%r819+11776], %r911;
add.s32 %r912, %r802, 96;
min.u32 %r913, %r912, %r803;
mad.lo.s32 %r914, %r913, %r2, %r806;
mul.wide.s32 %rd411, %r914, 36;
add.s64 %rd412, %rd337, %rd411;
add.s64 %rd413, %rd412, %rd508;
ld.global.nc.u32 %r915, [%rd413+4];
st.shared.u32 [%r819+12288], %r915;
add.s32 %r916, %r802, 100;
min.u32 %r917, %r916, %r803;
mad.lo.s32 %r918, %r917, %r2, %r806;
mul.wide.s32 %rd414, %r918, 36;
add.s64 %rd415, %rd337, %rd414;
add.s64 %rd416, %rd415, %rd508;
ld.global.nc.u32 %r919, [%rd416+4];
st.shared.u32 [%r819+12800], %r919;
add.s32 %r920, %r802, 104;
min.u32 %r921, %r920, %r803;
mad.lo.s32 %r922, %r921, %r2, %r806;
mul.wide.s32 %rd417, %r922, 36;
add.s64 %rd418, %rd337, %rd417;
add.s64 %rd419, %rd418, %rd508;
ld.global.nc.u32 %r923, [%rd419+4];
st.shared.u32 [%r819+13312], %r923;
add.s32 %r924, %r802, 108;
min.u32 %r925, %r924, %r803;
mad.lo.s32 %r926, %r925, %r2, %r806;
mul.wide.s32 %rd420, %r926, 36;
add.s64 %rd421, %rd337, %rd420;
add.s64 %rd422, %rd421, %rd508;
ld.global.nc.u32 %r927, [%rd422+4];
st.shared.u32 [%r819+13824], %r927;
add.s32 %r928, %r802, 112;
min.u32 %r929, %r928, %r803;
mad.lo.s32 %r930, %r929, %r2, %r806;
mul.wide.s32 %rd423, %r930, 36;
add.s64 %rd424, %rd337, %rd423;
add.s64 %rd425, %rd424, %rd508;
ld.global.nc.u32 %r931, [%rd425+4];
st.shared.u32 [%r819+14336], %r931;
add.s32 %r932, %r802, 116;
min.u32 %r933, %r932, %r803;
mad.lo.s32 %r934, %r933, %r2, %r806;
mul.wide.s32 %rd426, %r934, 36;
add.s64 %rd427, %rd337, %rd426;
add.s64 %rd428, %rd427, %rd508;
ld.global.nc.u32 %r935, [%rd428+4];
st.shared.u32 [%r819+14848], %r935;
add.s32 %r936, %r802, 120;
min.u32 %r937, %r936, %r803;
mad.lo.s32 %r938, %r937, %r2, %r806;
mul.wide.s32 %rd429, %r938, 36;
add.s64 %rd430, %rd337, %rd429;
add.s64 %rd431, %rd430, %rd508;
ld.global.nc.u32 %r939, [%rd431+4];
st.shared.u32 [%r819+15360], %r939;
add.s32 %r940, %r802, 124;
min.u32 %r941, %r940, %r803;
mad.lo.s32 %r942, %r941, %r2, %r806;
mul.wide.s32 %rd432, %r942, 36;
add.s64 %rd433, %rd337, %rd432;
add.s64 %rd434, %rd433, %rd508;
ld.global.nc.u32 %r943, [%rd434+4];
st.shared.u32 [%r819+15872], %r943;
shl.b32 %r944, %r86, 3;
shr.u32 %r945, %r91, 2;
add.s32 %r946, %r945, %r944;
and.b32 %r947, %r91, 3;
bfi.b32 %r948, %r9014, %r947, 3, 29;
shl.b32 %r949, %r9015, 2;
add.s32 %r950, %r948, %r949;
add.s32 %r951, %r946, %r800;
min.s32 %r952, %r951, %r803;
mad.lo.s32 %r953, %r952, %r2, %r950;
mul.wide.s32 %rd435, %r953, 36;
add.s64 %rd436, %rd337, %rd435;
bfi.b32 %r954, %r946, %r947, 2, 30;
shl.b32 %r955, %r954, 2;
mov.u32 %r956, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a69mul_mat_qILi256ELi4ELi16ELb0E10block_q3_KLi128ELi128ELi4EXadL_ZNS_19allocate_tiles_q3_KILi128EEEvPPiPP7__half2S4_S4_EEXadL_ZNS_15load_tiles_q3_KILi128ELi4ELb1EEEvPKvS3_S6_S3_S3_RKiSC_SC_SC_EELi2EXadL_ZNS_25vec_dot_q3_K_q8_1_mul_matEPSB_PKS5_SD_SD_SD_SF_SC_SC_SC_EEEEvSA_SA_PfiiiiiE9tile_y_ds;
add.s32 %r957, %r956, %r955;
ld.global.nc.u32 %r788, [%rd436];

	{.reg .f16 low,high;
mov.b32 {low,high}, %r788;
mov.b16 %rs131, low;}

	
	{ cvt.f32.f16 %f1027, %rs131;}


	st.shared.f32 [%r957], %f1027;
add.s32 %r958, %r951, 32;
min.s32 %r959, %r958, %r803;
mad.lo.s32 %r960, %r959, %r2, %r950;
mul.wide.s32 %rd437, %r960, 36;
add.s64 %rd438, %rd337, %rd437;
ld.global.nc.u32 %r789, [%rd438];

	{.reg .f16 low,high;
mov.b32 {low,high}, %r789;
mov.b16 %rs133, low;}

	
	{ cvt.f32.f16 %f1028, %rs133;}


	st.shared.f32 [%r957+512], %f1028;
add.s32 %r961, %r951, 64;
min.s32 %r962, %r961, %r803;
mad.lo.s32 %r963, %r962, %r2, %r950;
mul.wide.s32 %rd439, %r963, 36;
add.s64 %rd440, %rd337, %rd439;
ld.global.nc.u32 %r790, [%rd440];

	{.reg .f16 low,high;
mov.b32 {low,high}, %r790;
mov.b16 %rs135, low;}

	
	{ cvt.f32.f16 %f1029, %rs135;}


	st.shared.f32 [%r957+1024], %f1029;
add.s32 %r964, %r951, 96;
min.s32 %r965, %r964, %r803;
mad.lo.s32 %r966, %r965, %r2, %r950;
mul.wide.s32 %rd441, %r966, 36;
add.s64 %rd442, %rd337, %rd441;
ld.global.nc.u32 %r791, [%rd442];

	{.reg .f16 low,high;
mov.b32 {low,high}, %r791;
mov.b16 %rs137, low;}

	
	{ cvt.f32.f16 %f1030, %rs137;}


	st.shared.f32 [%r957+1536], %f1030;
bar.sync 0;
add.s32 %r967, %r793, 32;
shr.s32 %r31, %r967, 2;
shl.b32 %r9016, %r9015, 3;
setp.ge.s32 %p2, %r9016, %r31;
@%p2 bra $L__BB54_6;

$L__BB54_5:
shl.b32 %r9011, %r9015, 5;
add.s32 %r9010, %r9011, 32;
shr.s32 %r9009, %r9010, 2;
mov.u32 %r9008, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a69mul_mat_qILi256ELi4ELi16ELb0E10block_q3_KLi128ELi128ELi4EXadL_ZNS_19allocate_tiles_q3_KILi128EEEvPPiPP7__half2S4_S4_EEXadL_ZNS_15load_tiles_q3_KILi128ELi4ELb1EEEvPKvS3_S6_S3_S3_RKiSC_SC_SC_EELi2EXadL_ZNS_25vec_dot_q3_K_q8_1_mul_matEPSB_PKS5_SD_SD_SD_SF_SC_SC_SC_EEEEvSA_SA_PfiiiiiE9tile_y_qs;
shl.b32 %r9007, %r91, 1;
mov.u32 %r9006, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a619allocate_tiles_q3_KILi128EEEvPPiPP7__half2S2_S2_E9tile_x_ql;
shr.u32 %r9005, %r91, 2;
mov.u32 %r9004, _ZZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a69mul_mat_qILi256ELi4ELi16ELb0E10block_q3_KLi128ELi128ELi4EXadL_ZNS_19allocate_tiles_q3_KILi128EEEvPPiPP7__half2S4_S4_EEXadL_ZNS_15load_tiles_q3_KILi128ELi4ELb1EEEvPKvS3_S6_S3_S3_RKiSC_SC_SC_EELi2EXadL_ZNS_25vec_dot_q3_K_q8_1_mul_matEPSB_PKS5_SD_SD_SD_SF_SC_SC_SC_EEEEvSA_SA_PfiiiiiE9tile_y_ds;
shl.b32 %r9003, %r86, 5;
shr.u32 %r8136, %r9016, 4;
shl.b32 %r8137, %r8136, 2;
and.b32 %r8138, %r9016, 6;
and.b32 %r8139, %r9016, 1073741816;
shl.b32 %r8140, %r8136, 3;
shr.u32 %r8141, %r9016, 1;
shl.b32 %r8142, %r9016, 2;
and.b32 %r8143, %r8142, 24;
or.b32 %r8146, %r9003, %r8143;
shr.u32 %r8147, %r8146, 1;
add.s32 %r8149, %r9004, %r8147;
add.s32 %r8152, %r9005, %r8137;
shl.b32 %r8153, %r91, 3;
add.s32 %r8154, %r8152, %r8153;
mad.lo.s32 %r8155, %r91, 33, %r8139;
add.s32 %r8157, %r96, %r8140;
shl.b32 %r8158, %r91, 4;
add.s32 %r8159, %r8157, %r8158;
shl.b32 %r8160, %r8154, 2;
add.s32 %r8162, %r277, %r8160;
shl.b32 %r8163, %r8155, 2;
add.s32 %r8165, %r9006, %r8163;
ld.shared.u32 %r8166, [%r8165];
mov.u32 %r8123, 0;
shr.s32 %r8167, %r8166, %r8138;
and.b32 %r6121, %r8167, 50529027;
shl.b32 %r8168, %r8159, 2;
add.s32 %r8170, %r132, %r8168;
and.b32 %r8171, %r9016, 14;
shr.u32 %r8172, %r8171, 1;
ld.shared.u32 %r8173, [%r8170];
shr.s32 %r8174, %r8173, %r8172;
shl.b32 %r8175, %r8174, 2;
and.b32 %r6122, %r8175, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r968,r; 
}

	ld.shared.u32 %r8176, [%r8165+4];
shr.s32 %r8177, %r8176, %r8138;
and.b32 %r6124, %r8177, 50529027;
and.b32 %r8178, %r8141, 7;
ld.shared.u32 %r8179, [%r8170+4];
shr.s32 %r8180, %r8179, %r8178;
shl.b32 %r8181, %r8180, 2;
and.b32 %r6125, %r8181, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r971,r; 
}

	ld.shared.u32 %r8182, [%r8165+8];
shr.s32 %r8183, %r8182, %r8138;
and.b32 %r6127, %r8183, 50529027;
ld.shared.u32 %r8184, [%r8170+8];
shr.s32 %r8185, %r8184, %r8178;
shl.b32 %r8186, %r8185, 2;
and.b32 %r6128, %r8186, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r974,r; 
}

	ld.shared.u32 %r8187, [%r8165+12];
shr.s32 %r8188, %r8187, %r8138;
and.b32 %r6130, %r8188, 50529027;
ld.shared.u32 %r8189, [%r8170+12];
shr.s32 %r8190, %r8189, %r8178;
shl.b32 %r8191, %r8190, 2;
and.b32 %r6131, %r8191, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r977,r; 
}

	ld.shared.u32 %r8192, [%r8165+16];
shr.s32 %r8193, %r8192, %r8138;
and.b32 %r6133, %r8193, 50529027;
ld.shared.u32 %r8194, [%r8170+16];
shr.s32 %r8195, %r8194, %r8178;
shl.b32 %r8196, %r8195, 2;
and.b32 %r6134, %r8196, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r980,r; 
}

	ld.shared.u32 %r8197, [%r8165+20];
shr.s32 %r8198, %r8197, %r8138;
and.b32 %r6136, %r8198, 50529027;
ld.shared.u32 %r8199, [%r8170+20];
shr.s32 %r8200, %r8199, %r8178;
shl.b32 %r8201, %r8200, 2;
and.b32 %r6137, %r8201, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r983,r; 
}

	ld.shared.u32 %r8202, [%r8165+24];
shr.s32 %r8203, %r8202, %r8138;
and.b32 %r6139, %r8203, 50529027;
ld.shared.u32 %r8204, [%r8170+24];
shr.s32 %r8205, %r8204, %r8178;
shl.b32 %r8206, %r8205, 2;
and.b32 %r6140, %r8206, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r986,r; 
}

	ld.shared.u32 %r8207, [%r8165+28];
shr.s32 %r8208, %r8207, %r8138;
and.b32 %r6142, %r8208, 50529027;
ld.shared.u32 %r8209, [%r8170+28];
shr.s32 %r8210, %r8209, %r8178;
shl.b32 %r8211, %r8210, 2;
and.b32 %r6143, %r8211, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r989,r; 
}

	add.s32 %r8213, %r92, %r8136;
add.s32 %r8215, %r8213, %r9007;
shl.b32 %r8216, %r8215, 2;
add.s32 %r8218, %r111, %r8216;
shl.b32 %r8219, %r8146, 2;
add.s32 %r8221, %r9008, %r8219;
ld.shared.u32 %r994, [%r8221];

	dp4a.s32.s32 %r992, %r968, %r994, %r8123;

	ld.shared.u32 %r1166, [%r8221+4];

	dp4a.s32.s32 %r996, %r971, %r1166, %r992;

	ld.shared.u32 %r1170, [%r8221+8];

	dp4a.s32.s32 %r1000, %r974, %r1170, %r996;

	ld.shared.u32 %r1174, [%r8221+12];

	dp4a.s32.s32 %r1004, %r977, %r1174, %r1000;

	add.s32 %r8222, %r8162, %r8171;
ld.shared.s8 %r8223, [%r8222];
mul.lo.s32 %r8224, %r1004, %r8223;
ld.shared.u32 %r1178, [%r8221+16];

	dp4a.s32.s32 %r1008, %r980, %r1178, %r8123;

	ld.shared.u32 %r1182, [%r8221+20];

	dp4a.s32.s32 %r1012, %r983, %r1182, %r1008;

	ld.shared.u32 %r1186, [%r8221+24];

	dp4a.s32.s32 %r1016, %r986, %r1186, %r1012;

	ld.shared.u32 %r1190, [%r8221+28];

	dp4a.s32.s32 %r1020, %r989, %r1190, %r1016;

	ld.shared.s8 %r8225, [%r8222+1];
mad.lo.s32 %r8226, %r1020, %r8225, %r8224;
ld.shared.f32 %f1031, [%r8149];
ld.shared.f32 %f1032, [%r8218];
mul.ftz.f32 %f1033, %f1032, %f1031;
cvt.rn.f32.s32 %f1034, %r8226;
fma.rn.ftz.f32 %f1838, %f1033, %f1034, %f1838;
add.s32 %r8227, %r91, 32;
shr.u32 %r8228, %r8227, 2;
add.s32 %r8229, %r8228, %r8137;
shl.b32 %r8230, %r8227, 3;
add.s32 %r8231, %r8229, %r8230;
shr.u32 %r8232, %r8227, 1;
add.s32 %r8233, %r8232, %r8140;
shl.b32 %r8234, %r8227, 4;
add.s32 %r8235, %r8233, %r8234;
shl.b32 %r8236, %r8231, 2;
add.s32 %r8237, %r277, %r8236;
ld.shared.u32 %r8238, [%r8165+4224];
shr.s32 %r8239, %r8238, %r8138;
and.b32 %r6177, %r8239, 50529027;
shl.b32 %r8240, %r8235, 2;
add.s32 %r8241, %r132, %r8240;
ld.shared.u32 %r8242, [%r8241];
shr.s32 %r8243, %r8242, %r8172;
shl.b32 %r8244, %r8243, 2;
and.b32 %r6178, %r8244, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1024,r; 
}

	ld.shared.u32 %r8245, [%r8165+4228];
shr.s32 %r8246, %r8245, %r8138;
and.b32 %r6180, %r8246, 50529027;
ld.shared.u32 %r8247, [%r8241+4];
shr.s32 %r8248, %r8247, %r8178;
shl.b32 %r8249, %r8248, 2;
and.b32 %r6181, %r8249, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1027,r; 
}

	ld.shared.u32 %r8250, [%r8165+4232];
shr.s32 %r8251, %r8250, %r8138;
and.b32 %r6183, %r8251, 50529027;
ld.shared.u32 %r8252, [%r8241+8];
shr.s32 %r8253, %r8252, %r8178;
shl.b32 %r8254, %r8253, 2;
and.b32 %r6184, %r8254, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1030,r; 
}

	ld.shared.u32 %r8255, [%r8165+4236];
shr.s32 %r8256, %r8255, %r8138;
and.b32 %r6186, %r8256, 50529027;
ld.shared.u32 %r8257, [%r8241+12];
shr.s32 %r8258, %r8257, %r8178;
shl.b32 %r8259, %r8258, 2;
and.b32 %r6187, %r8259, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1033,r; 
}

	ld.shared.u32 %r8260, [%r8165+4240];
shr.s32 %r8261, %r8260, %r8138;
and.b32 %r6189, %r8261, 50529027;
ld.shared.u32 %r8262, [%r8241+16];
shr.s32 %r8263, %r8262, %r8178;
shl.b32 %r8264, %r8263, 2;
and.b32 %r6190, %r8264, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1036,r; 
}

	ld.shared.u32 %r8265, [%r8165+4244];
shr.s32 %r8266, %r8265, %r8138;
and.b32 %r6192, %r8266, 50529027;
ld.shared.u32 %r8267, [%r8241+20];
shr.s32 %r8268, %r8267, %r8178;
shl.b32 %r8269, %r8268, 2;
and.b32 %r6193, %r8269, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1039,r; 
}

	ld.shared.u32 %r8270, [%r8165+4248];
shr.s32 %r8271, %r8270, %r8138;
and.b32 %r6195, %r8271, 50529027;
ld.shared.u32 %r8272, [%r8241+24];
shr.s32 %r8273, %r8272, %r8178;
shl.b32 %r8274, %r8273, 2;
and.b32 %r6196, %r8274, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1042,r; 
}

	ld.shared.u32 %r8275, [%r8165+4252];
shr.s32 %r8276, %r8275, %r8138;
and.b32 %r6198, %r8276, 50529027;
ld.shared.u32 %r8277, [%r8241+28];
shr.s32 %r8278, %r8277, %r8178;
shl.b32 %r8279, %r8278, 2;
and.b32 %r6199, %r8279, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1045,r; 
}

	shr.u32 %r8280, %r8227, 4;
add.s32 %r8281, %r8280, %r8136;
shl.b32 %r8282, %r8227, 1;
add.s32 %r8283, %r8281, %r8282;
shl.b32 %r8284, %r8283, 2;
add.s32 %r8285, %r111, %r8284;

	dp4a.s32.s32 %r1048, %r1024, %r994, %r8123;

	
	dp4a.s32.s32 %r1052, %r1027, %r1166, %r1048;

	
	dp4a.s32.s32 %r1056, %r1030, %r1170, %r1052;

	
	dp4a.s32.s32 %r1060, %r1033, %r1174, %r1056;

	add.s32 %r8286, %r8237, %r8171;
ld.shared.s8 %r8287, [%r8286];
mul.lo.s32 %r8288, %r1060, %r8287;

	dp4a.s32.s32 %r1064, %r1036, %r1178, %r8123;

	
	dp4a.s32.s32 %r1068, %r1039, %r1182, %r1064;

	
	dp4a.s32.s32 %r1072, %r1042, %r1186, %r1068;

	
	dp4a.s32.s32 %r1076, %r1045, %r1190, %r1072;

	ld.shared.s8 %r8289, [%r8286+1];
mad.lo.s32 %r8290, %r1076, %r8289, %r8288;
ld.shared.f32 %f1035, [%r8285];
mul.ftz.f32 %f1036, %f1035, %f1031;
cvt.rn.f32.s32 %f1037, %r8290;
fma.rn.ftz.f32 %f1806, %f1036, %f1037, %f1806;
add.s32 %r8291, %r91, 64;
shr.u32 %r8292, %r8291, 2;
add.s32 %r8293, %r8292, %r8137;
shl.b32 %r8294, %r8291, 3;
add.s32 %r8295, %r8293, %r8294;
shr.u32 %r8296, %r8291, 1;
add.s32 %r8297, %r8296, %r8140;
shl.b32 %r8298, %r8291, 4;
add.s32 %r8299, %r8297, %r8298;
shl.b32 %r8300, %r8295, 2;
add.s32 %r8301, %r277, %r8300;
ld.shared.u32 %r8302, [%r8165+8448];
shr.s32 %r8303, %r8302, %r8138;
and.b32 %r6233, %r8303, 50529027;
shl.b32 %r8304, %r8299, 2;
add.s32 %r8305, %r132, %r8304;
ld.shared.u32 %r8306, [%r8305];
shr.s32 %r8307, %r8306, %r8172;
shl.b32 %r8308, %r8307, 2;
and.b32 %r6234, %r8308, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1080,r; 
}

	ld.shared.u32 %r8309, [%r8165+8452];
shr.s32 %r8310, %r8309, %r8138;
and.b32 %r6236, %r8310, 50529027;
ld.shared.u32 %r8311, [%r8305+4];
shr.s32 %r8312, %r8311, %r8178;
shl.b32 %r8313, %r8312, 2;
and.b32 %r6461, %r8313, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1083,r; 
}

	ld.shared.u32 %r8314, [%r8165+8456];
shr.s32 %r8315, %r8314, %r8138;
and.b32 %r6463, %r8315, 50529027;
ld.shared.u32 %r8316, [%r8305+8];
shr.s32 %r8317, %r8316, %r8178;
shl.b32 %r8318, %r8317, 2;
and.b32 %r6464, %r8318, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1086,r; 
}

	ld.shared.u32 %r8319, [%r8165+8460];
shr.s32 %r8320, %r8319, %r8138;
and.b32 %r6466, %r8320, 50529027;
ld.shared.u32 %r8321, [%r8305+12];
shr.s32 %r8322, %r8321, %r8178;
shl.b32 %r8323, %r8322, 2;
and.b32 %r6467, %r8323, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1089,r; 
}

	ld.shared.u32 %r8324, [%r8165+8464];
shr.s32 %r8325, %r8324, %r8138;
and.b32 %r6469, %r8325, 50529027;
ld.shared.u32 %r8326, [%r8305+16];
shr.s32 %r8327, %r8326, %r8178;
shl.b32 %r8328, %r8327, 2;
and.b32 %r6470, %r8328, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1092,r; 
}

	ld.shared.u32 %r8329, [%r8165+8468];
shr.s32 %r8330, %r8329, %r8138;
and.b32 %r6472, %r8330, 50529027;
ld.shared.u32 %r8331, [%r8305+20];
shr.s32 %r8332, %r8331, %r8178;
shl.b32 %r8333, %r8332, 2;
and.b32 %r6473, %r8333, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1095,r; 
}

	ld.shared.u32 %r8334, [%r8165+8472];
shr.s32 %r8335, %r8334, %r8138;
and.b32 %r6475, %r8335, 50529027;
ld.shared.u32 %r8336, [%r8305+24];
shr.s32 %r8337, %r8336, %r8178;
shl.b32 %r8338, %r8337, 2;
and.b32 %r6476, %r8338, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1098,r; 
}

	ld.shared.u32 %r8339, [%r8165+8476];
shr.s32 %r8340, %r8339, %r8138;
and.b32 %r6478, %r8340, 50529027;
ld.shared.u32 %r8341, [%r8305+28];
shr.s32 %r8342, %r8341, %r8178;
shl.b32 %r8343, %r8342, 2;
and.b32 %r6479, %r8343, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1101,r; 
}

	shr.u32 %r8344, %r8291, 4;
add.s32 %r8345, %r8344, %r8136;
shl.b32 %r8346, %r8291, 1;
add.s32 %r8347, %r8345, %r8346;
shl.b32 %r8348, %r8347, 2;
add.s32 %r8349, %r111, %r8348;

	dp4a.s32.s32 %r1104, %r1080, %r994, %r8123;

	
	dp4a.s32.s32 %r1108, %r1083, %r1166, %r1104;

	
	dp4a.s32.s32 %r1112, %r1086, %r1170, %r1108;

	
	dp4a.s32.s32 %r1116, %r1089, %r1174, %r1112;

	add.s32 %r8350, %r8301, %r8171;
ld.shared.s8 %r8351, [%r8350];
mul.lo.s32 %r8352, %r1116, %r8351;

	dp4a.s32.s32 %r1120, %r1092, %r1178, %r8123;

	
	dp4a.s32.s32 %r1124, %r1095, %r1182, %r1120;

	
	dp4a.s32.s32 %r1128, %r1098, %r1186, %r1124;

	
	dp4a.s32.s32 %r1132, %r1101, %r1190, %r1128;

	ld.shared.s8 %r8353, [%r8350+1];
mad.lo.s32 %r8354, %r1132, %r8353, %r8352;
ld.shared.f32 %f1038, [%r8349];
mul.ftz.f32 %f1039, %f1038, %f1031;
cvt.rn.f32.s32 %f1040, %r8354;
fma.rn.ftz.f32 %f1774, %f1039, %f1040, %f1774;
add.s32 %r8355, %r91, 96;
shr.u32 %r8356, %r8355, 2;
add.s32 %r8357, %r8356, %r8137;
shl.b32 %r8358, %r8355, 3;
add.s32 %r8359, %r8357, %r8358;
shr.u32 %r8360, %r8355, 1;
add.s32 %r8361, %r8360, %r8140;
shl.b32 %r8362, %r8355, 4;
add.s32 %r8363, %r8361, %r8362;
shl.b32 %r8364, %r8359, 2;
add.s32 %r8365, %r277, %r8364;
ld.shared.u32 %r8366, [%r8165+12672];
shr.s32 %r8367, %r8366, %r8138;
and.b32 %r6513, %r8367, 50529027;
shl.b32 %r8368, %r8363, 2;
add.s32 %r8369, %r132, %r8368;
ld.shared.u32 %r8370, [%r8369];
shr.s32 %r8371, %r8370, %r8172;
shl.b32 %r8372, %r8371, 2;
and.b32 %r6514, %r8372, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1136,r; 
}

	ld.shared.u32 %r8373, [%r8165+12676];
shr.s32 %r8374, %r8373, %r8138;
and.b32 %r6516, %r8374, 50529027;
ld.shared.u32 %r8375, [%r8369+4];
shr.s32 %r8376, %r8375, %r8178;
shl.b32 %r8377, %r8376, 2;
and.b32 %r6517, %r8377, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1139,r; 
}

	ld.shared.u32 %r8378, [%r8165+12680];
shr.s32 %r8379, %r8378, %r8138;
and.b32 %r6519, %r8379, 50529027;
ld.shared.u32 %r8380, [%r8369+8];
shr.s32 %r8381, %r8380, %r8178;
shl.b32 %r8382, %r8381, 2;
and.b32 %r6520, %r8382, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1142,r; 
}

	ld.shared.u32 %r8383, [%r8165+12684];
shr.s32 %r8384, %r8383, %r8138;
and.b32 %r6522, %r8384, 50529027;
ld.shared.u32 %r8385, [%r8369+12];
shr.s32 %r8386, %r8385, %r8178;
shl.b32 %r8387, %r8386, 2;
and.b32 %r6523, %r8387, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1145,r; 
}

	ld.shared.u32 %r8388, [%r8165+12688];
shr.s32 %r8389, %r8388, %r8138;
and.b32 %r6525, %r8389, 50529027;
ld.shared.u32 %r8390, [%r8369+16];
shr.s32 %r8391, %r8390, %r8178;
shl.b32 %r8392, %r8391, 2;
and.b32 %r6526, %r8392, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1148,r; 
}

	ld.shared.u32 %r8393, [%r8165+12692];
shr.s32 %r8394, %r8393, %r8138;
and.b32 %r6528, %r8394, 50529027;
ld.shared.u32 %r8395, [%r8369+20];
shr.s32 %r8396, %r8395, %r8178;
shl.b32 %r8397, %r8396, 2;
and.b32 %r6529, %r8397, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1151,r; 
}

	ld.shared.u32 %r8398, [%r8165+12696];
shr.s32 %r8399, %r8398, %r8138;
and.b32 %r6531, %r8399, 50529027;
ld.shared.u32 %r8400, [%r8369+24];
shr.s32 %r8401, %r8400, %r8178;
shl.b32 %r8402, %r8401, 2;
and.b32 %r6532, %r8402, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1154,r; 
}

	ld.shared.u32 %r8403, [%r8165+12700];
shr.s32 %r8404, %r8403, %r8138;
and.b32 %r6534, %r8404, 50529027;
ld.shared.u32 %r8405, [%r8369+28];
shr.s32 %r8406, %r8405, %r8178;
shl.b32 %r8407, %r8406, 2;
and.b32 %r6535, %r8407, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1157,r; 
}

	shr.u32 %r8408, %r8355, 4;
add.s32 %r8409, %r8408, %r8136;
shl.b32 %r8410, %r8355, 1;
add.s32 %r8411, %r8409, %r8410;
shl.b32 %r8412, %r8411, 2;
add.s32 %r8413, %r111, %r8412;

	dp4a.s32.s32 %r1160, %r1136, %r994, %r8123;

	
	dp4a.s32.s32 %r1164, %r1139, %r1166, %r1160;

	
	dp4a.s32.s32 %r1168, %r1142, %r1170, %r1164;

	
	dp4a.s32.s32 %r1172, %r1145, %r1174, %r1168;

	add.s32 %r8414, %r8365, %r8171;
ld.shared.s8 %r8415, [%r8414];
mul.lo.s32 %r8416, %r1172, %r8415;

	dp4a.s32.s32 %r1176, %r1148, %r1178, %r8123;

	
	dp4a.s32.s32 %r1180, %r1151, %r1182, %r1176;

	
	dp4a.s32.s32 %r1184, %r1154, %r1186, %r1180;

	
	dp4a.s32.s32 %r1188, %r1157, %r1190, %r1184;

	ld.shared.s8 %r8417, [%r8414+1];
mad.lo.s32 %r8418, %r1188, %r8417, %r8416;
ld.shared.f32 %f1041, [%r8413];
mul.ftz.f32 %f1042, %f1041, %f1031;
cvt.rn.f32.s32 %f1043, %r8418;
fma.rn.ftz.f32 %f1742, %f1042, %f1043, %f1742;
add.s32 %r8419, %r8146, 128;
shr.u32 %r8420, %r8419, 1;
add.s32 %r8421, %r9004, %r8420;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1192,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1195,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1198,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1201,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1204,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1207,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1210,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1213,r; 
}

	ld.shared.u32 %r1386, [%r8221+512];

	dp4a.s32.s32 %r1216, %r1192, %r1386, %r8123;

	ld.shared.u32 %r1390, [%r8221+516];

	dp4a.s32.s32 %r1220, %r1195, %r1390, %r1216;

	ld.shared.u32 %r1394, [%r8221+520];

	dp4a.s32.s32 %r1224, %r1198, %r1394, %r1220;

	ld.shared.u32 %r1398, [%r8221+524];

	dp4a.s32.s32 %r1228, %r1201, %r1398, %r1224;

	mul.lo.s32 %r8422, %r1228, %r8223;
ld.shared.u32 %r1402, [%r8221+528];

	dp4a.s32.s32 %r1232, %r1204, %r1402, %r8123;

	ld.shared.u32 %r1406, [%r8221+532];

	dp4a.s32.s32 %r1236, %r1207, %r1406, %r1232;

	ld.shared.u32 %r1410, [%r8221+536];

	dp4a.s32.s32 %r1240, %r1210, %r1410, %r1236;

	ld.shared.u32 %r1414, [%r8221+540];

	dp4a.s32.s32 %r1244, %r1213, %r1414, %r1240;

	mad.lo.s32 %r8423, %r1244, %r8225, %r8422;
ld.shared.f32 %f1044, [%r8421];
mul.ftz.f32 %f1045, %f1032, %f1044;
cvt.rn.f32.s32 %f1046, %r8423;
fma.rn.ftz.f32 %f1837, %f1045, %f1046, %f1837;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1248,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1251,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1254,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1257,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1260,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1263,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1266,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1269,r; 
}

	
	dp4a.s32.s32 %r1272, %r1248, %r1386, %r8123;

	
	dp4a.s32.s32 %r1276, %r1251, %r1390, %r1272;

	
	dp4a.s32.s32 %r1280, %r1254, %r1394, %r1276;

	
	dp4a.s32.s32 %r1284, %r1257, %r1398, %r1280;

	mul.lo.s32 %r8424, %r1284, %r8287;

	dp4a.s32.s32 %r1288, %r1260, %r1402, %r8123;

	
	dp4a.s32.s32 %r1292, %r1263, %r1406, %r1288;

	
	dp4a.s32.s32 %r1296, %r1266, %r1410, %r1292;

	
	dp4a.s32.s32 %r1300, %r1269, %r1414, %r1296;

	mad.lo.s32 %r8425, %r1300, %r8289, %r8424;
mul.ftz.f32 %f1047, %f1035, %f1044;
cvt.rn.f32.s32 %f1048, %r8425;
fma.rn.ftz.f32 %f1805, %f1047, %f1048, %f1805;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1304,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1307,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1310,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1313,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1316,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1319,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1322,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1325,r; 
}

	
	dp4a.s32.s32 %r1328, %r1304, %r1386, %r8123;

	
	dp4a.s32.s32 %r1332, %r1307, %r1390, %r1328;

	
	dp4a.s32.s32 %r1336, %r1310, %r1394, %r1332;

	
	dp4a.s32.s32 %r1340, %r1313, %r1398, %r1336;

	mul.lo.s32 %r8426, %r1340, %r8351;

	dp4a.s32.s32 %r1344, %r1316, %r1402, %r8123;

	
	dp4a.s32.s32 %r1348, %r1319, %r1406, %r1344;

	
	dp4a.s32.s32 %r1352, %r1322, %r1410, %r1348;

	
	dp4a.s32.s32 %r1356, %r1325, %r1414, %r1352;

	mad.lo.s32 %r8427, %r1356, %r8353, %r8426;
mul.ftz.f32 %f1049, %f1038, %f1044;
cvt.rn.f32.s32 %f1050, %r8427;
fma.rn.ftz.f32 %f1773, %f1049, %f1050, %f1773;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1360,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1363,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1366,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1369,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1372,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1375,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1378,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1381,r; 
}

	
	dp4a.s32.s32 %r1384, %r1360, %r1386, %r8123;

	
	dp4a.s32.s32 %r1388, %r1363, %r1390, %r1384;

	
	dp4a.s32.s32 %r1392, %r1366, %r1394, %r1388;

	
	dp4a.s32.s32 %r1396, %r1369, %r1398, %r1392;

	mul.lo.s32 %r8428, %r1396, %r8415;

	dp4a.s32.s32 %r1400, %r1372, %r1402, %r8123;

	
	dp4a.s32.s32 %r1404, %r1375, %r1406, %r1400;

	
	dp4a.s32.s32 %r1408, %r1378, %r1410, %r1404;

	
	dp4a.s32.s32 %r1412, %r1381, %r1414, %r1408;

	mad.lo.s32 %r8429, %r1412, %r8417, %r8428;
mul.ftz.f32 %f1051, %f1041, %f1044;
cvt.rn.f32.s32 %f1052, %r8429;
fma.rn.ftz.f32 %f1741, %f1051, %f1052, %f1741;
add.s32 %r8430, %r8146, 256;
shr.u32 %r8431, %r8430, 1;
add.s32 %r8432, %r9004, %r8431;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1416,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1419,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1422,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1425,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1428,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1431,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1434,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1437,r; 
}

	ld.shared.u32 %r1610, [%r8221+1024];

	dp4a.s32.s32 %r1440, %r1416, %r1610, %r8123;

	ld.shared.u32 %r1614, [%r8221+1028];

	dp4a.s32.s32 %r1444, %r1419, %r1614, %r1440;

	ld.shared.u32 %r1618, [%r8221+1032];

	dp4a.s32.s32 %r1448, %r1422, %r1618, %r1444;

	ld.shared.u32 %r1622, [%r8221+1036];

	dp4a.s32.s32 %r1452, %r1425, %r1622, %r1448;

	mul.lo.s32 %r8433, %r1452, %r8223;
ld.shared.u32 %r1626, [%r8221+1040];

	dp4a.s32.s32 %r1456, %r1428, %r1626, %r8123;

	ld.shared.u32 %r1630, [%r8221+1044];

	dp4a.s32.s32 %r1460, %r1431, %r1630, %r1456;

	ld.shared.u32 %r1634, [%r8221+1048];

	dp4a.s32.s32 %r1464, %r1434, %r1634, %r1460;

	ld.shared.u32 %r1638, [%r8221+1052];

	dp4a.s32.s32 %r1468, %r1437, %r1638, %r1464;

	mad.lo.s32 %r8434, %r1468, %r8225, %r8433;
ld.shared.f32 %f1053, [%r8432];
mul.ftz.f32 %f1054, %f1032, %f1053;
cvt.rn.f32.s32 %f1055, %r8434;
fma.rn.ftz.f32 %f1836, %f1054, %f1055, %f1836;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1472,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1475,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1478,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1481,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1484,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1487,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1490,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1493,r; 
}

	
	dp4a.s32.s32 %r1496, %r1472, %r1610, %r8123;

	
	dp4a.s32.s32 %r1500, %r1475, %r1614, %r1496;

	
	dp4a.s32.s32 %r1504, %r1478, %r1618, %r1500;

	
	dp4a.s32.s32 %r1508, %r1481, %r1622, %r1504;

	mul.lo.s32 %r8435, %r1508, %r8287;

	dp4a.s32.s32 %r1512, %r1484, %r1626, %r8123;

	
	dp4a.s32.s32 %r1516, %r1487, %r1630, %r1512;

	
	dp4a.s32.s32 %r1520, %r1490, %r1634, %r1516;

	
	dp4a.s32.s32 %r1524, %r1493, %r1638, %r1520;

	mad.lo.s32 %r8436, %r1524, %r8289, %r8435;
mul.ftz.f32 %f1056, %f1035, %f1053;
cvt.rn.f32.s32 %f1057, %r8436;
fma.rn.ftz.f32 %f1804, %f1056, %f1057, %f1804;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1528,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1531,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1534,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1537,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1540,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1543,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1546,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1549,r; 
}

	
	dp4a.s32.s32 %r1552, %r1528, %r1610, %r8123;

	
	dp4a.s32.s32 %r1556, %r1531, %r1614, %r1552;

	
	dp4a.s32.s32 %r1560, %r1534, %r1618, %r1556;

	
	dp4a.s32.s32 %r1564, %r1537, %r1622, %r1560;

	mul.lo.s32 %r8437, %r1564, %r8351;

	dp4a.s32.s32 %r1568, %r1540, %r1626, %r8123;

	
	dp4a.s32.s32 %r1572, %r1543, %r1630, %r1568;

	
	dp4a.s32.s32 %r1576, %r1546, %r1634, %r1572;

	
	dp4a.s32.s32 %r1580, %r1549, %r1638, %r1576;

	mad.lo.s32 %r8438, %r1580, %r8353, %r8437;
mul.ftz.f32 %f1058, %f1038, %f1053;
cvt.rn.f32.s32 %f1059, %r8438;
fma.rn.ftz.f32 %f1772, %f1058, %f1059, %f1772;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1584,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1587,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1590,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1593,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1596,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1599,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1602,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1605,r; 
}

	
	dp4a.s32.s32 %r1608, %r1584, %r1610, %r8123;

	
	dp4a.s32.s32 %r1612, %r1587, %r1614, %r1608;

	
	dp4a.s32.s32 %r1616, %r1590, %r1618, %r1612;

	
	dp4a.s32.s32 %r1620, %r1593, %r1622, %r1616;

	mul.lo.s32 %r8439, %r1620, %r8415;

	dp4a.s32.s32 %r1624, %r1596, %r1626, %r8123;

	
	dp4a.s32.s32 %r1628, %r1599, %r1630, %r1624;

	
	dp4a.s32.s32 %r1632, %r1602, %r1634, %r1628;

	
	dp4a.s32.s32 %r1636, %r1605, %r1638, %r1632;

	mad.lo.s32 %r8440, %r1636, %r8417, %r8439;
mul.ftz.f32 %f1060, %f1041, %f1053;
cvt.rn.f32.s32 %f1061, %r8440;
fma.rn.ftz.f32 %f1740, %f1060, %f1061, %f1740;
add.s32 %r8441, %r8146, 384;
shr.u32 %r8442, %r8441, 1;
add.s32 %r8443, %r9004, %r8442;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1640,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1643,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1646,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1649,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1652,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1655,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1658,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1661,r; 
}

	ld.shared.u32 %r1834, [%r8221+1536];

	dp4a.s32.s32 %r1664, %r1640, %r1834, %r8123;

	ld.shared.u32 %r1838, [%r8221+1540];

	dp4a.s32.s32 %r1668, %r1643, %r1838, %r1664;

	ld.shared.u32 %r1842, [%r8221+1544];

	dp4a.s32.s32 %r1672, %r1646, %r1842, %r1668;

	ld.shared.u32 %r1846, [%r8221+1548];

	dp4a.s32.s32 %r1676, %r1649, %r1846, %r1672;

	mul.lo.s32 %r8444, %r1676, %r8223;
ld.shared.u32 %r1850, [%r8221+1552];

	dp4a.s32.s32 %r1680, %r1652, %r1850, %r8123;

	ld.shared.u32 %r1854, [%r8221+1556];

	dp4a.s32.s32 %r1684, %r1655, %r1854, %r1680;

	ld.shared.u32 %r1858, [%r8221+1560];

	dp4a.s32.s32 %r1688, %r1658, %r1858, %r1684;

	ld.shared.u32 %r1862, [%r8221+1564];

	dp4a.s32.s32 %r1692, %r1661, %r1862, %r1688;

	mad.lo.s32 %r8445, %r1692, %r8225, %r8444;
ld.shared.f32 %f1062, [%r8443];
mul.ftz.f32 %f1063, %f1032, %f1062;
cvt.rn.f32.s32 %f1064, %r8445;
fma.rn.ftz.f32 %f1835, %f1063, %f1064, %f1835;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1696,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1699,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1702,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1705,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1708,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1711,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1714,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1717,r; 
}

	
	dp4a.s32.s32 %r1720, %r1696, %r1834, %r8123;

	
	dp4a.s32.s32 %r1724, %r1699, %r1838, %r1720;

	
	dp4a.s32.s32 %r1728, %r1702, %r1842, %r1724;

	
	dp4a.s32.s32 %r1732, %r1705, %r1846, %r1728;

	mul.lo.s32 %r8446, %r1732, %r8287;

	dp4a.s32.s32 %r1736, %r1708, %r1850, %r8123;

	
	dp4a.s32.s32 %r1740, %r1711, %r1854, %r1736;

	
	dp4a.s32.s32 %r1744, %r1714, %r1858, %r1740;

	
	dp4a.s32.s32 %r1748, %r1717, %r1862, %r1744;

	mad.lo.s32 %r8447, %r1748, %r8289, %r8446;
mul.ftz.f32 %f1065, %f1035, %f1062;
cvt.rn.f32.s32 %f1066, %r8447;
fma.rn.ftz.f32 %f1803, %f1065, %f1066, %f1803;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1752,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1755,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1758,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1761,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1764,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1767,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1770,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1773,r; 
}

	
	dp4a.s32.s32 %r1776, %r1752, %r1834, %r8123;

	
	dp4a.s32.s32 %r1780, %r1755, %r1838, %r1776;

	
	dp4a.s32.s32 %r1784, %r1758, %r1842, %r1780;

	
	dp4a.s32.s32 %r1788, %r1761, %r1846, %r1784;

	mul.lo.s32 %r8448, %r1788, %r8351;

	dp4a.s32.s32 %r1792, %r1764, %r1850, %r8123;

	
	dp4a.s32.s32 %r1796, %r1767, %r1854, %r1792;

	
	dp4a.s32.s32 %r1800, %r1770, %r1858, %r1796;

	
	dp4a.s32.s32 %r1804, %r1773, %r1862, %r1800;

	mad.lo.s32 %r8449, %r1804, %r8353, %r8448;
mul.ftz.f32 %f1067, %f1038, %f1062;
cvt.rn.f32.s32 %f1068, %r8449;
fma.rn.ftz.f32 %f1771, %f1067, %f1068, %f1771;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1808,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1811,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1814,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1817,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1820,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1823,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1826,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1829,r; 
}

	
	dp4a.s32.s32 %r1832, %r1808, %r1834, %r8123;

	
	dp4a.s32.s32 %r1836, %r1811, %r1838, %r1832;

	
	dp4a.s32.s32 %r1840, %r1814, %r1842, %r1836;

	
	dp4a.s32.s32 %r1844, %r1817, %r1846, %r1840;

	mul.lo.s32 %r8450, %r1844, %r8415;

	dp4a.s32.s32 %r1848, %r1820, %r1850, %r8123;

	
	dp4a.s32.s32 %r1852, %r1823, %r1854, %r1848;

	
	dp4a.s32.s32 %r1856, %r1826, %r1858, %r1852;

	
	dp4a.s32.s32 %r1860, %r1829, %r1862, %r1856;

	mad.lo.s32 %r8451, %r1860, %r8417, %r8450;
mul.ftz.f32 %f1069, %f1041, %f1062;
cvt.rn.f32.s32 %f1070, %r8451;
fma.rn.ftz.f32 %f1739, %f1069, %f1070, %f1739;
add.s32 %r8452, %r8146, 512;
shr.u32 %r8453, %r8452, 1;
add.s32 %r8454, %r9004, %r8453;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1864,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1867,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1870,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1873,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1876,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1879,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1882,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1885,r; 
}

	ld.shared.u32 %r2058, [%r8221+2048];

	dp4a.s32.s32 %r1888, %r1864, %r2058, %r8123;

	ld.shared.u32 %r2062, [%r8221+2052];

	dp4a.s32.s32 %r1892, %r1867, %r2062, %r1888;

	ld.shared.u32 %r2066, [%r8221+2056];

	dp4a.s32.s32 %r1896, %r1870, %r2066, %r1892;

	ld.shared.u32 %r2070, [%r8221+2060];

	dp4a.s32.s32 %r1900, %r1873, %r2070, %r1896;

	mul.lo.s32 %r8455, %r1900, %r8223;
ld.shared.u32 %r2074, [%r8221+2064];

	dp4a.s32.s32 %r1904, %r1876, %r2074, %r8123;

	ld.shared.u32 %r2078, [%r8221+2068];

	dp4a.s32.s32 %r1908, %r1879, %r2078, %r1904;

	ld.shared.u32 %r2082, [%r8221+2072];

	dp4a.s32.s32 %r1912, %r1882, %r2082, %r1908;

	ld.shared.u32 %r2086, [%r8221+2076];

	dp4a.s32.s32 %r1916, %r1885, %r2086, %r1912;

	mad.lo.s32 %r8456, %r1916, %r8225, %r8455;
ld.shared.f32 %f1071, [%r8454];
mul.ftz.f32 %f1072, %f1032, %f1071;
cvt.rn.f32.s32 %f1073, %r8456;
fma.rn.ftz.f32 %f1834, %f1072, %f1073, %f1834;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1920,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1923,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1926,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1929,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1932,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1935,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1938,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1941,r; 
}

	
	dp4a.s32.s32 %r1944, %r1920, %r2058, %r8123;

	
	dp4a.s32.s32 %r1948, %r1923, %r2062, %r1944;

	
	dp4a.s32.s32 %r1952, %r1926, %r2066, %r1948;

	
	dp4a.s32.s32 %r1956, %r1929, %r2070, %r1952;

	mul.lo.s32 %r8457, %r1956, %r8287;

	dp4a.s32.s32 %r1960, %r1932, %r2074, %r8123;

	
	dp4a.s32.s32 %r1964, %r1935, %r2078, %r1960;

	
	dp4a.s32.s32 %r1968, %r1938, %r2082, %r1964;

	
	dp4a.s32.s32 %r1972, %r1941, %r2086, %r1968;

	mad.lo.s32 %r8458, %r1972, %r8289, %r8457;
mul.ftz.f32 %f1074, %f1035, %f1071;
cvt.rn.f32.s32 %f1075, %r8458;
fma.rn.ftz.f32 %f1802, %f1074, %f1075, %f1802;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1976,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1979,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1982,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1985,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1988,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1991,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1994,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r1997,r; 
}

	
	dp4a.s32.s32 %r2000, %r1976, %r2058, %r8123;

	
	dp4a.s32.s32 %r2004, %r1979, %r2062, %r2000;

	
	dp4a.s32.s32 %r2008, %r1982, %r2066, %r2004;

	
	dp4a.s32.s32 %r2012, %r1985, %r2070, %r2008;

	mul.lo.s32 %r8459, %r2012, %r8351;

	dp4a.s32.s32 %r2016, %r1988, %r2074, %r8123;

	
	dp4a.s32.s32 %r2020, %r1991, %r2078, %r2016;

	
	dp4a.s32.s32 %r2024, %r1994, %r2082, %r2020;

	
	dp4a.s32.s32 %r2028, %r1997, %r2086, %r2024;

	mad.lo.s32 %r8460, %r2028, %r8353, %r8459;
mul.ftz.f32 %f1076, %f1038, %f1071;
cvt.rn.f32.s32 %f1077, %r8460;
fma.rn.ftz.f32 %f1770, %f1076, %f1077, %f1770;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2032,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2035,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2038,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2041,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2044,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2047,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2050,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2053,r; 
}

	
	dp4a.s32.s32 %r2056, %r2032, %r2058, %r8123;

	
	dp4a.s32.s32 %r2060, %r2035, %r2062, %r2056;

	
	dp4a.s32.s32 %r2064, %r2038, %r2066, %r2060;

	
	dp4a.s32.s32 %r2068, %r2041, %r2070, %r2064;

	mul.lo.s32 %r8461, %r2068, %r8415;

	dp4a.s32.s32 %r2072, %r2044, %r2074, %r8123;

	
	dp4a.s32.s32 %r2076, %r2047, %r2078, %r2072;

	
	dp4a.s32.s32 %r2080, %r2050, %r2082, %r2076;

	
	dp4a.s32.s32 %r2084, %r2053, %r2086, %r2080;

	mad.lo.s32 %r8462, %r2084, %r8417, %r8461;
mul.ftz.f32 %f1078, %f1041, %f1071;
cvt.rn.f32.s32 %f1079, %r8462;
fma.rn.ftz.f32 %f1738, %f1078, %f1079, %f1738;
add.s32 %r8463, %r8146, 640;
shr.u32 %r8464, %r8463, 1;
add.s32 %r8465, %r9004, %r8464;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2088,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2091,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2094,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2097,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2100,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2103,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2106,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2109,r; 
}

	ld.shared.u32 %r2282, [%r8221+2560];

	dp4a.s32.s32 %r2112, %r2088, %r2282, %r8123;

	ld.shared.u32 %r2286, [%r8221+2564];

	dp4a.s32.s32 %r2116, %r2091, %r2286, %r2112;

	ld.shared.u32 %r2290, [%r8221+2568];

	dp4a.s32.s32 %r2120, %r2094, %r2290, %r2116;

	ld.shared.u32 %r2294, [%r8221+2572];

	dp4a.s32.s32 %r2124, %r2097, %r2294, %r2120;

	mul.lo.s32 %r8466, %r2124, %r8223;
ld.shared.u32 %r2298, [%r8221+2576];

	dp4a.s32.s32 %r2128, %r2100, %r2298, %r8123;

	ld.shared.u32 %r2302, [%r8221+2580];

	dp4a.s32.s32 %r2132, %r2103, %r2302, %r2128;

	ld.shared.u32 %r2306, [%r8221+2584];

	dp4a.s32.s32 %r2136, %r2106, %r2306, %r2132;

	ld.shared.u32 %r2310, [%r8221+2588];

	dp4a.s32.s32 %r2140, %r2109, %r2310, %r2136;

	mad.lo.s32 %r8467, %r2140, %r8225, %r8466;
ld.shared.f32 %f1080, [%r8465];
mul.ftz.f32 %f1081, %f1032, %f1080;
cvt.rn.f32.s32 %f1082, %r8467;
fma.rn.ftz.f32 %f1833, %f1081, %f1082, %f1833;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2144,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2147,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2150,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2153,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2156,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2159,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2162,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2165,r; 
}

	
	dp4a.s32.s32 %r2168, %r2144, %r2282, %r8123;

	
	dp4a.s32.s32 %r2172, %r2147, %r2286, %r2168;

	
	dp4a.s32.s32 %r2176, %r2150, %r2290, %r2172;

	
	dp4a.s32.s32 %r2180, %r2153, %r2294, %r2176;

	mul.lo.s32 %r8468, %r2180, %r8287;

	dp4a.s32.s32 %r2184, %r2156, %r2298, %r8123;

	
	dp4a.s32.s32 %r2188, %r2159, %r2302, %r2184;

	
	dp4a.s32.s32 %r2192, %r2162, %r2306, %r2188;

	
	dp4a.s32.s32 %r2196, %r2165, %r2310, %r2192;

	mad.lo.s32 %r8469, %r2196, %r8289, %r8468;
mul.ftz.f32 %f1083, %f1035, %f1080;
cvt.rn.f32.s32 %f1084, %r8469;
fma.rn.ftz.f32 %f1801, %f1083, %f1084, %f1801;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2200,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2203,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2206,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2209,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2212,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2215,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2218,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2221,r; 
}

	
	dp4a.s32.s32 %r2224, %r2200, %r2282, %r8123;

	
	dp4a.s32.s32 %r2228, %r2203, %r2286, %r2224;

	
	dp4a.s32.s32 %r2232, %r2206, %r2290, %r2228;

	
	dp4a.s32.s32 %r2236, %r2209, %r2294, %r2232;

	mul.lo.s32 %r8470, %r2236, %r8351;

	dp4a.s32.s32 %r2240, %r2212, %r2298, %r8123;

	
	dp4a.s32.s32 %r2244, %r2215, %r2302, %r2240;

	
	dp4a.s32.s32 %r2248, %r2218, %r2306, %r2244;

	
	dp4a.s32.s32 %r2252, %r2221, %r2310, %r2248;

	mad.lo.s32 %r8471, %r2252, %r8353, %r8470;
mul.ftz.f32 %f1085, %f1038, %f1080;
cvt.rn.f32.s32 %f1086, %r8471;
fma.rn.ftz.f32 %f1769, %f1085, %f1086, %f1769;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2256,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2259,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2262,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2265,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2268,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2271,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2274,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2277,r; 
}

	
	dp4a.s32.s32 %r2280, %r2256, %r2282, %r8123;

	
	dp4a.s32.s32 %r2284, %r2259, %r2286, %r2280;

	
	dp4a.s32.s32 %r2288, %r2262, %r2290, %r2284;

	
	dp4a.s32.s32 %r2292, %r2265, %r2294, %r2288;

	mul.lo.s32 %r8472, %r2292, %r8415;

	dp4a.s32.s32 %r2296, %r2268, %r2298, %r8123;

	
	dp4a.s32.s32 %r2300, %r2271, %r2302, %r2296;

	
	dp4a.s32.s32 %r2304, %r2274, %r2306, %r2300;

	
	dp4a.s32.s32 %r2308, %r2277, %r2310, %r2304;

	mad.lo.s32 %r8473, %r2308, %r8417, %r8472;
mul.ftz.f32 %f1087, %f1041, %f1080;
cvt.rn.f32.s32 %f1088, %r8473;
fma.rn.ftz.f32 %f1737, %f1087, %f1088, %f1737;
add.s32 %r8474, %r8146, 768;
shr.u32 %r8475, %r8474, 1;
add.s32 %r8476, %r9004, %r8475;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2312,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2315,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2318,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2321,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2324,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2327,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2330,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2333,r; 
}

	ld.shared.u32 %r2506, [%r8221+3072];

	dp4a.s32.s32 %r2336, %r2312, %r2506, %r8123;

	ld.shared.u32 %r2510, [%r8221+3076];

	dp4a.s32.s32 %r2340, %r2315, %r2510, %r2336;

	ld.shared.u32 %r2514, [%r8221+3080];

	dp4a.s32.s32 %r2344, %r2318, %r2514, %r2340;

	ld.shared.u32 %r2518, [%r8221+3084];

	dp4a.s32.s32 %r2348, %r2321, %r2518, %r2344;

	mul.lo.s32 %r8477, %r2348, %r8223;
ld.shared.u32 %r2522, [%r8221+3088];

	dp4a.s32.s32 %r2352, %r2324, %r2522, %r8123;

	ld.shared.u32 %r2526, [%r8221+3092];

	dp4a.s32.s32 %r2356, %r2327, %r2526, %r2352;

	ld.shared.u32 %r2530, [%r8221+3096];

	dp4a.s32.s32 %r2360, %r2330, %r2530, %r2356;

	ld.shared.u32 %r2534, [%r8221+3100];

	dp4a.s32.s32 %r2364, %r2333, %r2534, %r2360;

	mad.lo.s32 %r8478, %r2364, %r8225, %r8477;
ld.shared.f32 %f1089, [%r8476];
mul.ftz.f32 %f1090, %f1032, %f1089;
cvt.rn.f32.s32 %f1091, %r8478;
fma.rn.ftz.f32 %f1832, %f1090, %f1091, %f1832;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2368,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2371,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2374,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2377,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2380,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2383,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2386,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2389,r; 
}

	
	dp4a.s32.s32 %r2392, %r2368, %r2506, %r8123;

	
	dp4a.s32.s32 %r2396, %r2371, %r2510, %r2392;

	
	dp4a.s32.s32 %r2400, %r2374, %r2514, %r2396;

	
	dp4a.s32.s32 %r2404, %r2377, %r2518, %r2400;

	mul.lo.s32 %r8479, %r2404, %r8287;

	dp4a.s32.s32 %r2408, %r2380, %r2522, %r8123;

	
	dp4a.s32.s32 %r2412, %r2383, %r2526, %r2408;

	
	dp4a.s32.s32 %r2416, %r2386, %r2530, %r2412;

	
	dp4a.s32.s32 %r2420, %r2389, %r2534, %r2416;

	mad.lo.s32 %r8480, %r2420, %r8289, %r8479;
mul.ftz.f32 %f1092, %f1035, %f1089;
cvt.rn.f32.s32 %f1093, %r8480;
fma.rn.ftz.f32 %f1800, %f1092, %f1093, %f1800;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2424,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2427,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2430,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2433,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2436,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2439,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2442,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2445,r; 
}

	
	dp4a.s32.s32 %r2448, %r2424, %r2506, %r8123;

	
	dp4a.s32.s32 %r2452, %r2427, %r2510, %r2448;

	
	dp4a.s32.s32 %r2456, %r2430, %r2514, %r2452;

	
	dp4a.s32.s32 %r2460, %r2433, %r2518, %r2456;

	mul.lo.s32 %r8481, %r2460, %r8351;

	dp4a.s32.s32 %r2464, %r2436, %r2522, %r8123;

	
	dp4a.s32.s32 %r2468, %r2439, %r2526, %r2464;

	
	dp4a.s32.s32 %r2472, %r2442, %r2530, %r2468;

	
	dp4a.s32.s32 %r2476, %r2445, %r2534, %r2472;

	mad.lo.s32 %r8482, %r2476, %r8353, %r8481;
mul.ftz.f32 %f1094, %f1038, %f1089;
cvt.rn.f32.s32 %f1095, %r8482;
fma.rn.ftz.f32 %f1768, %f1094, %f1095, %f1768;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2480,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2483,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2486,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2489,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2492,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2495,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2498,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2501,r; 
}

	
	dp4a.s32.s32 %r2504, %r2480, %r2506, %r8123;

	
	dp4a.s32.s32 %r2508, %r2483, %r2510, %r2504;

	
	dp4a.s32.s32 %r2512, %r2486, %r2514, %r2508;

	
	dp4a.s32.s32 %r2516, %r2489, %r2518, %r2512;

	mul.lo.s32 %r8483, %r2516, %r8415;

	dp4a.s32.s32 %r2520, %r2492, %r2522, %r8123;

	
	dp4a.s32.s32 %r2524, %r2495, %r2526, %r2520;

	
	dp4a.s32.s32 %r2528, %r2498, %r2530, %r2524;

	
	dp4a.s32.s32 %r2532, %r2501, %r2534, %r2528;

	mad.lo.s32 %r8484, %r2532, %r8417, %r8483;
mul.ftz.f32 %f1096, %f1041, %f1089;
cvt.rn.f32.s32 %f1097, %r8484;
fma.rn.ftz.f32 %f1736, %f1096, %f1097, %f1736;
add.s32 %r8485, %r8146, 896;
shr.u32 %r8486, %r8485, 1;
add.s32 %r8487, %r9004, %r8486;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2536,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2539,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2542,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2545,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2548,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2551,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2554,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2557,r; 
}

	ld.shared.u32 %r2730, [%r8221+3584];

	dp4a.s32.s32 %r2560, %r2536, %r2730, %r8123;

	ld.shared.u32 %r2734, [%r8221+3588];

	dp4a.s32.s32 %r2564, %r2539, %r2734, %r2560;

	ld.shared.u32 %r2738, [%r8221+3592];

	dp4a.s32.s32 %r2568, %r2542, %r2738, %r2564;

	ld.shared.u32 %r2742, [%r8221+3596];

	dp4a.s32.s32 %r2572, %r2545, %r2742, %r2568;

	mul.lo.s32 %r8488, %r2572, %r8223;
ld.shared.u32 %r2746, [%r8221+3600];

	dp4a.s32.s32 %r2576, %r2548, %r2746, %r8123;

	ld.shared.u32 %r2750, [%r8221+3604];

	dp4a.s32.s32 %r2580, %r2551, %r2750, %r2576;

	ld.shared.u32 %r2754, [%r8221+3608];

	dp4a.s32.s32 %r2584, %r2554, %r2754, %r2580;

	ld.shared.u32 %r2758, [%r8221+3612];

	dp4a.s32.s32 %r2588, %r2557, %r2758, %r2584;

	mad.lo.s32 %r8489, %r2588, %r8225, %r8488;
ld.shared.f32 %f1098, [%r8487];
mul.ftz.f32 %f1099, %f1032, %f1098;
cvt.rn.f32.s32 %f1100, %r8489;
fma.rn.ftz.f32 %f1831, %f1099, %f1100, %f1831;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2592,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2595,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2598,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2601,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2604,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2607,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2610,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2613,r; 
}

	
	dp4a.s32.s32 %r2616, %r2592, %r2730, %r8123;

	
	dp4a.s32.s32 %r2620, %r2595, %r2734, %r2616;

	
	dp4a.s32.s32 %r2624, %r2598, %r2738, %r2620;

	
	dp4a.s32.s32 %r2628, %r2601, %r2742, %r2624;

	mul.lo.s32 %r8490, %r2628, %r8287;

	dp4a.s32.s32 %r2632, %r2604, %r2746, %r8123;

	
	dp4a.s32.s32 %r2636, %r2607, %r2750, %r2632;

	
	dp4a.s32.s32 %r2640, %r2610, %r2754, %r2636;

	
	dp4a.s32.s32 %r2644, %r2613, %r2758, %r2640;

	mad.lo.s32 %r8491, %r2644, %r8289, %r8490;
mul.ftz.f32 %f1101, %f1035, %f1098;
cvt.rn.f32.s32 %f1102, %r8491;
fma.rn.ftz.f32 %f1799, %f1101, %f1102, %f1799;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2648,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2651,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2654,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2657,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2660,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2663,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2666,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2669,r; 
}

	
	dp4a.s32.s32 %r2672, %r2648, %r2730, %r8123;

	
	dp4a.s32.s32 %r2676, %r2651, %r2734, %r2672;

	
	dp4a.s32.s32 %r2680, %r2654, %r2738, %r2676;

	
	dp4a.s32.s32 %r2684, %r2657, %r2742, %r2680;

	mul.lo.s32 %r8492, %r2684, %r8351;

	dp4a.s32.s32 %r2688, %r2660, %r2746, %r8123;

	
	dp4a.s32.s32 %r2692, %r2663, %r2750, %r2688;

	
	dp4a.s32.s32 %r2696, %r2666, %r2754, %r2692;

	
	dp4a.s32.s32 %r2700, %r2669, %r2758, %r2696;

	mad.lo.s32 %r8493, %r2700, %r8353, %r8492;
mul.ftz.f32 %f1103, %f1038, %f1098;
cvt.rn.f32.s32 %f1104, %r8493;
fma.rn.ftz.f32 %f1767, %f1103, %f1104, %f1767;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2704,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2707,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2710,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2713,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2716,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2719,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2722,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2725,r; 
}

	
	dp4a.s32.s32 %r2728, %r2704, %r2730, %r8123;

	
	dp4a.s32.s32 %r2732, %r2707, %r2734, %r2728;

	
	dp4a.s32.s32 %r2736, %r2710, %r2738, %r2732;

	
	dp4a.s32.s32 %r2740, %r2713, %r2742, %r2736;

	mul.lo.s32 %r8494, %r2740, %r8415;

	dp4a.s32.s32 %r2744, %r2716, %r2746, %r8123;

	
	dp4a.s32.s32 %r2748, %r2719, %r2750, %r2744;

	
	dp4a.s32.s32 %r2752, %r2722, %r2754, %r2748;

	
	dp4a.s32.s32 %r2756, %r2725, %r2758, %r2752;

	mad.lo.s32 %r8495, %r2756, %r8417, %r8494;
mul.ftz.f32 %f1105, %f1041, %f1098;
cvt.rn.f32.s32 %f1106, %r8495;
fma.rn.ftz.f32 %f1735, %f1105, %f1106, %f1735;
add.s32 %r8496, %r8146, 1024;
shr.u32 %r8497, %r8496, 1;
add.s32 %r8498, %r9004, %r8497;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2760,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2763,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2766,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2769,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2772,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2775,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2778,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2781,r; 
}

	ld.shared.u32 %r2954, [%r8221+4096];

	dp4a.s32.s32 %r2784, %r2760, %r2954, %r8123;

	ld.shared.u32 %r2958, [%r8221+4100];

	dp4a.s32.s32 %r2788, %r2763, %r2958, %r2784;

	ld.shared.u32 %r2962, [%r8221+4104];

	dp4a.s32.s32 %r2792, %r2766, %r2962, %r2788;

	ld.shared.u32 %r2966, [%r8221+4108];

	dp4a.s32.s32 %r2796, %r2769, %r2966, %r2792;

	mul.lo.s32 %r8499, %r2796, %r8223;
ld.shared.u32 %r2970, [%r8221+4112];

	dp4a.s32.s32 %r2800, %r2772, %r2970, %r8123;

	ld.shared.u32 %r2974, [%r8221+4116];

	dp4a.s32.s32 %r2804, %r2775, %r2974, %r2800;

	ld.shared.u32 %r2978, [%r8221+4120];

	dp4a.s32.s32 %r2808, %r2778, %r2978, %r2804;

	ld.shared.u32 %r2982, [%r8221+4124];

	dp4a.s32.s32 %r2812, %r2781, %r2982, %r2808;

	mad.lo.s32 %r8500, %r2812, %r8225, %r8499;
ld.shared.f32 %f1107, [%r8498];
mul.ftz.f32 %f1108, %f1032, %f1107;
cvt.rn.f32.s32 %f1109, %r8500;
fma.rn.ftz.f32 %f1830, %f1108, %f1109, %f1830;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2816,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2819,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2822,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2825,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2828,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2831,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2834,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2837,r; 
}

	
	dp4a.s32.s32 %r2840, %r2816, %r2954, %r8123;

	
	dp4a.s32.s32 %r2844, %r2819, %r2958, %r2840;

	
	dp4a.s32.s32 %r2848, %r2822, %r2962, %r2844;

	
	dp4a.s32.s32 %r2852, %r2825, %r2966, %r2848;

	mul.lo.s32 %r8501, %r2852, %r8287;

	dp4a.s32.s32 %r2856, %r2828, %r2970, %r8123;

	
	dp4a.s32.s32 %r2860, %r2831, %r2974, %r2856;

	
	dp4a.s32.s32 %r2864, %r2834, %r2978, %r2860;

	
	dp4a.s32.s32 %r2868, %r2837, %r2982, %r2864;

	mad.lo.s32 %r8502, %r2868, %r8289, %r8501;
mul.ftz.f32 %f1110, %f1035, %f1107;
cvt.rn.f32.s32 %f1111, %r8502;
fma.rn.ftz.f32 %f1798, %f1110, %f1111, %f1798;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2872,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2875,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2878,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2881,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2884,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2887,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2890,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2893,r; 
}

	
	dp4a.s32.s32 %r2896, %r2872, %r2954, %r8123;

	
	dp4a.s32.s32 %r2900, %r2875, %r2958, %r2896;

	
	dp4a.s32.s32 %r2904, %r2878, %r2962, %r2900;

	
	dp4a.s32.s32 %r2908, %r2881, %r2966, %r2904;

	mul.lo.s32 %r8503, %r2908, %r8351;

	dp4a.s32.s32 %r2912, %r2884, %r2970, %r8123;

	
	dp4a.s32.s32 %r2916, %r2887, %r2974, %r2912;

	
	dp4a.s32.s32 %r2920, %r2890, %r2978, %r2916;

	
	dp4a.s32.s32 %r2924, %r2893, %r2982, %r2920;

	mad.lo.s32 %r8504, %r2924, %r8353, %r8503;
mul.ftz.f32 %f1112, %f1038, %f1107;
cvt.rn.f32.s32 %f1113, %r8504;
fma.rn.ftz.f32 %f1766, %f1112, %f1113, %f1766;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2928,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2931,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2934,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2937,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2940,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2943,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2946,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2949,r; 
}

	
	dp4a.s32.s32 %r2952, %r2928, %r2954, %r8123;

	
	dp4a.s32.s32 %r2956, %r2931, %r2958, %r2952;

	
	dp4a.s32.s32 %r2960, %r2934, %r2962, %r2956;

	
	dp4a.s32.s32 %r2964, %r2937, %r2966, %r2960;

	mul.lo.s32 %r8505, %r2964, %r8415;

	dp4a.s32.s32 %r2968, %r2940, %r2970, %r8123;

	
	dp4a.s32.s32 %r2972, %r2943, %r2974, %r2968;

	
	dp4a.s32.s32 %r2976, %r2946, %r2978, %r2972;

	
	dp4a.s32.s32 %r2980, %r2949, %r2982, %r2976;

	mad.lo.s32 %r8506, %r2980, %r8417, %r8505;
mul.ftz.f32 %f1114, %f1041, %f1107;
cvt.rn.f32.s32 %f1115, %r8506;
fma.rn.ftz.f32 %f1734, %f1114, %f1115, %f1734;
add.s32 %r8507, %r8146, 1152;
shr.u32 %r8508, %r8507, 1;
add.s32 %r8509, %r9004, %r8508;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2984,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2987,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2990,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2993,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2996,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r2999,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3002,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3005,r; 
}

	ld.shared.u32 %r3178, [%r8221+4608];

	dp4a.s32.s32 %r3008, %r2984, %r3178, %r8123;

	ld.shared.u32 %r3182, [%r8221+4612];

	dp4a.s32.s32 %r3012, %r2987, %r3182, %r3008;

	ld.shared.u32 %r3186, [%r8221+4616];

	dp4a.s32.s32 %r3016, %r2990, %r3186, %r3012;

	ld.shared.u32 %r3190, [%r8221+4620];

	dp4a.s32.s32 %r3020, %r2993, %r3190, %r3016;

	mul.lo.s32 %r8510, %r3020, %r8223;
ld.shared.u32 %r3194, [%r8221+4624];

	dp4a.s32.s32 %r3024, %r2996, %r3194, %r8123;

	ld.shared.u32 %r3198, [%r8221+4628];

	dp4a.s32.s32 %r3028, %r2999, %r3198, %r3024;

	ld.shared.u32 %r3202, [%r8221+4632];

	dp4a.s32.s32 %r3032, %r3002, %r3202, %r3028;

	ld.shared.u32 %r3206, [%r8221+4636];

	dp4a.s32.s32 %r3036, %r3005, %r3206, %r3032;

	mad.lo.s32 %r8511, %r3036, %r8225, %r8510;
ld.shared.f32 %f1116, [%r8509];
mul.ftz.f32 %f1117, %f1032, %f1116;
cvt.rn.f32.s32 %f1118, %r8511;
fma.rn.ftz.f32 %f1829, %f1117, %f1118, %f1829;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3040,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3043,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3046,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3049,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3052,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3055,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3058,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3061,r; 
}

	
	dp4a.s32.s32 %r3064, %r3040, %r3178, %r8123;

	
	dp4a.s32.s32 %r3068, %r3043, %r3182, %r3064;

	
	dp4a.s32.s32 %r3072, %r3046, %r3186, %r3068;

	
	dp4a.s32.s32 %r3076, %r3049, %r3190, %r3072;

	mul.lo.s32 %r8512, %r3076, %r8287;

	dp4a.s32.s32 %r3080, %r3052, %r3194, %r8123;

	
	dp4a.s32.s32 %r3084, %r3055, %r3198, %r3080;

	
	dp4a.s32.s32 %r3088, %r3058, %r3202, %r3084;

	
	dp4a.s32.s32 %r3092, %r3061, %r3206, %r3088;

	mad.lo.s32 %r8513, %r3092, %r8289, %r8512;
mul.ftz.f32 %f1119, %f1035, %f1116;
cvt.rn.f32.s32 %f1120, %r8513;
fma.rn.ftz.f32 %f1797, %f1119, %f1120, %f1797;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3096,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3099,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3102,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3105,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3108,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3111,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3114,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3117,r; 
}

	
	dp4a.s32.s32 %r3120, %r3096, %r3178, %r8123;

	
	dp4a.s32.s32 %r3124, %r3099, %r3182, %r3120;

	
	dp4a.s32.s32 %r3128, %r3102, %r3186, %r3124;

	
	dp4a.s32.s32 %r3132, %r3105, %r3190, %r3128;

	mul.lo.s32 %r8514, %r3132, %r8351;

	dp4a.s32.s32 %r3136, %r3108, %r3194, %r8123;

	
	dp4a.s32.s32 %r3140, %r3111, %r3198, %r3136;

	
	dp4a.s32.s32 %r3144, %r3114, %r3202, %r3140;

	
	dp4a.s32.s32 %r3148, %r3117, %r3206, %r3144;

	mad.lo.s32 %r8515, %r3148, %r8353, %r8514;
mul.ftz.f32 %f1121, %f1038, %f1116;
cvt.rn.f32.s32 %f1122, %r8515;
fma.rn.ftz.f32 %f1765, %f1121, %f1122, %f1765;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3152,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3155,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3158,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3161,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3164,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3167,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3170,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3173,r; 
}

	
	dp4a.s32.s32 %r3176, %r3152, %r3178, %r8123;

	
	dp4a.s32.s32 %r3180, %r3155, %r3182, %r3176;

	
	dp4a.s32.s32 %r3184, %r3158, %r3186, %r3180;

	
	dp4a.s32.s32 %r3188, %r3161, %r3190, %r3184;

	mul.lo.s32 %r8516, %r3188, %r8415;

	dp4a.s32.s32 %r3192, %r3164, %r3194, %r8123;

	
	dp4a.s32.s32 %r3196, %r3167, %r3198, %r3192;

	
	dp4a.s32.s32 %r3200, %r3170, %r3202, %r3196;

	
	dp4a.s32.s32 %r3204, %r3173, %r3206, %r3200;

	mad.lo.s32 %r8517, %r3204, %r8417, %r8516;
mul.ftz.f32 %f1123, %f1041, %f1116;
cvt.rn.f32.s32 %f1124, %r8517;
fma.rn.ftz.f32 %f1733, %f1123, %f1124, %f1733;
add.s32 %r8518, %r8146, 1280;
shr.u32 %r8519, %r8518, 1;
add.s32 %r8520, %r9004, %r8519;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3208,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3211,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3214,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3217,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3220,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3223,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3226,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3229,r; 
}

	ld.shared.u32 %r3402, [%r8221+5120];

	dp4a.s32.s32 %r3232, %r3208, %r3402, %r8123;

	ld.shared.u32 %r3406, [%r8221+5124];

	dp4a.s32.s32 %r3236, %r3211, %r3406, %r3232;

	ld.shared.u32 %r3410, [%r8221+5128];

	dp4a.s32.s32 %r3240, %r3214, %r3410, %r3236;

	ld.shared.u32 %r3414, [%r8221+5132];

	dp4a.s32.s32 %r3244, %r3217, %r3414, %r3240;

	mul.lo.s32 %r8521, %r3244, %r8223;
ld.shared.u32 %r3418, [%r8221+5136];

	dp4a.s32.s32 %r3248, %r3220, %r3418, %r8123;

	ld.shared.u32 %r3422, [%r8221+5140];

	dp4a.s32.s32 %r3252, %r3223, %r3422, %r3248;

	ld.shared.u32 %r3426, [%r8221+5144];

	dp4a.s32.s32 %r3256, %r3226, %r3426, %r3252;

	ld.shared.u32 %r3430, [%r8221+5148];

	dp4a.s32.s32 %r3260, %r3229, %r3430, %r3256;

	mad.lo.s32 %r8522, %r3260, %r8225, %r8521;
ld.shared.f32 %f1125, [%r8520];
mul.ftz.f32 %f1126, %f1032, %f1125;
cvt.rn.f32.s32 %f1127, %r8522;
fma.rn.ftz.f32 %f1828, %f1126, %f1127, %f1828;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3264,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3267,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3270,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3273,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3276,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3279,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3282,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3285,r; 
}

	
	dp4a.s32.s32 %r3288, %r3264, %r3402, %r8123;

	
	dp4a.s32.s32 %r3292, %r3267, %r3406, %r3288;

	
	dp4a.s32.s32 %r3296, %r3270, %r3410, %r3292;

	
	dp4a.s32.s32 %r3300, %r3273, %r3414, %r3296;

	mul.lo.s32 %r8523, %r3300, %r8287;

	dp4a.s32.s32 %r3304, %r3276, %r3418, %r8123;

	
	dp4a.s32.s32 %r3308, %r3279, %r3422, %r3304;

	
	dp4a.s32.s32 %r3312, %r3282, %r3426, %r3308;

	
	dp4a.s32.s32 %r3316, %r3285, %r3430, %r3312;

	mad.lo.s32 %r8524, %r3316, %r8289, %r8523;
mul.ftz.f32 %f1128, %f1035, %f1125;
cvt.rn.f32.s32 %f1129, %r8524;
fma.rn.ftz.f32 %f1796, %f1128, %f1129, %f1796;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3320,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3323,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3326,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3329,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3332,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3335,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3338,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3341,r; 
}

	
	dp4a.s32.s32 %r3344, %r3320, %r3402, %r8123;

	
	dp4a.s32.s32 %r3348, %r3323, %r3406, %r3344;

	
	dp4a.s32.s32 %r3352, %r3326, %r3410, %r3348;

	
	dp4a.s32.s32 %r3356, %r3329, %r3414, %r3352;

	mul.lo.s32 %r8525, %r3356, %r8351;

	dp4a.s32.s32 %r3360, %r3332, %r3418, %r8123;

	
	dp4a.s32.s32 %r3364, %r3335, %r3422, %r3360;

	
	dp4a.s32.s32 %r3368, %r3338, %r3426, %r3364;

	
	dp4a.s32.s32 %r3372, %r3341, %r3430, %r3368;

	mad.lo.s32 %r8526, %r3372, %r8353, %r8525;
mul.ftz.f32 %f1130, %f1038, %f1125;
cvt.rn.f32.s32 %f1131, %r8526;
fma.rn.ftz.f32 %f1764, %f1130, %f1131, %f1764;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3376,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3379,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3382,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3385,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3388,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3391,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3394,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3397,r; 
}

	
	dp4a.s32.s32 %r3400, %r3376, %r3402, %r8123;

	
	dp4a.s32.s32 %r3404, %r3379, %r3406, %r3400;

	
	dp4a.s32.s32 %r3408, %r3382, %r3410, %r3404;

	
	dp4a.s32.s32 %r3412, %r3385, %r3414, %r3408;

	mul.lo.s32 %r8527, %r3412, %r8415;

	dp4a.s32.s32 %r3416, %r3388, %r3418, %r8123;

	
	dp4a.s32.s32 %r3420, %r3391, %r3422, %r3416;

	
	dp4a.s32.s32 %r3424, %r3394, %r3426, %r3420;

	
	dp4a.s32.s32 %r3428, %r3397, %r3430, %r3424;

	mad.lo.s32 %r8528, %r3428, %r8417, %r8527;
mul.ftz.f32 %f1132, %f1041, %f1125;
cvt.rn.f32.s32 %f1133, %r8528;
fma.rn.ftz.f32 %f1732, %f1132, %f1133, %f1732;
add.s32 %r8529, %r8146, 1408;
shr.u32 %r8530, %r8529, 1;
add.s32 %r8531, %r9004, %r8530;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3432,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3435,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3438,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3441,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3444,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3447,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3450,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3453,r; 
}

	ld.shared.u32 %r3626, [%r8221+5632];

	dp4a.s32.s32 %r3456, %r3432, %r3626, %r8123;

	ld.shared.u32 %r3630, [%r8221+5636];

	dp4a.s32.s32 %r3460, %r3435, %r3630, %r3456;

	ld.shared.u32 %r3634, [%r8221+5640];

	dp4a.s32.s32 %r3464, %r3438, %r3634, %r3460;

	ld.shared.u32 %r3638, [%r8221+5644];

	dp4a.s32.s32 %r3468, %r3441, %r3638, %r3464;

	mul.lo.s32 %r8532, %r3468, %r8223;
ld.shared.u32 %r3642, [%r8221+5648];

	dp4a.s32.s32 %r3472, %r3444, %r3642, %r8123;

	ld.shared.u32 %r3646, [%r8221+5652];

	dp4a.s32.s32 %r3476, %r3447, %r3646, %r3472;

	ld.shared.u32 %r3650, [%r8221+5656];

	dp4a.s32.s32 %r3480, %r3450, %r3650, %r3476;

	ld.shared.u32 %r3654, [%r8221+5660];

	dp4a.s32.s32 %r3484, %r3453, %r3654, %r3480;

	mad.lo.s32 %r8533, %r3484, %r8225, %r8532;
ld.shared.f32 %f1134, [%r8531];
mul.ftz.f32 %f1135, %f1032, %f1134;
cvt.rn.f32.s32 %f1136, %r8533;
fma.rn.ftz.f32 %f1827, %f1135, %f1136, %f1827;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3488,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3491,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3494,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3497,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3500,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3503,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3506,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3509,r; 
}

	
	dp4a.s32.s32 %r3512, %r3488, %r3626, %r8123;

	
	dp4a.s32.s32 %r3516, %r3491, %r3630, %r3512;

	
	dp4a.s32.s32 %r3520, %r3494, %r3634, %r3516;

	
	dp4a.s32.s32 %r3524, %r3497, %r3638, %r3520;

	mul.lo.s32 %r8534, %r3524, %r8287;

	dp4a.s32.s32 %r3528, %r3500, %r3642, %r8123;

	
	dp4a.s32.s32 %r3532, %r3503, %r3646, %r3528;

	
	dp4a.s32.s32 %r3536, %r3506, %r3650, %r3532;

	
	dp4a.s32.s32 %r3540, %r3509, %r3654, %r3536;

	mad.lo.s32 %r8535, %r3540, %r8289, %r8534;
mul.ftz.f32 %f1137, %f1035, %f1134;
cvt.rn.f32.s32 %f1138, %r8535;
fma.rn.ftz.f32 %f1795, %f1137, %f1138, %f1795;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3544,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3547,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3550,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3553,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3556,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3559,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3562,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3565,r; 
}

	
	dp4a.s32.s32 %r3568, %r3544, %r3626, %r8123;

	
	dp4a.s32.s32 %r3572, %r3547, %r3630, %r3568;

	
	dp4a.s32.s32 %r3576, %r3550, %r3634, %r3572;

	
	dp4a.s32.s32 %r3580, %r3553, %r3638, %r3576;

	mul.lo.s32 %r8536, %r3580, %r8351;

	dp4a.s32.s32 %r3584, %r3556, %r3642, %r8123;

	
	dp4a.s32.s32 %r3588, %r3559, %r3646, %r3584;

	
	dp4a.s32.s32 %r3592, %r3562, %r3650, %r3588;

	
	dp4a.s32.s32 %r3596, %r3565, %r3654, %r3592;

	mad.lo.s32 %r8537, %r3596, %r8353, %r8536;
mul.ftz.f32 %f1139, %f1038, %f1134;
cvt.rn.f32.s32 %f1140, %r8537;
fma.rn.ftz.f32 %f1763, %f1139, %f1140, %f1763;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3600,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3603,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3606,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3609,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3612,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3615,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3618,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3621,r; 
}

	
	dp4a.s32.s32 %r3624, %r3600, %r3626, %r8123;

	
	dp4a.s32.s32 %r3628, %r3603, %r3630, %r3624;

	
	dp4a.s32.s32 %r3632, %r3606, %r3634, %r3628;

	
	dp4a.s32.s32 %r3636, %r3609, %r3638, %r3632;

	mul.lo.s32 %r8538, %r3636, %r8415;

	dp4a.s32.s32 %r3640, %r3612, %r3642, %r8123;

	
	dp4a.s32.s32 %r3644, %r3615, %r3646, %r3640;

	
	dp4a.s32.s32 %r3648, %r3618, %r3650, %r3644;

	
	dp4a.s32.s32 %r3652, %r3621, %r3654, %r3648;

	mad.lo.s32 %r8539, %r3652, %r8417, %r8538;
mul.ftz.f32 %f1141, %f1041, %f1134;
cvt.rn.f32.s32 %f1142, %r8539;
fma.rn.ftz.f32 %f1731, %f1141, %f1142, %f1731;
add.s32 %r8540, %r8146, 1536;
shr.u32 %r8541, %r8540, 1;
add.s32 %r8542, %r9004, %r8541;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3656,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3659,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3662,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3665,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3668,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3671,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3674,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3677,r; 
}

	ld.shared.u32 %r3850, [%r8221+6144];

	dp4a.s32.s32 %r3680, %r3656, %r3850, %r8123;

	ld.shared.u32 %r3854, [%r8221+6148];

	dp4a.s32.s32 %r3684, %r3659, %r3854, %r3680;

	ld.shared.u32 %r3858, [%r8221+6152];

	dp4a.s32.s32 %r3688, %r3662, %r3858, %r3684;

	ld.shared.u32 %r3862, [%r8221+6156];

	dp4a.s32.s32 %r3692, %r3665, %r3862, %r3688;

	mul.lo.s32 %r8543, %r3692, %r8223;
ld.shared.u32 %r3866, [%r8221+6160];

	dp4a.s32.s32 %r3696, %r3668, %r3866, %r8123;

	ld.shared.u32 %r3870, [%r8221+6164];

	dp4a.s32.s32 %r3700, %r3671, %r3870, %r3696;

	ld.shared.u32 %r3874, [%r8221+6168];

	dp4a.s32.s32 %r3704, %r3674, %r3874, %r3700;

	ld.shared.u32 %r3878, [%r8221+6172];

	dp4a.s32.s32 %r3708, %r3677, %r3878, %r3704;

	mad.lo.s32 %r8544, %r3708, %r8225, %r8543;
ld.shared.f32 %f1143, [%r8542];
mul.ftz.f32 %f1144, %f1032, %f1143;
cvt.rn.f32.s32 %f1145, %r8544;
fma.rn.ftz.f32 %f1826, %f1144, %f1145, %f1826;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3712,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3715,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3718,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3721,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3724,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3727,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3730,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3733,r; 
}

	
	dp4a.s32.s32 %r3736, %r3712, %r3850, %r8123;

	
	dp4a.s32.s32 %r3740, %r3715, %r3854, %r3736;

	
	dp4a.s32.s32 %r3744, %r3718, %r3858, %r3740;

	
	dp4a.s32.s32 %r3748, %r3721, %r3862, %r3744;

	mul.lo.s32 %r8545, %r3748, %r8287;

	dp4a.s32.s32 %r3752, %r3724, %r3866, %r8123;

	
	dp4a.s32.s32 %r3756, %r3727, %r3870, %r3752;

	
	dp4a.s32.s32 %r3760, %r3730, %r3874, %r3756;

	
	dp4a.s32.s32 %r3764, %r3733, %r3878, %r3760;

	mad.lo.s32 %r8546, %r3764, %r8289, %r8545;
mul.ftz.f32 %f1146, %f1035, %f1143;
cvt.rn.f32.s32 %f1147, %r8546;
fma.rn.ftz.f32 %f1794, %f1146, %f1147, %f1794;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3768,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3771,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3774,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3777,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3780,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3783,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3786,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3789,r; 
}

	
	dp4a.s32.s32 %r3792, %r3768, %r3850, %r8123;

	
	dp4a.s32.s32 %r3796, %r3771, %r3854, %r3792;

	
	dp4a.s32.s32 %r3800, %r3774, %r3858, %r3796;

	
	dp4a.s32.s32 %r3804, %r3777, %r3862, %r3800;

	mul.lo.s32 %r8547, %r3804, %r8351;

	dp4a.s32.s32 %r3808, %r3780, %r3866, %r8123;

	
	dp4a.s32.s32 %r3812, %r3783, %r3870, %r3808;

	
	dp4a.s32.s32 %r3816, %r3786, %r3874, %r3812;

	
	dp4a.s32.s32 %r3820, %r3789, %r3878, %r3816;

	mad.lo.s32 %r8548, %r3820, %r8353, %r8547;
mul.ftz.f32 %f1148, %f1038, %f1143;
cvt.rn.f32.s32 %f1149, %r8548;
fma.rn.ftz.f32 %f1762, %f1148, %f1149, %f1762;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3824,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3827,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3830,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3833,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3836,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3839,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3842,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3845,r; 
}

	
	dp4a.s32.s32 %r3848, %r3824, %r3850, %r8123;

	
	dp4a.s32.s32 %r3852, %r3827, %r3854, %r3848;

	
	dp4a.s32.s32 %r3856, %r3830, %r3858, %r3852;

	
	dp4a.s32.s32 %r3860, %r3833, %r3862, %r3856;

	mul.lo.s32 %r8549, %r3860, %r8415;

	dp4a.s32.s32 %r3864, %r3836, %r3866, %r8123;

	
	dp4a.s32.s32 %r3868, %r3839, %r3870, %r3864;

	
	dp4a.s32.s32 %r3872, %r3842, %r3874, %r3868;

	
	dp4a.s32.s32 %r3876, %r3845, %r3878, %r3872;

	mad.lo.s32 %r8550, %r3876, %r8417, %r8549;
mul.ftz.f32 %f1150, %f1041, %f1143;
cvt.rn.f32.s32 %f1151, %r8550;
fma.rn.ftz.f32 %f1730, %f1150, %f1151, %f1730;
add.s32 %r8551, %r8146, 1664;
shr.u32 %r8552, %r8551, 1;
add.s32 %r8553, %r9004, %r8552;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3880,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3883,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3886,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3889,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3892,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3895,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3898,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3901,r; 
}

	ld.shared.u32 %r4074, [%r8221+6656];

	dp4a.s32.s32 %r3904, %r3880, %r4074, %r8123;

	ld.shared.u32 %r4078, [%r8221+6660];

	dp4a.s32.s32 %r3908, %r3883, %r4078, %r3904;

	ld.shared.u32 %r4082, [%r8221+6664];

	dp4a.s32.s32 %r3912, %r3886, %r4082, %r3908;

	ld.shared.u32 %r4086, [%r8221+6668];

	dp4a.s32.s32 %r3916, %r3889, %r4086, %r3912;

	mul.lo.s32 %r8554, %r3916, %r8223;
ld.shared.u32 %r4090, [%r8221+6672];

	dp4a.s32.s32 %r3920, %r3892, %r4090, %r8123;

	ld.shared.u32 %r4094, [%r8221+6676];

	dp4a.s32.s32 %r3924, %r3895, %r4094, %r3920;

	ld.shared.u32 %r4098, [%r8221+6680];

	dp4a.s32.s32 %r3928, %r3898, %r4098, %r3924;

	ld.shared.u32 %r4102, [%r8221+6684];

	dp4a.s32.s32 %r3932, %r3901, %r4102, %r3928;

	mad.lo.s32 %r8555, %r3932, %r8225, %r8554;
ld.shared.f32 %f1152, [%r8553];
mul.ftz.f32 %f1153, %f1032, %f1152;
cvt.rn.f32.s32 %f1154, %r8555;
fma.rn.ftz.f32 %f1825, %f1153, %f1154, %f1825;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3936,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3939,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3942,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3945,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3948,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3951,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3954,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3957,r; 
}

	
	dp4a.s32.s32 %r3960, %r3936, %r4074, %r8123;

	
	dp4a.s32.s32 %r3964, %r3939, %r4078, %r3960;

	
	dp4a.s32.s32 %r3968, %r3942, %r4082, %r3964;

	
	dp4a.s32.s32 %r3972, %r3945, %r4086, %r3968;

	mul.lo.s32 %r8556, %r3972, %r8287;

	dp4a.s32.s32 %r3976, %r3948, %r4090, %r8123;

	
	dp4a.s32.s32 %r3980, %r3951, %r4094, %r3976;

	
	dp4a.s32.s32 %r3984, %r3954, %r4098, %r3980;

	
	dp4a.s32.s32 %r3988, %r3957, %r4102, %r3984;

	mad.lo.s32 %r8557, %r3988, %r8289, %r8556;
mul.ftz.f32 %f1155, %f1035, %f1152;
cvt.rn.f32.s32 %f1156, %r8557;
fma.rn.ftz.f32 %f1793, %f1155, %f1156, %f1793;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3992,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3995,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r3998,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4001,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4004,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4007,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4010,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4013,r; 
}

	
	dp4a.s32.s32 %r4016, %r3992, %r4074, %r8123;

	
	dp4a.s32.s32 %r4020, %r3995, %r4078, %r4016;

	
	dp4a.s32.s32 %r4024, %r3998, %r4082, %r4020;

	
	dp4a.s32.s32 %r4028, %r4001, %r4086, %r4024;

	mul.lo.s32 %r8558, %r4028, %r8351;

	dp4a.s32.s32 %r4032, %r4004, %r4090, %r8123;

	
	dp4a.s32.s32 %r4036, %r4007, %r4094, %r4032;

	
	dp4a.s32.s32 %r4040, %r4010, %r4098, %r4036;

	
	dp4a.s32.s32 %r4044, %r4013, %r4102, %r4040;

	mad.lo.s32 %r8559, %r4044, %r8353, %r8558;
mul.ftz.f32 %f1157, %f1038, %f1152;
cvt.rn.f32.s32 %f1158, %r8559;
fma.rn.ftz.f32 %f1761, %f1157, %f1158, %f1761;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4048,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4051,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4054,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4057,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4060,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4063,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4066,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4069,r; 
}

	
	dp4a.s32.s32 %r4072, %r4048, %r4074, %r8123;

	
	dp4a.s32.s32 %r4076, %r4051, %r4078, %r4072;

	
	dp4a.s32.s32 %r4080, %r4054, %r4082, %r4076;

	
	dp4a.s32.s32 %r4084, %r4057, %r4086, %r4080;

	mul.lo.s32 %r8560, %r4084, %r8415;

	dp4a.s32.s32 %r4088, %r4060, %r4090, %r8123;

	
	dp4a.s32.s32 %r4092, %r4063, %r4094, %r4088;

	
	dp4a.s32.s32 %r4096, %r4066, %r4098, %r4092;

	
	dp4a.s32.s32 %r4100, %r4069, %r4102, %r4096;

	mad.lo.s32 %r8561, %r4100, %r8417, %r8560;
mul.ftz.f32 %f1159, %f1041, %f1152;
cvt.rn.f32.s32 %f1160, %r8561;
fma.rn.ftz.f32 %f1729, %f1159, %f1160, %f1729;
add.s32 %r8562, %r8146, 1792;
shr.u32 %r8563, %r8562, 1;
add.s32 %r8564, %r9004, %r8563;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4104,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4107,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4110,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4113,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4116,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4119,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4122,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4125,r; 
}

	ld.shared.u32 %r4298, [%r8221+7168];

	dp4a.s32.s32 %r4128, %r4104, %r4298, %r8123;

	ld.shared.u32 %r4302, [%r8221+7172];

	dp4a.s32.s32 %r4132, %r4107, %r4302, %r4128;

	ld.shared.u32 %r4306, [%r8221+7176];

	dp4a.s32.s32 %r4136, %r4110, %r4306, %r4132;

	ld.shared.u32 %r4310, [%r8221+7180];

	dp4a.s32.s32 %r4140, %r4113, %r4310, %r4136;

	mul.lo.s32 %r8565, %r4140, %r8223;
ld.shared.u32 %r4314, [%r8221+7184];

	dp4a.s32.s32 %r4144, %r4116, %r4314, %r8123;

	ld.shared.u32 %r4318, [%r8221+7188];

	dp4a.s32.s32 %r4148, %r4119, %r4318, %r4144;

	ld.shared.u32 %r4322, [%r8221+7192];

	dp4a.s32.s32 %r4152, %r4122, %r4322, %r4148;

	ld.shared.u32 %r4326, [%r8221+7196];

	dp4a.s32.s32 %r4156, %r4125, %r4326, %r4152;

	mad.lo.s32 %r8566, %r4156, %r8225, %r8565;
ld.shared.f32 %f1161, [%r8564];
mul.ftz.f32 %f1162, %f1032, %f1161;
cvt.rn.f32.s32 %f1163, %r8566;
fma.rn.ftz.f32 %f1824, %f1162, %f1163, %f1824;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4160,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4163,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4166,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4169,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4172,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4175,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4178,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4181,r; 
}

	
	dp4a.s32.s32 %r4184, %r4160, %r4298, %r8123;

	
	dp4a.s32.s32 %r4188, %r4163, %r4302, %r4184;

	
	dp4a.s32.s32 %r4192, %r4166, %r4306, %r4188;

	
	dp4a.s32.s32 %r4196, %r4169, %r4310, %r4192;

	mul.lo.s32 %r8567, %r4196, %r8287;

	dp4a.s32.s32 %r4200, %r4172, %r4314, %r8123;

	
	dp4a.s32.s32 %r4204, %r4175, %r4318, %r4200;

	
	dp4a.s32.s32 %r4208, %r4178, %r4322, %r4204;

	
	dp4a.s32.s32 %r4212, %r4181, %r4326, %r4208;

	mad.lo.s32 %r8568, %r4212, %r8289, %r8567;
mul.ftz.f32 %f1164, %f1035, %f1161;
cvt.rn.f32.s32 %f1165, %r8568;
fma.rn.ftz.f32 %f1792, %f1164, %f1165, %f1792;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4216,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4219,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4222,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4225,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4228,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4231,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4234,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4237,r; 
}

	
	dp4a.s32.s32 %r4240, %r4216, %r4298, %r8123;

	
	dp4a.s32.s32 %r4244, %r4219, %r4302, %r4240;

	
	dp4a.s32.s32 %r4248, %r4222, %r4306, %r4244;

	
	dp4a.s32.s32 %r4252, %r4225, %r4310, %r4248;

	mul.lo.s32 %r8569, %r4252, %r8351;

	dp4a.s32.s32 %r4256, %r4228, %r4314, %r8123;

	
	dp4a.s32.s32 %r4260, %r4231, %r4318, %r4256;

	
	dp4a.s32.s32 %r4264, %r4234, %r4322, %r4260;

	
	dp4a.s32.s32 %r4268, %r4237, %r4326, %r4264;

	mad.lo.s32 %r8570, %r4268, %r8353, %r8569;
mul.ftz.f32 %f1166, %f1038, %f1161;
cvt.rn.f32.s32 %f1167, %r8570;
fma.rn.ftz.f32 %f1760, %f1166, %f1167, %f1760;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4272,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4275,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4278,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4281,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4284,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4287,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4290,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4293,r; 
}

	
	dp4a.s32.s32 %r4296, %r4272, %r4298, %r8123;

	
	dp4a.s32.s32 %r4300, %r4275, %r4302, %r4296;

	
	dp4a.s32.s32 %r4304, %r4278, %r4306, %r4300;

	
	dp4a.s32.s32 %r4308, %r4281, %r4310, %r4304;

	mul.lo.s32 %r8571, %r4308, %r8415;

	dp4a.s32.s32 %r4312, %r4284, %r4314, %r8123;

	
	dp4a.s32.s32 %r4316, %r4287, %r4318, %r4312;

	
	dp4a.s32.s32 %r4320, %r4290, %r4322, %r4316;

	
	dp4a.s32.s32 %r4324, %r4293, %r4326, %r4320;

	mad.lo.s32 %r8572, %r4324, %r8417, %r8571;
mul.ftz.f32 %f1168, %f1041, %f1161;
cvt.rn.f32.s32 %f1169, %r8572;
fma.rn.ftz.f32 %f1728, %f1168, %f1169, %f1728;
add.s32 %r8573, %r8146, 1920;
shr.u32 %r8574, %r8573, 1;
add.s32 %r8575, %r9004, %r8574;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4328,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4331,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4334,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4337,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4340,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4343,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4346,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4349,r; 
}

	ld.shared.u32 %r4522, [%r8221+7680];

	dp4a.s32.s32 %r4352, %r4328, %r4522, %r8123;

	ld.shared.u32 %r4526, [%r8221+7684];

	dp4a.s32.s32 %r4356, %r4331, %r4526, %r4352;

	ld.shared.u32 %r4530, [%r8221+7688];

	dp4a.s32.s32 %r4360, %r4334, %r4530, %r4356;

	ld.shared.u32 %r4534, [%r8221+7692];

	dp4a.s32.s32 %r4364, %r4337, %r4534, %r4360;

	mul.lo.s32 %r8576, %r4364, %r8223;
ld.shared.u32 %r4538, [%r8221+7696];

	dp4a.s32.s32 %r4368, %r4340, %r4538, %r8123;

	ld.shared.u32 %r4542, [%r8221+7700];

	dp4a.s32.s32 %r4372, %r4343, %r4542, %r4368;

	ld.shared.u32 %r4546, [%r8221+7704];

	dp4a.s32.s32 %r4376, %r4346, %r4546, %r4372;

	ld.shared.u32 %r4550, [%r8221+7708];

	dp4a.s32.s32 %r4380, %r4349, %r4550, %r4376;

	mad.lo.s32 %r8577, %r4380, %r8225, %r8576;
ld.shared.f32 %f1170, [%r8575];
mul.ftz.f32 %f1171, %f1032, %f1170;
cvt.rn.f32.s32 %f1172, %r8577;
fma.rn.ftz.f32 %f1823, %f1171, %f1172, %f1823;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4384,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4387,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4390,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4393,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4396,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4399,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4402,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4405,r; 
}

	
	dp4a.s32.s32 %r4408, %r4384, %r4522, %r8123;

	
	dp4a.s32.s32 %r4412, %r4387, %r4526, %r4408;

	
	dp4a.s32.s32 %r4416, %r4390, %r4530, %r4412;

	
	dp4a.s32.s32 %r4420, %r4393, %r4534, %r4416;

	mul.lo.s32 %r8578, %r4420, %r8287;

	dp4a.s32.s32 %r4424, %r4396, %r4538, %r8123;

	
	dp4a.s32.s32 %r4428, %r4399, %r4542, %r4424;

	
	dp4a.s32.s32 %r4432, %r4402, %r4546, %r4428;

	
	dp4a.s32.s32 %r4436, %r4405, %r4550, %r4432;

	mad.lo.s32 %r8579, %r4436, %r8289, %r8578;
mul.ftz.f32 %f1173, %f1035, %f1170;
cvt.rn.f32.s32 %f1174, %r8579;
fma.rn.ftz.f32 %f1791, %f1173, %f1174, %f1791;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4440,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4443,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4446,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4449,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4452,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4455,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4458,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4461,r; 
}

	
	dp4a.s32.s32 %r4464, %r4440, %r4522, %r8123;

	
	dp4a.s32.s32 %r4468, %r4443, %r4526, %r4464;

	
	dp4a.s32.s32 %r4472, %r4446, %r4530, %r4468;

	
	dp4a.s32.s32 %r4476, %r4449, %r4534, %r4472;

	mul.lo.s32 %r8580, %r4476, %r8351;

	dp4a.s32.s32 %r4480, %r4452, %r4538, %r8123;

	
	dp4a.s32.s32 %r4484, %r4455, %r4542, %r4480;

	
	dp4a.s32.s32 %r4488, %r4458, %r4546, %r4484;

	
	dp4a.s32.s32 %r4492, %r4461, %r4550, %r4488;

	mad.lo.s32 %r8581, %r4492, %r8353, %r8580;
mul.ftz.f32 %f1175, %f1038, %f1170;
cvt.rn.f32.s32 %f1176, %r8581;
fma.rn.ftz.f32 %f1759, %f1175, %f1176, %f1759;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4496,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4499,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4502,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4505,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4508,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4511,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4514,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4517,r; 
}

	
	dp4a.s32.s32 %r4520, %r4496, %r4522, %r8123;

	
	dp4a.s32.s32 %r4524, %r4499, %r4526, %r4520;

	
	dp4a.s32.s32 %r4528, %r4502, %r4530, %r4524;

	
	dp4a.s32.s32 %r4532, %r4505, %r4534, %r4528;

	mul.lo.s32 %r8582, %r4532, %r8415;

	dp4a.s32.s32 %r4536, %r4508, %r4538, %r8123;

	
	dp4a.s32.s32 %r4540, %r4511, %r4542, %r4536;

	
	dp4a.s32.s32 %r4544, %r4514, %r4546, %r4540;

	
	dp4a.s32.s32 %r4548, %r4517, %r4550, %r4544;

	mad.lo.s32 %r8583, %r4548, %r8417, %r8582;
mul.ftz.f32 %f1177, %f1041, %f1170;
cvt.rn.f32.s32 %f1178, %r8583;
fma.rn.ftz.f32 %f1727, %f1177, %f1178, %f1727;
add.s32 %r8584, %r8146, 2048;
shr.u32 %r8585, %r8584, 1;
add.s32 %r8586, %r9004, %r8585;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4552,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4555,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4558,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4561,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4564,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4567,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4570,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4573,r; 
}

	ld.shared.u32 %r4746, [%r8221+8192];

	dp4a.s32.s32 %r4576, %r4552, %r4746, %r8123;

	ld.shared.u32 %r4750, [%r8221+8196];

	dp4a.s32.s32 %r4580, %r4555, %r4750, %r4576;

	ld.shared.u32 %r4754, [%r8221+8200];

	dp4a.s32.s32 %r4584, %r4558, %r4754, %r4580;

	ld.shared.u32 %r4758, [%r8221+8204];

	dp4a.s32.s32 %r4588, %r4561, %r4758, %r4584;

	mul.lo.s32 %r8587, %r4588, %r8223;
ld.shared.u32 %r4762, [%r8221+8208];

	dp4a.s32.s32 %r4592, %r4564, %r4762, %r8123;

	ld.shared.u32 %r4766, [%r8221+8212];

	dp4a.s32.s32 %r4596, %r4567, %r4766, %r4592;

	ld.shared.u32 %r4770, [%r8221+8216];

	dp4a.s32.s32 %r4600, %r4570, %r4770, %r4596;

	ld.shared.u32 %r4774, [%r8221+8220];

	dp4a.s32.s32 %r4604, %r4573, %r4774, %r4600;

	mad.lo.s32 %r8588, %r4604, %r8225, %r8587;
ld.shared.f32 %f1179, [%r8586];
mul.ftz.f32 %f1180, %f1032, %f1179;
cvt.rn.f32.s32 %f1181, %r8588;
fma.rn.ftz.f32 %f1822, %f1180, %f1181, %f1822;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4608,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4611,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4614,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4617,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4620,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4623,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4626,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4629,r; 
}

	
	dp4a.s32.s32 %r4632, %r4608, %r4746, %r8123;

	
	dp4a.s32.s32 %r4636, %r4611, %r4750, %r4632;

	
	dp4a.s32.s32 %r4640, %r4614, %r4754, %r4636;

	
	dp4a.s32.s32 %r4644, %r4617, %r4758, %r4640;

	mul.lo.s32 %r8589, %r4644, %r8287;

	dp4a.s32.s32 %r4648, %r4620, %r4762, %r8123;

	
	dp4a.s32.s32 %r4652, %r4623, %r4766, %r4648;

	
	dp4a.s32.s32 %r4656, %r4626, %r4770, %r4652;

	
	dp4a.s32.s32 %r4660, %r4629, %r4774, %r4656;

	mad.lo.s32 %r8590, %r4660, %r8289, %r8589;
mul.ftz.f32 %f1182, %f1035, %f1179;
cvt.rn.f32.s32 %f1183, %r8590;
fma.rn.ftz.f32 %f1790, %f1182, %f1183, %f1790;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4664,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4667,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4670,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4673,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4676,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4679,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4682,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4685,r; 
}

	
	dp4a.s32.s32 %r4688, %r4664, %r4746, %r8123;

	
	dp4a.s32.s32 %r4692, %r4667, %r4750, %r4688;

	
	dp4a.s32.s32 %r4696, %r4670, %r4754, %r4692;

	
	dp4a.s32.s32 %r4700, %r4673, %r4758, %r4696;

	mul.lo.s32 %r8591, %r4700, %r8351;

	dp4a.s32.s32 %r4704, %r4676, %r4762, %r8123;

	
	dp4a.s32.s32 %r4708, %r4679, %r4766, %r4704;

	
	dp4a.s32.s32 %r4712, %r4682, %r4770, %r4708;

	
	dp4a.s32.s32 %r4716, %r4685, %r4774, %r4712;

	mad.lo.s32 %r8592, %r4716, %r8353, %r8591;
mul.ftz.f32 %f1184, %f1038, %f1179;
cvt.rn.f32.s32 %f1185, %r8592;
fma.rn.ftz.f32 %f1758, %f1184, %f1185, %f1758;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4720,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4723,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4726,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4729,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4732,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4735,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4738,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4741,r; 
}

	
	dp4a.s32.s32 %r4744, %r4720, %r4746, %r8123;

	
	dp4a.s32.s32 %r4748, %r4723, %r4750, %r4744;

	
	dp4a.s32.s32 %r4752, %r4726, %r4754, %r4748;

	
	dp4a.s32.s32 %r4756, %r4729, %r4758, %r4752;

	mul.lo.s32 %r8593, %r4756, %r8415;

	dp4a.s32.s32 %r4760, %r4732, %r4762, %r8123;

	
	dp4a.s32.s32 %r4764, %r4735, %r4766, %r4760;

	
	dp4a.s32.s32 %r4768, %r4738, %r4770, %r4764;

	
	dp4a.s32.s32 %r4772, %r4741, %r4774, %r4768;

	mad.lo.s32 %r8594, %r4772, %r8417, %r8593;
mul.ftz.f32 %f1186, %f1041, %f1179;
cvt.rn.f32.s32 %f1187, %r8594;
fma.rn.ftz.f32 %f1726, %f1186, %f1187, %f1726;
add.s32 %r8595, %r8146, 2176;
shr.u32 %r8596, %r8595, 1;
add.s32 %r8597, %r9004, %r8596;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4776,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4779,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4782,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4785,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4788,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4791,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4794,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4797,r; 
}

	ld.shared.u32 %r4970, [%r8221+8704];

	dp4a.s32.s32 %r4800, %r4776, %r4970, %r8123;

	ld.shared.u32 %r4974, [%r8221+8708];

	dp4a.s32.s32 %r4804, %r4779, %r4974, %r4800;

	ld.shared.u32 %r4978, [%r8221+8712];

	dp4a.s32.s32 %r4808, %r4782, %r4978, %r4804;

	ld.shared.u32 %r4982, [%r8221+8716];

	dp4a.s32.s32 %r4812, %r4785, %r4982, %r4808;

	mul.lo.s32 %r8598, %r4812, %r8223;
ld.shared.u32 %r4986, [%r8221+8720];

	dp4a.s32.s32 %r4816, %r4788, %r4986, %r8123;

	ld.shared.u32 %r4990, [%r8221+8724];

	dp4a.s32.s32 %r4820, %r4791, %r4990, %r4816;

	ld.shared.u32 %r4994, [%r8221+8728];

	dp4a.s32.s32 %r4824, %r4794, %r4994, %r4820;

	ld.shared.u32 %r4998, [%r8221+8732];

	dp4a.s32.s32 %r4828, %r4797, %r4998, %r4824;

	mad.lo.s32 %r8599, %r4828, %r8225, %r8598;
ld.shared.f32 %f1188, [%r8597];
mul.ftz.f32 %f1189, %f1032, %f1188;
cvt.rn.f32.s32 %f1190, %r8599;
fma.rn.ftz.f32 %f1821, %f1189, %f1190, %f1821;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4832,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4835,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4838,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4841,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4844,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4847,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4850,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4853,r; 
}

	
	dp4a.s32.s32 %r4856, %r4832, %r4970, %r8123;

	
	dp4a.s32.s32 %r4860, %r4835, %r4974, %r4856;

	
	dp4a.s32.s32 %r4864, %r4838, %r4978, %r4860;

	
	dp4a.s32.s32 %r4868, %r4841, %r4982, %r4864;

	mul.lo.s32 %r8600, %r4868, %r8287;

	dp4a.s32.s32 %r4872, %r4844, %r4986, %r8123;

	
	dp4a.s32.s32 %r4876, %r4847, %r4990, %r4872;

	
	dp4a.s32.s32 %r4880, %r4850, %r4994, %r4876;

	
	dp4a.s32.s32 %r4884, %r4853, %r4998, %r4880;

	mad.lo.s32 %r8601, %r4884, %r8289, %r8600;
mul.ftz.f32 %f1191, %f1035, %f1188;
cvt.rn.f32.s32 %f1192, %r8601;
fma.rn.ftz.f32 %f1789, %f1191, %f1192, %f1789;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4888,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4891,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4894,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4897,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4900,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4903,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4906,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4909,r; 
}

	
	dp4a.s32.s32 %r4912, %r4888, %r4970, %r8123;

	
	dp4a.s32.s32 %r4916, %r4891, %r4974, %r4912;

	
	dp4a.s32.s32 %r4920, %r4894, %r4978, %r4916;

	
	dp4a.s32.s32 %r4924, %r4897, %r4982, %r4920;

	mul.lo.s32 %r8602, %r4924, %r8351;

	dp4a.s32.s32 %r4928, %r4900, %r4986, %r8123;

	
	dp4a.s32.s32 %r4932, %r4903, %r4990, %r4928;

	
	dp4a.s32.s32 %r4936, %r4906, %r4994, %r4932;

	
	dp4a.s32.s32 %r4940, %r4909, %r4998, %r4936;

	mad.lo.s32 %r8603, %r4940, %r8353, %r8602;
mul.ftz.f32 %f1193, %f1038, %f1188;
cvt.rn.f32.s32 %f1194, %r8603;
fma.rn.ftz.f32 %f1757, %f1193, %f1194, %f1757;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4944,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4947,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4950,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4953,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4956,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4959,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4962,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r4965,r; 
}

	
	dp4a.s32.s32 %r4968, %r4944, %r4970, %r8123;

	
	dp4a.s32.s32 %r4972, %r4947, %r4974, %r4968;

	
	dp4a.s32.s32 %r4976, %r4950, %r4978, %r4972;

	
	dp4a.s32.s32 %r4980, %r4953, %r4982, %r4976;

	mul.lo.s32 %r8604, %r4980, %r8415;

	dp4a.s32.s32 %r4984, %r4956, %r4986, %r8123;

	
	dp4a.s32.s32 %r4988, %r4959, %r4990, %r4984;

	
	dp4a.s32.s32 %r4992, %r4962, %r4994, %r4988;

	
	dp4a.s32.s32 %r4996, %r4965, %r4998, %r4992;

	mad.lo.s32 %r8605, %r4996, %r8417, %r8604;
mul.ftz.f32 %f1195, %f1041, %f1188;
cvt.rn.f32.s32 %f1196, %r8605;
fma.rn.ftz.f32 %f1725, %f1195, %f1196, %f1725;
add.s32 %r8606, %r8146, 2304;
shr.u32 %r8607, %r8606, 1;
add.s32 %r8608, %r9004, %r8607;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5000,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5003,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5006,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5009,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5012,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5015,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5018,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5021,r; 
}

	ld.shared.u32 %r5194, [%r8221+9216];

	dp4a.s32.s32 %r5024, %r5000, %r5194, %r8123;

	ld.shared.u32 %r5198, [%r8221+9220];

	dp4a.s32.s32 %r5028, %r5003, %r5198, %r5024;

	ld.shared.u32 %r5202, [%r8221+9224];

	dp4a.s32.s32 %r5032, %r5006, %r5202, %r5028;

	ld.shared.u32 %r5206, [%r8221+9228];

	dp4a.s32.s32 %r5036, %r5009, %r5206, %r5032;

	mul.lo.s32 %r8609, %r5036, %r8223;
ld.shared.u32 %r5210, [%r8221+9232];

	dp4a.s32.s32 %r5040, %r5012, %r5210, %r8123;

	ld.shared.u32 %r5214, [%r8221+9236];

	dp4a.s32.s32 %r5044, %r5015, %r5214, %r5040;

	ld.shared.u32 %r5218, [%r8221+9240];

	dp4a.s32.s32 %r5048, %r5018, %r5218, %r5044;

	ld.shared.u32 %r5222, [%r8221+9244];

	dp4a.s32.s32 %r5052, %r5021, %r5222, %r5048;

	mad.lo.s32 %r8610, %r5052, %r8225, %r8609;
ld.shared.f32 %f1197, [%r8608];
mul.ftz.f32 %f1198, %f1032, %f1197;
cvt.rn.f32.s32 %f1199, %r8610;
fma.rn.ftz.f32 %f1820, %f1198, %f1199, %f1820;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5056,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5059,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5062,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5065,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5068,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5071,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5074,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5077,r; 
}

	
	dp4a.s32.s32 %r5080, %r5056, %r5194, %r8123;

	
	dp4a.s32.s32 %r5084, %r5059, %r5198, %r5080;

	
	dp4a.s32.s32 %r5088, %r5062, %r5202, %r5084;

	
	dp4a.s32.s32 %r5092, %r5065, %r5206, %r5088;

	mul.lo.s32 %r8611, %r5092, %r8287;

	dp4a.s32.s32 %r5096, %r5068, %r5210, %r8123;

	
	dp4a.s32.s32 %r5100, %r5071, %r5214, %r5096;

	
	dp4a.s32.s32 %r5104, %r5074, %r5218, %r5100;

	
	dp4a.s32.s32 %r5108, %r5077, %r5222, %r5104;

	mad.lo.s32 %r8612, %r5108, %r8289, %r8611;
mul.ftz.f32 %f1200, %f1035, %f1197;
cvt.rn.f32.s32 %f1201, %r8612;
fma.rn.ftz.f32 %f1788, %f1200, %f1201, %f1788;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5112,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5115,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5118,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5121,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5124,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5127,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5130,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5133,r; 
}

	
	dp4a.s32.s32 %r5136, %r5112, %r5194, %r8123;

	
	dp4a.s32.s32 %r5140, %r5115, %r5198, %r5136;

	
	dp4a.s32.s32 %r5144, %r5118, %r5202, %r5140;

	
	dp4a.s32.s32 %r5148, %r5121, %r5206, %r5144;

	mul.lo.s32 %r8613, %r5148, %r8351;

	dp4a.s32.s32 %r5152, %r5124, %r5210, %r8123;

	
	dp4a.s32.s32 %r5156, %r5127, %r5214, %r5152;

	
	dp4a.s32.s32 %r5160, %r5130, %r5218, %r5156;

	
	dp4a.s32.s32 %r5164, %r5133, %r5222, %r5160;

	mad.lo.s32 %r8614, %r5164, %r8353, %r8613;
mul.ftz.f32 %f1202, %f1038, %f1197;
cvt.rn.f32.s32 %f1203, %r8614;
fma.rn.ftz.f32 %f1756, %f1202, %f1203, %f1756;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5168,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5171,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5174,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5177,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5180,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5183,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5186,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5189,r; 
}

	
	dp4a.s32.s32 %r5192, %r5168, %r5194, %r8123;

	
	dp4a.s32.s32 %r5196, %r5171, %r5198, %r5192;

	
	dp4a.s32.s32 %r5200, %r5174, %r5202, %r5196;

	
	dp4a.s32.s32 %r5204, %r5177, %r5206, %r5200;

	mul.lo.s32 %r8615, %r5204, %r8415;

	dp4a.s32.s32 %r5208, %r5180, %r5210, %r8123;

	
	dp4a.s32.s32 %r5212, %r5183, %r5214, %r5208;

	
	dp4a.s32.s32 %r5216, %r5186, %r5218, %r5212;

	
	dp4a.s32.s32 %r5220, %r5189, %r5222, %r5216;

	mad.lo.s32 %r8616, %r5220, %r8417, %r8615;
mul.ftz.f32 %f1204, %f1041, %f1197;
cvt.rn.f32.s32 %f1205, %r8616;
fma.rn.ftz.f32 %f1724, %f1204, %f1205, %f1724;
add.s32 %r8617, %r8146, 2432;
shr.u32 %r8618, %r8617, 1;
add.s32 %r8619, %r9004, %r8618;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5224,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5227,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5230,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5233,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5236,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5239,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5242,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5245,r; 
}

	ld.shared.u32 %r5418, [%r8221+9728];

	dp4a.s32.s32 %r5248, %r5224, %r5418, %r8123;

	ld.shared.u32 %r5422, [%r8221+9732];

	dp4a.s32.s32 %r5252, %r5227, %r5422, %r5248;

	ld.shared.u32 %r5426, [%r8221+9736];

	dp4a.s32.s32 %r5256, %r5230, %r5426, %r5252;

	ld.shared.u32 %r5430, [%r8221+9740];

	dp4a.s32.s32 %r5260, %r5233, %r5430, %r5256;

	mul.lo.s32 %r8620, %r5260, %r8223;
ld.shared.u32 %r5434, [%r8221+9744];

	dp4a.s32.s32 %r5264, %r5236, %r5434, %r8123;

	ld.shared.u32 %r5438, [%r8221+9748];

	dp4a.s32.s32 %r5268, %r5239, %r5438, %r5264;

	ld.shared.u32 %r5442, [%r8221+9752];

	dp4a.s32.s32 %r5272, %r5242, %r5442, %r5268;

	ld.shared.u32 %r5446, [%r8221+9756];

	dp4a.s32.s32 %r5276, %r5245, %r5446, %r5272;

	mad.lo.s32 %r8621, %r5276, %r8225, %r8620;
ld.shared.f32 %f1206, [%r8619];
mul.ftz.f32 %f1207, %f1032, %f1206;
cvt.rn.f32.s32 %f1208, %r8621;
fma.rn.ftz.f32 %f1819, %f1207, %f1208, %f1819;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5280,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5283,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5286,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5289,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5292,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5295,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5298,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5301,r; 
}

	
	dp4a.s32.s32 %r5304, %r5280, %r5418, %r8123;

	
	dp4a.s32.s32 %r5308, %r5283, %r5422, %r5304;

	
	dp4a.s32.s32 %r5312, %r5286, %r5426, %r5308;

	
	dp4a.s32.s32 %r5316, %r5289, %r5430, %r5312;

	mul.lo.s32 %r8622, %r5316, %r8287;

	dp4a.s32.s32 %r5320, %r5292, %r5434, %r8123;

	
	dp4a.s32.s32 %r5324, %r5295, %r5438, %r5320;

	
	dp4a.s32.s32 %r5328, %r5298, %r5442, %r5324;

	
	dp4a.s32.s32 %r5332, %r5301, %r5446, %r5328;

	mad.lo.s32 %r8623, %r5332, %r8289, %r8622;
mul.ftz.f32 %f1209, %f1035, %f1206;
cvt.rn.f32.s32 %f1210, %r8623;
fma.rn.ftz.f32 %f1787, %f1209, %f1210, %f1787;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5336,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5339,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5342,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5345,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5348,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5351,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5354,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5357,r; 
}

	
	dp4a.s32.s32 %r5360, %r5336, %r5418, %r8123;

	
	dp4a.s32.s32 %r5364, %r5339, %r5422, %r5360;

	
	dp4a.s32.s32 %r5368, %r5342, %r5426, %r5364;

	
	dp4a.s32.s32 %r5372, %r5345, %r5430, %r5368;

	mul.lo.s32 %r8624, %r5372, %r8351;

	dp4a.s32.s32 %r5376, %r5348, %r5434, %r8123;

	
	dp4a.s32.s32 %r5380, %r5351, %r5438, %r5376;

	
	dp4a.s32.s32 %r5384, %r5354, %r5442, %r5380;

	
	dp4a.s32.s32 %r5388, %r5357, %r5446, %r5384;

	mad.lo.s32 %r8625, %r5388, %r8353, %r8624;
mul.ftz.f32 %f1211, %f1038, %f1206;
cvt.rn.f32.s32 %f1212, %r8625;
fma.rn.ftz.f32 %f1755, %f1211, %f1212, %f1755;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5392,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5395,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5398,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5401,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5404,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5407,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5410,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5413,r; 
}

	
	dp4a.s32.s32 %r5416, %r5392, %r5418, %r8123;

	
	dp4a.s32.s32 %r5420, %r5395, %r5422, %r5416;

	
	dp4a.s32.s32 %r5424, %r5398, %r5426, %r5420;

	
	dp4a.s32.s32 %r5428, %r5401, %r5430, %r5424;

	mul.lo.s32 %r8626, %r5428, %r8415;

	dp4a.s32.s32 %r5432, %r5404, %r5434, %r8123;

	
	dp4a.s32.s32 %r5436, %r5407, %r5438, %r5432;

	
	dp4a.s32.s32 %r5440, %r5410, %r5442, %r5436;

	
	dp4a.s32.s32 %r5444, %r5413, %r5446, %r5440;

	mad.lo.s32 %r8627, %r5444, %r8417, %r8626;
mul.ftz.f32 %f1213, %f1041, %f1206;
cvt.rn.f32.s32 %f1214, %r8627;
fma.rn.ftz.f32 %f1723, %f1213, %f1214, %f1723;
add.s32 %r8628, %r8146, 2560;
shr.u32 %r8629, %r8628, 1;
add.s32 %r8630, %r9004, %r8629;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5448,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5451,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5454,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5457,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5460,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5463,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5466,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5469,r; 
}

	ld.shared.u32 %r5642, [%r8221+10240];

	dp4a.s32.s32 %r5472, %r5448, %r5642, %r8123;

	ld.shared.u32 %r5646, [%r8221+10244];

	dp4a.s32.s32 %r5476, %r5451, %r5646, %r5472;

	ld.shared.u32 %r5650, [%r8221+10248];

	dp4a.s32.s32 %r5480, %r5454, %r5650, %r5476;

	ld.shared.u32 %r5654, [%r8221+10252];

	dp4a.s32.s32 %r5484, %r5457, %r5654, %r5480;

	mul.lo.s32 %r8631, %r5484, %r8223;
ld.shared.u32 %r5658, [%r8221+10256];

	dp4a.s32.s32 %r5488, %r5460, %r5658, %r8123;

	ld.shared.u32 %r5662, [%r8221+10260];

	dp4a.s32.s32 %r5492, %r5463, %r5662, %r5488;

	ld.shared.u32 %r5666, [%r8221+10264];

	dp4a.s32.s32 %r5496, %r5466, %r5666, %r5492;

	ld.shared.u32 %r5670, [%r8221+10268];

	dp4a.s32.s32 %r5500, %r5469, %r5670, %r5496;

	mad.lo.s32 %r8632, %r5500, %r8225, %r8631;
ld.shared.f32 %f1215, [%r8630];
mul.ftz.f32 %f1216, %f1032, %f1215;
cvt.rn.f32.s32 %f1217, %r8632;
fma.rn.ftz.f32 %f1818, %f1216, %f1217, %f1818;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5504,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5507,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5510,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5513,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5516,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5519,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5522,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5525,r; 
}

	
	dp4a.s32.s32 %r5528, %r5504, %r5642, %r8123;

	
	dp4a.s32.s32 %r5532, %r5507, %r5646, %r5528;

	
	dp4a.s32.s32 %r5536, %r5510, %r5650, %r5532;

	
	dp4a.s32.s32 %r5540, %r5513, %r5654, %r5536;

	mul.lo.s32 %r8633, %r5540, %r8287;

	dp4a.s32.s32 %r5544, %r5516, %r5658, %r8123;

	
	dp4a.s32.s32 %r5548, %r5519, %r5662, %r5544;

	
	dp4a.s32.s32 %r5552, %r5522, %r5666, %r5548;

	
	dp4a.s32.s32 %r5556, %r5525, %r5670, %r5552;

	mad.lo.s32 %r8634, %r5556, %r8289, %r8633;
mul.ftz.f32 %f1218, %f1035, %f1215;
cvt.rn.f32.s32 %f1219, %r8634;
fma.rn.ftz.f32 %f1786, %f1218, %f1219, %f1786;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5560,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5563,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5566,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5569,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5572,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5575,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5578,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5581,r; 
}

	
	dp4a.s32.s32 %r5584, %r5560, %r5642, %r8123;

	
	dp4a.s32.s32 %r5588, %r5563, %r5646, %r5584;

	
	dp4a.s32.s32 %r5592, %r5566, %r5650, %r5588;

	
	dp4a.s32.s32 %r5596, %r5569, %r5654, %r5592;

	mul.lo.s32 %r8635, %r5596, %r8351;

	dp4a.s32.s32 %r5600, %r5572, %r5658, %r8123;

	
	dp4a.s32.s32 %r5604, %r5575, %r5662, %r5600;

	
	dp4a.s32.s32 %r5608, %r5578, %r5666, %r5604;

	
	dp4a.s32.s32 %r5612, %r5581, %r5670, %r5608;

	mad.lo.s32 %r8636, %r5612, %r8353, %r8635;
mul.ftz.f32 %f1220, %f1038, %f1215;
cvt.rn.f32.s32 %f1221, %r8636;
fma.rn.ftz.f32 %f1754, %f1220, %f1221, %f1754;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5616,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5619,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5622,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5625,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5628,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5631,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5634,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5637,r; 
}

	
	dp4a.s32.s32 %r5640, %r5616, %r5642, %r8123;

	
	dp4a.s32.s32 %r5644, %r5619, %r5646, %r5640;

	
	dp4a.s32.s32 %r5648, %r5622, %r5650, %r5644;

	
	dp4a.s32.s32 %r5652, %r5625, %r5654, %r5648;

	mul.lo.s32 %r8637, %r5652, %r8415;

	dp4a.s32.s32 %r5656, %r5628, %r5658, %r8123;

	
	dp4a.s32.s32 %r5660, %r5631, %r5662, %r5656;

	
	dp4a.s32.s32 %r5664, %r5634, %r5666, %r5660;

	
	dp4a.s32.s32 %r5668, %r5637, %r5670, %r5664;

	mad.lo.s32 %r8638, %r5668, %r8417, %r8637;
mul.ftz.f32 %f1222, %f1041, %f1215;
cvt.rn.f32.s32 %f1223, %r8638;
fma.rn.ftz.f32 %f1722, %f1222, %f1223, %f1722;
add.s32 %r8639, %r8146, 2688;
shr.u32 %r8640, %r8639, 1;
add.s32 %r8641, %r9004, %r8640;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5672,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5675,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5678,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5681,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5684,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5687,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5690,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5693,r; 
}

	ld.shared.u32 %r5866, [%r8221+10752];

	dp4a.s32.s32 %r5696, %r5672, %r5866, %r8123;

	ld.shared.u32 %r5870, [%r8221+10756];

	dp4a.s32.s32 %r5700, %r5675, %r5870, %r5696;

	ld.shared.u32 %r5874, [%r8221+10760];

	dp4a.s32.s32 %r5704, %r5678, %r5874, %r5700;

	ld.shared.u32 %r5878, [%r8221+10764];

	dp4a.s32.s32 %r5708, %r5681, %r5878, %r5704;

	mul.lo.s32 %r8642, %r5708, %r8223;
ld.shared.u32 %r5882, [%r8221+10768];

	dp4a.s32.s32 %r5712, %r5684, %r5882, %r8123;

	ld.shared.u32 %r5886, [%r8221+10772];

	dp4a.s32.s32 %r5716, %r5687, %r5886, %r5712;

	ld.shared.u32 %r5890, [%r8221+10776];

	dp4a.s32.s32 %r5720, %r5690, %r5890, %r5716;

	ld.shared.u32 %r5894, [%r8221+10780];

	dp4a.s32.s32 %r5724, %r5693, %r5894, %r5720;

	mad.lo.s32 %r8643, %r5724, %r8225, %r8642;
ld.shared.f32 %f1224, [%r8641];
mul.ftz.f32 %f1225, %f1032, %f1224;
cvt.rn.f32.s32 %f1226, %r8643;
fma.rn.ftz.f32 %f1817, %f1225, %f1226, %f1817;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5728,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5731,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5734,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5737,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5740,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5743,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5746,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5749,r; 
}

	
	dp4a.s32.s32 %r5752, %r5728, %r5866, %r8123;

	
	dp4a.s32.s32 %r5756, %r5731, %r5870, %r5752;

	
	dp4a.s32.s32 %r5760, %r5734, %r5874, %r5756;

	
	dp4a.s32.s32 %r5764, %r5737, %r5878, %r5760;

	mul.lo.s32 %r8644, %r5764, %r8287;

	dp4a.s32.s32 %r5768, %r5740, %r5882, %r8123;

	
	dp4a.s32.s32 %r5772, %r5743, %r5886, %r5768;

	
	dp4a.s32.s32 %r5776, %r5746, %r5890, %r5772;

	
	dp4a.s32.s32 %r5780, %r5749, %r5894, %r5776;

	mad.lo.s32 %r8645, %r5780, %r8289, %r8644;
mul.ftz.f32 %f1227, %f1035, %f1224;
cvt.rn.f32.s32 %f1228, %r8645;
fma.rn.ftz.f32 %f1785, %f1227, %f1228, %f1785;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5784,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5787,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5790,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5793,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5796,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5799,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5802,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5805,r; 
}

	
	dp4a.s32.s32 %r5808, %r5784, %r5866, %r8123;

	
	dp4a.s32.s32 %r5812, %r5787, %r5870, %r5808;

	
	dp4a.s32.s32 %r5816, %r5790, %r5874, %r5812;

	
	dp4a.s32.s32 %r5820, %r5793, %r5878, %r5816;

	mul.lo.s32 %r8646, %r5820, %r8351;

	dp4a.s32.s32 %r5824, %r5796, %r5882, %r8123;

	
	dp4a.s32.s32 %r5828, %r5799, %r5886, %r5824;

	
	dp4a.s32.s32 %r5832, %r5802, %r5890, %r5828;

	
	dp4a.s32.s32 %r5836, %r5805, %r5894, %r5832;

	mad.lo.s32 %r8647, %r5836, %r8353, %r8646;
mul.ftz.f32 %f1229, %f1038, %f1224;
cvt.rn.f32.s32 %f1230, %r8647;
fma.rn.ftz.f32 %f1753, %f1229, %f1230, %f1753;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5840,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5843,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5846,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5849,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5852,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5855,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5858,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5861,r; 
}

	
	dp4a.s32.s32 %r5864, %r5840, %r5866, %r8123;

	
	dp4a.s32.s32 %r5868, %r5843, %r5870, %r5864;

	
	dp4a.s32.s32 %r5872, %r5846, %r5874, %r5868;

	
	dp4a.s32.s32 %r5876, %r5849, %r5878, %r5872;

	mul.lo.s32 %r8648, %r5876, %r8415;

	dp4a.s32.s32 %r5880, %r5852, %r5882, %r8123;

	
	dp4a.s32.s32 %r5884, %r5855, %r5886, %r5880;

	
	dp4a.s32.s32 %r5888, %r5858, %r5890, %r5884;

	
	dp4a.s32.s32 %r5892, %r5861, %r5894, %r5888;

	mad.lo.s32 %r8649, %r5892, %r8417, %r8648;
mul.ftz.f32 %f1231, %f1041, %f1224;
cvt.rn.f32.s32 %f1232, %r8649;
fma.rn.ftz.f32 %f1721, %f1231, %f1232, %f1721;
add.s32 %r8650, %r8146, 2816;
shr.u32 %r8651, %r8650, 1;
add.s32 %r8652, %r9004, %r8651;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5896,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5899,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5902,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5905,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5908,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5911,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5914,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5917,r; 
}

	ld.shared.u32 %r6090, [%r8221+11264];

	dp4a.s32.s32 %r5920, %r5896, %r6090, %r8123;

	ld.shared.u32 %r6094, [%r8221+11268];

	dp4a.s32.s32 %r5924, %r5899, %r6094, %r5920;

	ld.shared.u32 %r6098, [%r8221+11272];

	dp4a.s32.s32 %r5928, %r5902, %r6098, %r5924;

	ld.shared.u32 %r6102, [%r8221+11276];

	dp4a.s32.s32 %r5932, %r5905, %r6102, %r5928;

	mul.lo.s32 %r8653, %r5932, %r8223;
ld.shared.u32 %r6106, [%r8221+11280];

	dp4a.s32.s32 %r5936, %r5908, %r6106, %r8123;

	ld.shared.u32 %r6110, [%r8221+11284];

	dp4a.s32.s32 %r5940, %r5911, %r6110, %r5936;

	ld.shared.u32 %r6114, [%r8221+11288];

	dp4a.s32.s32 %r5944, %r5914, %r6114, %r5940;

	ld.shared.u32 %r6118, [%r8221+11292];

	dp4a.s32.s32 %r5948, %r5917, %r6118, %r5944;

	mad.lo.s32 %r8654, %r5948, %r8225, %r8653;
ld.shared.f32 %f1233, [%r8652];
mul.ftz.f32 %f1234, %f1032, %f1233;
cvt.rn.f32.s32 %f1235, %r8654;
fma.rn.ftz.f32 %f1816, %f1234, %f1235, %f1816;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5952,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5955,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5958,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5961,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5964,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5967,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5970,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r5973,r; 
}

	
	dp4a.s32.s32 %r5976, %r5952, %r6090, %r8123;

	
	dp4a.s32.s32 %r5980, %r5955, %r6094, %r5976;

	
	dp4a.s32.s32 %r5984, %r5958, %r6098, %r5980;

	
	dp4a.s32.s32 %r5988, %r5961, %r6102, %r5984;

	mul.lo.s32 %r8655, %r5988, %r8287;

	dp4a.s32.s32 %r5992, %r5964, %r6106, %r8123;

	
	dp4a.s32.s32 %r5996, %r5967, %r6110, %r5992;

	
	dp4a.s32.s32 %r6000, %r5970, %r6114, %r5996;

	
	dp4a.s32.s32 %r6004, %r5973, %r6118, %r6000;

	mad.lo.s32 %r8656, %r6004, %r8289, %r8655;
mul.ftz.f32 %f1236, %f1035, %f1233;
cvt.rn.f32.s32 %f1237, %r8656;
fma.rn.ftz.f32 %f1784, %f1236, %f1237, %f1784;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6008,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6011,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6014,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6017,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6020,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6023,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6026,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6029,r; 
}

	
	dp4a.s32.s32 %r6032, %r6008, %r6090, %r8123;

	
	dp4a.s32.s32 %r6036, %r6011, %r6094, %r6032;

	
	dp4a.s32.s32 %r6040, %r6014, %r6098, %r6036;

	
	dp4a.s32.s32 %r6044, %r6017, %r6102, %r6040;

	mul.lo.s32 %r8657, %r6044, %r8351;

	dp4a.s32.s32 %r6048, %r6020, %r6106, %r8123;

	
	dp4a.s32.s32 %r6052, %r6023, %r6110, %r6048;

	
	dp4a.s32.s32 %r6056, %r6026, %r6114, %r6052;

	
	dp4a.s32.s32 %r6060, %r6029, %r6118, %r6056;

	mad.lo.s32 %r8658, %r6060, %r8353, %r8657;
mul.ftz.f32 %f1238, %f1038, %f1233;
cvt.rn.f32.s32 %f1239, %r8658;
fma.rn.ftz.f32 %f1752, %f1238, %f1239, %f1752;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6064,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6067,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6070,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6073,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6076,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6079,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6082,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6085,r; 
}

	
	dp4a.s32.s32 %r6088, %r6064, %r6090, %r8123;

	
	dp4a.s32.s32 %r6092, %r6067, %r6094, %r6088;

	
	dp4a.s32.s32 %r6096, %r6070, %r6098, %r6092;

	
	dp4a.s32.s32 %r6100, %r6073, %r6102, %r6096;

	mul.lo.s32 %r8659, %r6100, %r8415;

	dp4a.s32.s32 %r6104, %r6076, %r6106, %r8123;

	
	dp4a.s32.s32 %r6108, %r6079, %r6110, %r6104;

	
	dp4a.s32.s32 %r6112, %r6082, %r6114, %r6108;

	
	dp4a.s32.s32 %r6116, %r6085, %r6118, %r6112;

	mad.lo.s32 %r8660, %r6116, %r8417, %r8659;
mul.ftz.f32 %f1240, %f1041, %f1233;
cvt.rn.f32.s32 %f1241, %r8660;
fma.rn.ftz.f32 %f1720, %f1240, %f1241, %f1720;
add.s32 %r8661, %r8146, 2944;
shr.u32 %r8662, %r8661, 1;
add.s32 %r8663, %r9004, %r8662;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6121; 
mov.b32 b,%r6122; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6120,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6124; 
mov.b32 b,%r6125; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6123,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6127; 
mov.b32 b,%r6128; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6126,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6130; 
mov.b32 b,%r6131; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6129,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6133; 
mov.b32 b,%r6134; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6132,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6136; 
mov.b32 b,%r6137; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6135,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6139; 
mov.b32 b,%r6140; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6138,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6142; 
mov.b32 b,%r6143; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6141,r; 
}

	ld.shared.u32 %r6314, [%r8221+11776];

	dp4a.s32.s32 %r6144, %r6120, %r6314, %r8123;

	ld.shared.u32 %r6318, [%r8221+11780];

	dp4a.s32.s32 %r6148, %r6123, %r6318, %r6144;

	ld.shared.u32 %r6322, [%r8221+11784];

	dp4a.s32.s32 %r6152, %r6126, %r6322, %r6148;

	ld.shared.u32 %r6326, [%r8221+11788];

	dp4a.s32.s32 %r6156, %r6129, %r6326, %r6152;

	mul.lo.s32 %r8664, %r6156, %r8223;
ld.shared.u32 %r6330, [%r8221+11792];

	dp4a.s32.s32 %r6160, %r6132, %r6330, %r8123;

	ld.shared.u32 %r6334, [%r8221+11796];

	dp4a.s32.s32 %r6164, %r6135, %r6334, %r6160;

	ld.shared.u32 %r6338, [%r8221+11800];

	dp4a.s32.s32 %r6168, %r6138, %r6338, %r6164;

	ld.shared.u32 %r6342, [%r8221+11804];

	dp4a.s32.s32 %r6172, %r6141, %r6342, %r6168;

	mad.lo.s32 %r8665, %r6172, %r8225, %r8664;
ld.shared.f32 %f1242, [%r8663];
mul.ftz.f32 %f1243, %f1032, %f1242;
cvt.rn.f32.s32 %f1244, %r8665;
fma.rn.ftz.f32 %f1815, %f1243, %f1244, %f1815;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6177; 
mov.b32 b,%r6178; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6176,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6180; 
mov.b32 b,%r6181; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6179,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6183; 
mov.b32 b,%r6184; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6182,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6186; 
mov.b32 b,%r6187; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6185,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6189; 
mov.b32 b,%r6190; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6188,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6192; 
mov.b32 b,%r6193; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6191,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6195; 
mov.b32 b,%r6196; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6194,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6198; 
mov.b32 b,%r6199; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6197,r; 
}

	
	dp4a.s32.s32 %r6200, %r6176, %r6314, %r8123;

	
	dp4a.s32.s32 %r6204, %r6179, %r6318, %r6200;

	
	dp4a.s32.s32 %r6208, %r6182, %r6322, %r6204;

	
	dp4a.s32.s32 %r6212, %r6185, %r6326, %r6208;

	mul.lo.s32 %r8666, %r6212, %r8287;

	dp4a.s32.s32 %r6216, %r6188, %r6330, %r8123;

	
	dp4a.s32.s32 %r6220, %r6191, %r6334, %r6216;

	
	dp4a.s32.s32 %r6224, %r6194, %r6338, %r6220;

	
	dp4a.s32.s32 %r6228, %r6197, %r6342, %r6224;

	mad.lo.s32 %r8667, %r6228, %r8289, %r8666;
mul.ftz.f32 %f1245, %f1035, %f1242;
cvt.rn.f32.s32 %f1246, %r8667;
fma.rn.ftz.f32 %f1783, %f1245, %f1246, %f1783;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6233; 
mov.b32 b,%r6234; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6232,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6236; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6235,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6238,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6241,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6244,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6247,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6250,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6253,r; 
}

	
	dp4a.s32.s32 %r6256, %r6232, %r6314, %r8123;

	
	dp4a.s32.s32 %r6260, %r6235, %r6318, %r6256;

	
	dp4a.s32.s32 %r6264, %r6238, %r6322, %r6260;

	
	dp4a.s32.s32 %r6268, %r6241, %r6326, %r6264;

	mul.lo.s32 %r8668, %r6268, %r8351;

	dp4a.s32.s32 %r6272, %r6244, %r6330, %r8123;

	
	dp4a.s32.s32 %r6276, %r6247, %r6334, %r6272;

	
	dp4a.s32.s32 %r6280, %r6250, %r6338, %r6276;

	
	dp4a.s32.s32 %r6284, %r6253, %r6342, %r6280;

	mad.lo.s32 %r8669, %r6284, %r8353, %r8668;
mul.ftz.f32 %f1247, %f1038, %f1242;
cvt.rn.f32.s32 %f1248, %r8669;
fma.rn.ftz.f32 %f1751, %f1247, %f1248, %f1751;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6288,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6291,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6294,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6297,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6300,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6303,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6306,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6309,r; 
}

	
	dp4a.s32.s32 %r6312, %r6288, %r6314, %r8123;

	
	dp4a.s32.s32 %r6316, %r6291, %r6318, %r6312;

	
	dp4a.s32.s32 %r6320, %r6294, %r6322, %r6316;

	
	dp4a.s32.s32 %r6324, %r6297, %r6326, %r6320;

	mul.lo.s32 %r8670, %r6324, %r8415;

	dp4a.s32.s32 %r6328, %r6300, %r6330, %r8123;

	
	dp4a.s32.s32 %r6332, %r6303, %r6334, %r6328;

	
	dp4a.s32.s32 %r6336, %r6306, %r6338, %r6332;

	
	dp4a.s32.s32 %r6340, %r6309, %r6342, %r6336;

	mad.lo.s32 %r8671, %r6340, %r8417, %r8670;
mul.ftz.f32 %f1249, %f1041, %f1242;
cvt.rn.f32.s32 %f1250, %r8671;
fma.rn.ftz.f32 %f1719, %f1249, %f1250, %f1719;
add.s32 %r8672, %r8146, 3072;
shr.u32 %r8673, %r8672, 1;
add.s32 %r8674, %r9004, %r8673;
ld.shared.u32 %r8675, [%r8165];
shr.s32 %r8676, %r8675, %r8138;
and.b32 %r7913, %r8676, 50529027;
ld.shared.u32 %r8677, [%r8170];
shr.s32 %r8678, %r8677, %r8172;
shl.b32 %r8679, %r8678, 2;
and.b32 %r7914, %r8679, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7913; 
mov.b32 b,%r7914; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6344,r; 
}

	ld.shared.u32 %r8680, [%r8165+4];
shr.s32 %r8681, %r8680, %r8138;
and.b32 %r7916, %r8681, 50529027;
ld.shared.u32 %r8682, [%r8170+4];
shr.s32 %r8683, %r8682, %r8178;
shl.b32 %r8684, %r8683, 2;
and.b32 %r7917, %r8684, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7916; 
mov.b32 b,%r7917; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6347,r; 
}

	ld.shared.u32 %r8685, [%r8165+8];
shr.s32 %r8686, %r8685, %r8138;
and.b32 %r7919, %r8686, 50529027;
ld.shared.u32 %r8687, [%r8170+8];
shr.s32 %r8688, %r8687, %r8178;
shl.b32 %r8689, %r8688, 2;
and.b32 %r7920, %r8689, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7919; 
mov.b32 b,%r7920; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6350,r; 
}

	ld.shared.u32 %r8690, [%r8165+12];
shr.s32 %r8691, %r8690, %r8138;
and.b32 %r7922, %r8691, 50529027;
ld.shared.u32 %r8692, [%r8170+12];
shr.s32 %r8693, %r8692, %r8178;
shl.b32 %r8694, %r8693, 2;
and.b32 %r7923, %r8694, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7922; 
mov.b32 b,%r7923; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6353,r; 
}

	ld.shared.u32 %r8695, [%r8165+16];
shr.s32 %r8696, %r8695, %r8138;
and.b32 %r7925, %r8696, 50529027;
ld.shared.u32 %r8697, [%r8170+16];
shr.s32 %r8698, %r8697, %r8178;
shl.b32 %r8699, %r8698, 2;
and.b32 %r7926, %r8699, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7925; 
mov.b32 b,%r7926; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6356,r; 
}

	ld.shared.u32 %r8700, [%r8165+20];
shr.s32 %r8701, %r8700, %r8138;
and.b32 %r7928, %r8701, 50529027;
ld.shared.u32 %r8702, [%r8170+20];
shr.s32 %r8703, %r8702, %r8178;
shl.b32 %r8704, %r8703, 2;
and.b32 %r7929, %r8704, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7928; 
mov.b32 b,%r7929; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6359,r; 
}

	ld.shared.u32 %r8705, [%r8165+24];
shr.s32 %r8706, %r8705, %r8138;
and.b32 %r7931, %r8706, 50529027;
ld.shared.u32 %r8707, [%r8170+24];
shr.s32 %r8708, %r8707, %r8178;
shl.b32 %r8709, %r8708, 2;
and.b32 %r7932, %r8709, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7931; 
mov.b32 b,%r7932; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6362,r; 
}

	ld.shared.u32 %r8710, [%r8165+28];
shr.s32 %r8711, %r8710, %r8138;
and.b32 %r7934, %r8711, 50529027;
ld.shared.u32 %r8712, [%r8170+28];
shr.s32 %r8713, %r8712, %r8178;
shl.b32 %r8714, %r8713, 2;
and.b32 %r7935, %r8714, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7934; 
mov.b32 b,%r7935; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6365,r; 
}

	ld.shared.u32 %r6538, [%r8221+12288];

	dp4a.s32.s32 %r6368, %r6344, %r6538, %r8123;

	ld.shared.u32 %r6542, [%r8221+12292];

	dp4a.s32.s32 %r6372, %r6347, %r6542, %r6368;

	ld.shared.u32 %r6546, [%r8221+12296];

	dp4a.s32.s32 %r6376, %r6350, %r6546, %r6372;

	ld.shared.u32 %r6550, [%r8221+12300];

	dp4a.s32.s32 %r6380, %r6353, %r6550, %r6376;

	ld.shared.s8 %r8715, [%r8222];
mul.lo.s32 %r8716, %r6380, %r8715;
ld.shared.u32 %r6554, [%r8221+12304];

	dp4a.s32.s32 %r6384, %r6356, %r6554, %r8123;

	ld.shared.u32 %r6558, [%r8221+12308];

	dp4a.s32.s32 %r6388, %r6359, %r6558, %r6384;

	ld.shared.u32 %r6562, [%r8221+12312];

	dp4a.s32.s32 %r6392, %r6362, %r6562, %r6388;

	ld.shared.u32 %r6566, [%r8221+12316];

	dp4a.s32.s32 %r6396, %r6365, %r6566, %r6392;

	ld.shared.s8 %r8717, [%r8222+1];
mad.lo.s32 %r8718, %r6396, %r8717, %r8716;
ld.shared.f32 %f1251, [%r8674];
ld.shared.f32 %f1252, [%r8218];
mul.ftz.f32 %f1253, %f1252, %f1251;
cvt.rn.f32.s32 %f1254, %r8718;
fma.rn.ftz.f32 %f1814, %f1253, %f1254, %f1814;
ld.shared.u32 %r8719, [%r8165+4224];
shr.s32 %r8720, %r8719, %r8138;
and.b32 %r7969, %r8720, 50529027;
ld.shared.u32 %r8721, [%r8241];
shr.s32 %r8722, %r8721, %r8172;
shl.b32 %r8723, %r8722, 2;
and.b32 %r7970, %r8723, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7969; 
mov.b32 b,%r7970; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6400,r; 
}

	ld.shared.u32 %r8724, [%r8165+4228];
shr.s32 %r8725, %r8724, %r8138;
and.b32 %r7972, %r8725, 50529027;
ld.shared.u32 %r8726, [%r8241+4];
shr.s32 %r8727, %r8726, %r8178;
shl.b32 %r8728, %r8727, 2;
and.b32 %r7973, %r8728, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7972; 
mov.b32 b,%r7973; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6403,r; 
}

	ld.shared.u32 %r8729, [%r8165+4232];
shr.s32 %r8730, %r8729, %r8138;
and.b32 %r7975, %r8730, 50529027;
ld.shared.u32 %r8731, [%r8241+8];
shr.s32 %r8732, %r8731, %r8178;
shl.b32 %r8733, %r8732, 2;
and.b32 %r7976, %r8733, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7975; 
mov.b32 b,%r7976; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6406,r; 
}

	ld.shared.u32 %r8734, [%r8165+4236];
shr.s32 %r8735, %r8734, %r8138;
and.b32 %r7978, %r8735, 50529027;
ld.shared.u32 %r8736, [%r8241+12];
shr.s32 %r8737, %r8736, %r8178;
shl.b32 %r8738, %r8737, 2;
and.b32 %r7979, %r8738, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7978; 
mov.b32 b,%r7979; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6409,r; 
}

	ld.shared.u32 %r8739, [%r8165+4240];
shr.s32 %r8740, %r8739, %r8138;
and.b32 %r7981, %r8740, 50529027;
ld.shared.u32 %r8741, [%r8241+16];
shr.s32 %r8742, %r8741, %r8178;
shl.b32 %r8743, %r8742, 2;
and.b32 %r7982, %r8743, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7981; 
mov.b32 b,%r7982; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6412,r; 
}

	ld.shared.u32 %r8744, [%r8165+4244];
shr.s32 %r8745, %r8744, %r8138;
and.b32 %r7984, %r8745, 50529027;
ld.shared.u32 %r8746, [%r8241+20];
shr.s32 %r8747, %r8746, %r8178;
shl.b32 %r8748, %r8747, 2;
and.b32 %r7985, %r8748, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7984; 
mov.b32 b,%r7985; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6415,r; 
}

	ld.shared.u32 %r8749, [%r8165+4248];
shr.s32 %r8750, %r8749, %r8138;
and.b32 %r7987, %r8750, 50529027;
ld.shared.u32 %r8751, [%r8241+24];
shr.s32 %r8752, %r8751, %r8178;
shl.b32 %r8753, %r8752, 2;
and.b32 %r7988, %r8753, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7987; 
mov.b32 b,%r7988; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6418,r; 
}

	ld.shared.u32 %r8754, [%r8165+4252];
shr.s32 %r8755, %r8754, %r8138;
and.b32 %r7990, %r8755, 50529027;
ld.shared.u32 %r8756, [%r8241+28];
shr.s32 %r8757, %r8756, %r8178;
shl.b32 %r8758, %r8757, 2;
and.b32 %r7991, %r8758, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7990; 
mov.b32 b,%r7991; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6421,r; 
}

	
	dp4a.s32.s32 %r6424, %r6400, %r6538, %r8123;

	
	dp4a.s32.s32 %r6428, %r6403, %r6542, %r6424;

	
	dp4a.s32.s32 %r6432, %r6406, %r6546, %r6428;

	
	dp4a.s32.s32 %r6436, %r6409, %r6550, %r6432;

	ld.shared.s8 %r8759, [%r8286];
mul.lo.s32 %r8760, %r6436, %r8759;

	dp4a.s32.s32 %r6440, %r6412, %r6554, %r8123;

	
	dp4a.s32.s32 %r6444, %r6415, %r6558, %r6440;

	
	dp4a.s32.s32 %r6448, %r6418, %r6562, %r6444;

	
	dp4a.s32.s32 %r6452, %r6421, %r6566, %r6448;

	ld.shared.s8 %r8761, [%r8286+1];
mad.lo.s32 %r8762, %r6452, %r8761, %r8760;
ld.shared.f32 %f1255, [%r8285];
mul.ftz.f32 %f1256, %f1255, %f1251;
cvt.rn.f32.s32 %f1257, %r8762;
fma.rn.ftz.f32 %f1782, %f1256, %f1257, %f1782;
ld.shared.u32 %r8763, [%r8165+8448];
shr.s32 %r8764, %r8763, %r8138;
and.b32 %r8025, %r8764, 50529027;
ld.shared.u32 %r8765, [%r8305];
shr.s32 %r8766, %r8765, %r8172;
shl.b32 %r8767, %r8766, 2;
and.b32 %r8026, %r8767, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8025; 
mov.b32 b,%r8026; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6456,r; 
}

	ld.shared.u32 %r8768, [%r8165+8452];
shr.s32 %r8769, %r8768, %r8138;
and.b32 %r8028, %r8769, 50529027;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8028; 
mov.b32 b,%r6461; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6459,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6463; 
mov.b32 b,%r6464; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6462,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6466; 
mov.b32 b,%r6467; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6465,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6469; 
mov.b32 b,%r6470; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6468,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6472; 
mov.b32 b,%r6473; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6471,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6475; 
mov.b32 b,%r6476; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6474,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6478; 
mov.b32 b,%r6479; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6477,r; 
}

	
	dp4a.s32.s32 %r6480, %r6456, %r6538, %r8123;

	
	dp4a.s32.s32 %r6484, %r6459, %r6542, %r6480;

	
	dp4a.s32.s32 %r6488, %r6462, %r6546, %r6484;

	
	dp4a.s32.s32 %r6492, %r6465, %r6550, %r6488;

	mul.lo.s32 %r8770, %r6492, %r8351;

	dp4a.s32.s32 %r6496, %r6468, %r6554, %r8123;

	
	dp4a.s32.s32 %r6500, %r6471, %r6558, %r6496;

	
	dp4a.s32.s32 %r6504, %r6474, %r6562, %r6500;

	
	dp4a.s32.s32 %r6508, %r6477, %r6566, %r6504;

	mad.lo.s32 %r8771, %r6508, %r8353, %r8770;
mul.ftz.f32 %f1258, %f1038, %f1251;
cvt.rn.f32.s32 %f1259, %r8771;
fma.rn.ftz.f32 %f1750, %f1258, %f1259, %f1750;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6513; 
mov.b32 b,%r6514; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6512,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6516; 
mov.b32 b,%r6517; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6515,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6519; 
mov.b32 b,%r6520; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6518,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6522; 
mov.b32 b,%r6523; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6521,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6525; 
mov.b32 b,%r6526; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6524,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6528; 
mov.b32 b,%r6529; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6527,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6531; 
mov.b32 b,%r6532; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6530,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r6534; 
mov.b32 b,%r6535; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6533,r; 
}

	
	dp4a.s32.s32 %r6536, %r6512, %r6538, %r8123;

	
	dp4a.s32.s32 %r6540, %r6515, %r6542, %r6536;

	
	dp4a.s32.s32 %r6544, %r6518, %r6546, %r6540;

	
	dp4a.s32.s32 %r6548, %r6521, %r6550, %r6544;

	mul.lo.s32 %r8772, %r6548, %r8415;

	dp4a.s32.s32 %r6552, %r6524, %r6554, %r8123;

	
	dp4a.s32.s32 %r6556, %r6527, %r6558, %r6552;

	
	dp4a.s32.s32 %r6560, %r6530, %r6562, %r6556;

	
	dp4a.s32.s32 %r6564, %r6533, %r6566, %r6560;

	mad.lo.s32 %r8773, %r6564, %r8417, %r8772;
mul.ftz.f32 %f1260, %f1041, %f1251;
cvt.rn.f32.s32 %f1261, %r8773;
fma.rn.ftz.f32 %f1718, %f1260, %f1261, %f1718;
add.s32 %r8774, %r8146, 3200;
shr.u32 %r8775, %r8774, 1;
add.s32 %r8776, %r9004, %r8775;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7913; 
mov.b32 b,%r7914; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6568,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7916; 
mov.b32 b,%r7917; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6571,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7919; 
mov.b32 b,%r7920; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6574,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7922; 
mov.b32 b,%r7923; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6577,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7925; 
mov.b32 b,%r7926; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6580,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7928; 
mov.b32 b,%r7929; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6583,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7931; 
mov.b32 b,%r7932; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6586,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7934; 
mov.b32 b,%r7935; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6589,r; 
}

	ld.shared.u32 %r6762, [%r8221+12800];

	dp4a.s32.s32 %r6592, %r6568, %r6762, %r8123;

	ld.shared.u32 %r6766, [%r8221+12804];

	dp4a.s32.s32 %r6596, %r6571, %r6766, %r6592;

	ld.shared.u32 %r6770, [%r8221+12808];

	dp4a.s32.s32 %r6600, %r6574, %r6770, %r6596;

	ld.shared.u32 %r6774, [%r8221+12812];

	dp4a.s32.s32 %r6604, %r6577, %r6774, %r6600;

	mul.lo.s32 %r8777, %r6604, %r8715;
ld.shared.u32 %r6778, [%r8221+12816];

	dp4a.s32.s32 %r6608, %r6580, %r6778, %r8123;

	ld.shared.u32 %r6782, [%r8221+12820];

	dp4a.s32.s32 %r6612, %r6583, %r6782, %r6608;

	ld.shared.u32 %r6786, [%r8221+12824];

	dp4a.s32.s32 %r6616, %r6586, %r6786, %r6612;

	ld.shared.u32 %r6790, [%r8221+12828];

	dp4a.s32.s32 %r6620, %r6589, %r6790, %r6616;

	mad.lo.s32 %r8778, %r6620, %r8717, %r8777;
ld.shared.f32 %f1262, [%r8776];
mul.ftz.f32 %f1263, %f1252, %f1262;
cvt.rn.f32.s32 %f1264, %r8778;
fma.rn.ftz.f32 %f1813, %f1263, %f1264, %f1813;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7969; 
mov.b32 b,%r7970; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6624,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7972; 
mov.b32 b,%r7973; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6627,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7975; 
mov.b32 b,%r7976; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6630,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7978; 
mov.b32 b,%r7979; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6633,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7981; 
mov.b32 b,%r7982; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6636,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7984; 
mov.b32 b,%r7985; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6639,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7987; 
mov.b32 b,%r7988; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6642,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7990; 
mov.b32 b,%r7991; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6645,r; 
}

	
	dp4a.s32.s32 %r6648, %r6624, %r6762, %r8123;

	
	dp4a.s32.s32 %r6652, %r6627, %r6766, %r6648;

	
	dp4a.s32.s32 %r6656, %r6630, %r6770, %r6652;

	
	dp4a.s32.s32 %r6660, %r6633, %r6774, %r6656;

	mul.lo.s32 %r8779, %r6660, %r8759;

	dp4a.s32.s32 %r6664, %r6636, %r6778, %r8123;

	
	dp4a.s32.s32 %r6668, %r6639, %r6782, %r6664;

	
	dp4a.s32.s32 %r6672, %r6642, %r6786, %r6668;

	
	dp4a.s32.s32 %r6676, %r6645, %r6790, %r6672;

	mad.lo.s32 %r8780, %r6676, %r8761, %r8779;
mul.ftz.f32 %f1265, %f1255, %f1262;
cvt.rn.f32.s32 %f1266, %r8780;
fma.rn.ftz.f32 %f1781, %f1265, %f1266, %f1781;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8025; 
mov.b32 b,%r8026; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6680,r; 
}

	ld.shared.u32 %r8781, [%r8305+4];
shr.s32 %r8782, %r8781, %r8178;
shl.b32 %r8783, %r8782, 2;
and.b32 %r8029, %r8783, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8028; 
mov.b32 b,%r8029; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6683,r; 
}

	ld.shared.u32 %r8784, [%r8165+8456];
shr.s32 %r8785, %r8784, %r8138;
and.b32 %r8031, %r8785, 50529027;
ld.shared.u32 %r8786, [%r8305+8];
shr.s32 %r8787, %r8786, %r8178;
shl.b32 %r8788, %r8787, 2;
and.b32 %r8032, %r8788, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8031; 
mov.b32 b,%r8032; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6686,r; 
}

	ld.shared.u32 %r8789, [%r8165+8460];
shr.s32 %r8790, %r8789, %r8138;
and.b32 %r8034, %r8790, 50529027;
ld.shared.u32 %r8791, [%r8305+12];
shr.s32 %r8792, %r8791, %r8178;
shl.b32 %r8793, %r8792, 2;
and.b32 %r8035, %r8793, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8034; 
mov.b32 b,%r8035; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6689,r; 
}

	ld.shared.u32 %r8794, [%r8165+8464];
shr.s32 %r8795, %r8794, %r8138;
and.b32 %r8037, %r8795, 50529027;
ld.shared.u32 %r8796, [%r8305+16];
shr.s32 %r8797, %r8796, %r8178;
shl.b32 %r8798, %r8797, 2;
and.b32 %r8038, %r8798, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8037; 
mov.b32 b,%r8038; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6692,r; 
}

	ld.shared.u32 %r8799, [%r8165+8468];
shr.s32 %r8800, %r8799, %r8138;
and.b32 %r8040, %r8800, 50529027;
ld.shared.u32 %r8801, [%r8305+20];
shr.s32 %r8802, %r8801, %r8178;
shl.b32 %r8803, %r8802, 2;
and.b32 %r8041, %r8803, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8040; 
mov.b32 b,%r8041; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6695,r; 
}

	ld.shared.u32 %r8804, [%r8165+8472];
shr.s32 %r8805, %r8804, %r8138;
and.b32 %r8043, %r8805, 50529027;
ld.shared.u32 %r8806, [%r8305+24];
shr.s32 %r8807, %r8806, %r8178;
shl.b32 %r8808, %r8807, 2;
and.b32 %r8044, %r8808, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8043; 
mov.b32 b,%r8044; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6698,r; 
}

	ld.shared.u32 %r8809, [%r8165+8476];
shr.s32 %r8810, %r8809, %r8138;
and.b32 %r8046, %r8810, 50529027;
ld.shared.u32 %r8811, [%r8305+28];
shr.s32 %r8812, %r8811, %r8178;
shl.b32 %r8813, %r8812, 2;
and.b32 %r8047, %r8813, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8046; 
mov.b32 b,%r8047; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6701,r; 
}

	
	dp4a.s32.s32 %r6704, %r6680, %r6762, %r8123;

	
	dp4a.s32.s32 %r6708, %r6683, %r6766, %r6704;

	
	dp4a.s32.s32 %r6712, %r6686, %r6770, %r6708;

	
	dp4a.s32.s32 %r6716, %r6689, %r6774, %r6712;

	ld.shared.s8 %r8814, [%r8350];
mul.lo.s32 %r8815, %r6716, %r8814;

	dp4a.s32.s32 %r6720, %r6692, %r6778, %r8123;

	
	dp4a.s32.s32 %r6724, %r6695, %r6782, %r6720;

	
	dp4a.s32.s32 %r6728, %r6698, %r6786, %r6724;

	
	dp4a.s32.s32 %r6732, %r6701, %r6790, %r6728;

	ld.shared.s8 %r8816, [%r8350+1];
mad.lo.s32 %r8817, %r6732, %r8816, %r8815;
ld.shared.f32 %f1267, [%r8349];
mul.ftz.f32 %f1268, %f1267, %f1262;
cvt.rn.f32.s32 %f1269, %r8817;
fma.rn.ftz.f32 %f1749, %f1268, %f1269, %f1749;
ld.shared.u32 %r8818, [%r8165+12672];
shr.s32 %r8819, %r8818, %r8138;
and.b32 %r8081, %r8819, 50529027;
ld.shared.u32 %r8820, [%r8369];
shr.s32 %r8821, %r8820, %r8172;
shl.b32 %r8822, %r8821, 2;
and.b32 %r8082, %r8822, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8081; 
mov.b32 b,%r8082; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6736,r; 
}

	ld.shared.u32 %r8823, [%r8165+12676];
shr.s32 %r8824, %r8823, %r8138;
and.b32 %r8084, %r8824, 50529027;
ld.shared.u32 %r8825, [%r8369+4];
shr.s32 %r8826, %r8825, %r8178;
shl.b32 %r8827, %r8826, 2;
and.b32 %r8085, %r8827, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8084; 
mov.b32 b,%r8085; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6739,r; 
}

	ld.shared.u32 %r8828, [%r8165+12680];
shr.s32 %r8829, %r8828, %r8138;
and.b32 %r8087, %r8829, 50529027;
ld.shared.u32 %r8830, [%r8369+8];
shr.s32 %r8831, %r8830, %r8178;
shl.b32 %r8832, %r8831, 2;
and.b32 %r8088, %r8832, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8087; 
mov.b32 b,%r8088; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6742,r; 
}

	ld.shared.u32 %r8833, [%r8165+12684];
shr.s32 %r8834, %r8833, %r8138;
and.b32 %r8090, %r8834, 50529027;
ld.shared.u32 %r8835, [%r8369+12];
shr.s32 %r8836, %r8835, %r8178;
shl.b32 %r8837, %r8836, 2;
and.b32 %r8091, %r8837, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8090; 
mov.b32 b,%r8091; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6745,r; 
}

	ld.shared.u32 %r8838, [%r8165+12688];
shr.s32 %r8839, %r8838, %r8138;
and.b32 %r8093, %r8839, 50529027;
ld.shared.u32 %r8840, [%r8369+16];
shr.s32 %r8841, %r8840, %r8178;
shl.b32 %r8842, %r8841, 2;
and.b32 %r8094, %r8842, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8093; 
mov.b32 b,%r8094; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6748,r; 
}

	ld.shared.u32 %r8843, [%r8165+12692];
shr.s32 %r8844, %r8843, %r8138;
and.b32 %r8096, %r8844, 50529027;
ld.shared.u32 %r8845, [%r8369+20];
shr.s32 %r8846, %r8845, %r8178;
shl.b32 %r8847, %r8846, 2;
and.b32 %r8097, %r8847, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8096; 
mov.b32 b,%r8097; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6751,r; 
}

	ld.shared.u32 %r8848, [%r8165+12696];
shr.s32 %r8849, %r8848, %r8138;
and.b32 %r8099, %r8849, 50529027;
ld.shared.u32 %r8850, [%r8369+24];
shr.s32 %r8851, %r8850, %r8178;
shl.b32 %r8852, %r8851, 2;
and.b32 %r8100, %r8852, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8099; 
mov.b32 b,%r8100; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6754,r; 
}

	ld.shared.u32 %r8853, [%r8165+12700];
shr.s32 %r8854, %r8853, %r8138;
and.b32 %r8102, %r8854, 50529027;
ld.shared.u32 %r8855, [%r8369+28];
shr.s32 %r8856, %r8855, %r8178;
shl.b32 %r8857, %r8856, 2;
and.b32 %r8103, %r8857, 67372036;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8102; 
mov.b32 b,%r8103; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6757,r; 
}

	
	dp4a.s32.s32 %r6760, %r6736, %r6762, %r8123;

	
	dp4a.s32.s32 %r6764, %r6739, %r6766, %r6760;

	
	dp4a.s32.s32 %r6768, %r6742, %r6770, %r6764;

	
	dp4a.s32.s32 %r6772, %r6745, %r6774, %r6768;

	ld.shared.s8 %r8858, [%r8414];
mul.lo.s32 %r8859, %r6772, %r8858;

	dp4a.s32.s32 %r6776, %r6748, %r6778, %r8123;

	
	dp4a.s32.s32 %r6780, %r6751, %r6782, %r6776;

	
	dp4a.s32.s32 %r6784, %r6754, %r6786, %r6780;

	
	dp4a.s32.s32 %r6788, %r6757, %r6790, %r6784;

	ld.shared.s8 %r8860, [%r8414+1];
mad.lo.s32 %r8861, %r6788, %r8860, %r8859;
ld.shared.f32 %f1270, [%r8413];
mul.ftz.f32 %f1271, %f1270, %f1262;
cvt.rn.f32.s32 %f1272, %r8861;
fma.rn.ftz.f32 %f1717, %f1271, %f1272, %f1717;
add.s32 %r8862, %r8146, 3328;
shr.u32 %r8863, %r8862, 1;
add.s32 %r8864, %r9004, %r8863;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7913; 
mov.b32 b,%r7914; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6792,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7916; 
mov.b32 b,%r7917; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6795,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7919; 
mov.b32 b,%r7920; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6798,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7922; 
mov.b32 b,%r7923; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6801,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7925; 
mov.b32 b,%r7926; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6804,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7928; 
mov.b32 b,%r7929; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6807,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7931; 
mov.b32 b,%r7932; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6810,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7934; 
mov.b32 b,%r7935; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6813,r; 
}

	ld.shared.u32 %r6986, [%r8221+13312];

	dp4a.s32.s32 %r6816, %r6792, %r6986, %r8123;

	ld.shared.u32 %r6990, [%r8221+13316];

	dp4a.s32.s32 %r6820, %r6795, %r6990, %r6816;

	ld.shared.u32 %r6994, [%r8221+13320];

	dp4a.s32.s32 %r6824, %r6798, %r6994, %r6820;

	ld.shared.u32 %r6998, [%r8221+13324];

	dp4a.s32.s32 %r6828, %r6801, %r6998, %r6824;

	mul.lo.s32 %r8865, %r6828, %r8715;
ld.shared.u32 %r7002, [%r8221+13328];

	dp4a.s32.s32 %r6832, %r6804, %r7002, %r8123;

	ld.shared.u32 %r7006, [%r8221+13332];

	dp4a.s32.s32 %r6836, %r6807, %r7006, %r6832;

	ld.shared.u32 %r7010, [%r8221+13336];

	dp4a.s32.s32 %r6840, %r6810, %r7010, %r6836;

	ld.shared.u32 %r7014, [%r8221+13340];

	dp4a.s32.s32 %r6844, %r6813, %r7014, %r6840;

	mad.lo.s32 %r8866, %r6844, %r8717, %r8865;
ld.shared.f32 %f1273, [%r8864];
mul.ftz.f32 %f1274, %f1252, %f1273;
cvt.rn.f32.s32 %f1275, %r8866;
fma.rn.ftz.f32 %f1812, %f1274, %f1275, %f1812;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7969; 
mov.b32 b,%r7970; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6848,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7972; 
mov.b32 b,%r7973; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6851,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7975; 
mov.b32 b,%r7976; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6854,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7978; 
mov.b32 b,%r7979; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6857,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7981; 
mov.b32 b,%r7982; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6860,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7984; 
mov.b32 b,%r7985; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6863,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7987; 
mov.b32 b,%r7988; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6866,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7990; 
mov.b32 b,%r7991; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6869,r; 
}

	
	dp4a.s32.s32 %r6872, %r6848, %r6986, %r8123;

	
	dp4a.s32.s32 %r6876, %r6851, %r6990, %r6872;

	
	dp4a.s32.s32 %r6880, %r6854, %r6994, %r6876;

	
	dp4a.s32.s32 %r6884, %r6857, %r6998, %r6880;

	mul.lo.s32 %r8867, %r6884, %r8759;

	dp4a.s32.s32 %r6888, %r6860, %r7002, %r8123;

	
	dp4a.s32.s32 %r6892, %r6863, %r7006, %r6888;

	
	dp4a.s32.s32 %r6896, %r6866, %r7010, %r6892;

	
	dp4a.s32.s32 %r6900, %r6869, %r7014, %r6896;

	mad.lo.s32 %r8868, %r6900, %r8761, %r8867;
mul.ftz.f32 %f1276, %f1255, %f1273;
cvt.rn.f32.s32 %f1277, %r8868;
fma.rn.ftz.f32 %f1780, %f1276, %f1277, %f1780;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8025; 
mov.b32 b,%r8026; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6904,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8028; 
mov.b32 b,%r8029; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6907,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8031; 
mov.b32 b,%r8032; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6910,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8034; 
mov.b32 b,%r8035; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6913,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8037; 
mov.b32 b,%r8038; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6916,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8040; 
mov.b32 b,%r8041; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6919,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8043; 
mov.b32 b,%r8044; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6922,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8046; 
mov.b32 b,%r8047; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6925,r; 
}

	
	dp4a.s32.s32 %r6928, %r6904, %r6986, %r8123;

	
	dp4a.s32.s32 %r6932, %r6907, %r6990, %r6928;

	
	dp4a.s32.s32 %r6936, %r6910, %r6994, %r6932;

	
	dp4a.s32.s32 %r6940, %r6913, %r6998, %r6936;

	mul.lo.s32 %r8869, %r6940, %r8814;

	dp4a.s32.s32 %r6944, %r6916, %r7002, %r8123;

	
	dp4a.s32.s32 %r6948, %r6919, %r7006, %r6944;

	
	dp4a.s32.s32 %r6952, %r6922, %r7010, %r6948;

	
	dp4a.s32.s32 %r6956, %r6925, %r7014, %r6952;

	mad.lo.s32 %r8870, %r6956, %r8816, %r8869;
mul.ftz.f32 %f1278, %f1267, %f1273;
cvt.rn.f32.s32 %f1279, %r8870;
fma.rn.ftz.f32 %f1748, %f1278, %f1279, %f1748;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8081; 
mov.b32 b,%r8082; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6960,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8084; 
mov.b32 b,%r8085; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6963,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8087; 
mov.b32 b,%r8088; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6966,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8090; 
mov.b32 b,%r8091; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6969,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8093; 
mov.b32 b,%r8094; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6972,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8096; 
mov.b32 b,%r8097; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6975,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8099; 
mov.b32 b,%r8100; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6978,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8102; 
mov.b32 b,%r8103; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r6981,r; 
}

	
	dp4a.s32.s32 %r6984, %r6960, %r6986, %r8123;

	
	dp4a.s32.s32 %r6988, %r6963, %r6990, %r6984;

	
	dp4a.s32.s32 %r6992, %r6966, %r6994, %r6988;

	
	dp4a.s32.s32 %r6996, %r6969, %r6998, %r6992;

	mul.lo.s32 %r8871, %r6996, %r8858;

	dp4a.s32.s32 %r7000, %r6972, %r7002, %r8123;

	
	dp4a.s32.s32 %r7004, %r6975, %r7006, %r7000;

	
	dp4a.s32.s32 %r7008, %r6978, %r7010, %r7004;

	
	dp4a.s32.s32 %r7012, %r6981, %r7014, %r7008;

	mad.lo.s32 %r8872, %r7012, %r8860, %r8871;
mul.ftz.f32 %f1280, %f1270, %f1273;
cvt.rn.f32.s32 %f1281, %r8872;
fma.rn.ftz.f32 %f1716, %f1280, %f1281, %f1716;
add.s32 %r8873, %r8146, 3456;
shr.u32 %r8874, %r8873, 1;
add.s32 %r8875, %r9004, %r8874;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7913; 
mov.b32 b,%r7914; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7016,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7916; 
mov.b32 b,%r7917; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7019,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7919; 
mov.b32 b,%r7920; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7022,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7922; 
mov.b32 b,%r7923; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7025,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7925; 
mov.b32 b,%r7926; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7028,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7928; 
mov.b32 b,%r7929; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7031,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7931; 
mov.b32 b,%r7932; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7034,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7934; 
mov.b32 b,%r7935; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7037,r; 
}

	ld.shared.u32 %r7210, [%r8221+13824];

	dp4a.s32.s32 %r7040, %r7016, %r7210, %r8123;

	ld.shared.u32 %r7214, [%r8221+13828];

	dp4a.s32.s32 %r7044, %r7019, %r7214, %r7040;

	ld.shared.u32 %r7218, [%r8221+13832];

	dp4a.s32.s32 %r7048, %r7022, %r7218, %r7044;

	ld.shared.u32 %r7222, [%r8221+13836];

	dp4a.s32.s32 %r7052, %r7025, %r7222, %r7048;

	mul.lo.s32 %r8876, %r7052, %r8715;
ld.shared.u32 %r7226, [%r8221+13840];

	dp4a.s32.s32 %r7056, %r7028, %r7226, %r8123;

	ld.shared.u32 %r7230, [%r8221+13844];

	dp4a.s32.s32 %r7060, %r7031, %r7230, %r7056;

	ld.shared.u32 %r7234, [%r8221+13848];

	dp4a.s32.s32 %r7064, %r7034, %r7234, %r7060;

	ld.shared.u32 %r7238, [%r8221+13852];

	dp4a.s32.s32 %r7068, %r7037, %r7238, %r7064;

	mad.lo.s32 %r8877, %r7068, %r8717, %r8876;
ld.shared.f32 %f1282, [%r8875];
mul.ftz.f32 %f1283, %f1252, %f1282;
cvt.rn.f32.s32 %f1284, %r8877;
fma.rn.ftz.f32 %f1811, %f1283, %f1284, %f1811;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7969; 
mov.b32 b,%r7970; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7072,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7972; 
mov.b32 b,%r7973; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7075,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7975; 
mov.b32 b,%r7976; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7078,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7978; 
mov.b32 b,%r7979; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7081,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7981; 
mov.b32 b,%r7982; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7084,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7984; 
mov.b32 b,%r7985; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7087,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7987; 
mov.b32 b,%r7988; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7090,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7990; 
mov.b32 b,%r7991; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7093,r; 
}

	
	dp4a.s32.s32 %r7096, %r7072, %r7210, %r8123;

	
	dp4a.s32.s32 %r7100, %r7075, %r7214, %r7096;

	
	dp4a.s32.s32 %r7104, %r7078, %r7218, %r7100;

	
	dp4a.s32.s32 %r7108, %r7081, %r7222, %r7104;

	mul.lo.s32 %r8878, %r7108, %r8759;

	dp4a.s32.s32 %r7112, %r7084, %r7226, %r8123;

	
	dp4a.s32.s32 %r7116, %r7087, %r7230, %r7112;

	
	dp4a.s32.s32 %r7120, %r7090, %r7234, %r7116;

	
	dp4a.s32.s32 %r7124, %r7093, %r7238, %r7120;

	mad.lo.s32 %r8879, %r7124, %r8761, %r8878;
mul.ftz.f32 %f1285, %f1255, %f1282;
cvt.rn.f32.s32 %f1286, %r8879;
fma.rn.ftz.f32 %f1779, %f1285, %f1286, %f1779;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8025; 
mov.b32 b,%r8026; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7128,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8028; 
mov.b32 b,%r8029; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7131,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8031; 
mov.b32 b,%r8032; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7134,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8034; 
mov.b32 b,%r8035; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7137,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8037; 
mov.b32 b,%r8038; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7140,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8040; 
mov.b32 b,%r8041; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7143,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8043; 
mov.b32 b,%r8044; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7146,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8046; 
mov.b32 b,%r8047; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7149,r; 
}

	
	dp4a.s32.s32 %r7152, %r7128, %r7210, %r8123;

	
	dp4a.s32.s32 %r7156, %r7131, %r7214, %r7152;

	
	dp4a.s32.s32 %r7160, %r7134, %r7218, %r7156;

	
	dp4a.s32.s32 %r7164, %r7137, %r7222, %r7160;

	mul.lo.s32 %r8880, %r7164, %r8814;

	dp4a.s32.s32 %r7168, %r7140, %r7226, %r8123;

	
	dp4a.s32.s32 %r7172, %r7143, %r7230, %r7168;

	
	dp4a.s32.s32 %r7176, %r7146, %r7234, %r7172;

	
	dp4a.s32.s32 %r7180, %r7149, %r7238, %r7176;

	mad.lo.s32 %r8881, %r7180, %r8816, %r8880;
mul.ftz.f32 %f1287, %f1267, %f1282;
cvt.rn.f32.s32 %f1288, %r8881;
fma.rn.ftz.f32 %f1747, %f1287, %f1288, %f1747;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8081; 
mov.b32 b,%r8082; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7184,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8084; 
mov.b32 b,%r8085; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7187,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8087; 
mov.b32 b,%r8088; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7190,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8090; 
mov.b32 b,%r8091; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7193,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8093; 
mov.b32 b,%r8094; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7196,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8096; 
mov.b32 b,%r8097; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7199,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8099; 
mov.b32 b,%r8100; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7202,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8102; 
mov.b32 b,%r8103; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7205,r; 
}

	
	dp4a.s32.s32 %r7208, %r7184, %r7210, %r8123;

	
	dp4a.s32.s32 %r7212, %r7187, %r7214, %r7208;

	
	dp4a.s32.s32 %r7216, %r7190, %r7218, %r7212;

	
	dp4a.s32.s32 %r7220, %r7193, %r7222, %r7216;

	mul.lo.s32 %r8882, %r7220, %r8858;

	dp4a.s32.s32 %r7224, %r7196, %r7226, %r8123;

	
	dp4a.s32.s32 %r7228, %r7199, %r7230, %r7224;

	
	dp4a.s32.s32 %r7232, %r7202, %r7234, %r7228;

	
	dp4a.s32.s32 %r7236, %r7205, %r7238, %r7232;

	mad.lo.s32 %r8883, %r7236, %r8860, %r8882;
mul.ftz.f32 %f1289, %f1270, %f1282;
cvt.rn.f32.s32 %f1290, %r8883;
fma.rn.ftz.f32 %f1715, %f1289, %f1290, %f1715;
add.s32 %r8884, %r8146, 3584;
shr.u32 %r8885, %r8884, 1;
add.s32 %r8886, %r9004, %r8885;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7913; 
mov.b32 b,%r7914; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7240,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7916; 
mov.b32 b,%r7917; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7243,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7919; 
mov.b32 b,%r7920; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7246,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7922; 
mov.b32 b,%r7923; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7249,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7925; 
mov.b32 b,%r7926; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7252,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7928; 
mov.b32 b,%r7929; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7255,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7931; 
mov.b32 b,%r7932; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7258,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7934; 
mov.b32 b,%r7935; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7261,r; 
}

	ld.shared.u32 %r7434, [%r8221+14336];

	dp4a.s32.s32 %r7264, %r7240, %r7434, %r8123;

	ld.shared.u32 %r7438, [%r8221+14340];

	dp4a.s32.s32 %r7268, %r7243, %r7438, %r7264;

	ld.shared.u32 %r7442, [%r8221+14344];

	dp4a.s32.s32 %r7272, %r7246, %r7442, %r7268;

	ld.shared.u32 %r7446, [%r8221+14348];

	dp4a.s32.s32 %r7276, %r7249, %r7446, %r7272;

	mul.lo.s32 %r8887, %r7276, %r8715;
ld.shared.u32 %r7450, [%r8221+14352];

	dp4a.s32.s32 %r7280, %r7252, %r7450, %r8123;

	ld.shared.u32 %r7454, [%r8221+14356];

	dp4a.s32.s32 %r7284, %r7255, %r7454, %r7280;

	ld.shared.u32 %r7458, [%r8221+14360];

	dp4a.s32.s32 %r7288, %r7258, %r7458, %r7284;

	ld.shared.u32 %r7462, [%r8221+14364];

	dp4a.s32.s32 %r7292, %r7261, %r7462, %r7288;

	mad.lo.s32 %r8888, %r7292, %r8717, %r8887;
ld.shared.f32 %f1291, [%r8886];
mul.ftz.f32 %f1292, %f1252, %f1291;
cvt.rn.f32.s32 %f1293, %r8888;
fma.rn.ftz.f32 %f1810, %f1292, %f1293, %f1810;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7969; 
mov.b32 b,%r7970; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7296,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7972; 
mov.b32 b,%r7973; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7299,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7975; 
mov.b32 b,%r7976; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7302,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7978; 
mov.b32 b,%r7979; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7305,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7981; 
mov.b32 b,%r7982; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7308,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7984; 
mov.b32 b,%r7985; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7311,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7987; 
mov.b32 b,%r7988; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7314,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7990; 
mov.b32 b,%r7991; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7317,r; 
}

	
	dp4a.s32.s32 %r7320, %r7296, %r7434, %r8123;

	
	dp4a.s32.s32 %r7324, %r7299, %r7438, %r7320;

	
	dp4a.s32.s32 %r7328, %r7302, %r7442, %r7324;

	
	dp4a.s32.s32 %r7332, %r7305, %r7446, %r7328;

	mul.lo.s32 %r8889, %r7332, %r8759;

	dp4a.s32.s32 %r7336, %r7308, %r7450, %r8123;

	
	dp4a.s32.s32 %r7340, %r7311, %r7454, %r7336;

	
	dp4a.s32.s32 %r7344, %r7314, %r7458, %r7340;

	
	dp4a.s32.s32 %r7348, %r7317, %r7462, %r7344;

	mad.lo.s32 %r8890, %r7348, %r8761, %r8889;
mul.ftz.f32 %f1294, %f1255, %f1291;
cvt.rn.f32.s32 %f1295, %r8890;
fma.rn.ftz.f32 %f1778, %f1294, %f1295, %f1778;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8025; 
mov.b32 b,%r8026; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7352,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8028; 
mov.b32 b,%r8029; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7355,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8031; 
mov.b32 b,%r8032; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7358,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8034; 
mov.b32 b,%r8035; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7361,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8037; 
mov.b32 b,%r8038; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7364,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8040; 
mov.b32 b,%r8041; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7367,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8043; 
mov.b32 b,%r8044; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7370,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8046; 
mov.b32 b,%r8047; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7373,r; 
}

	
	dp4a.s32.s32 %r7376, %r7352, %r7434, %r8123;

	
	dp4a.s32.s32 %r7380, %r7355, %r7438, %r7376;

	
	dp4a.s32.s32 %r7384, %r7358, %r7442, %r7380;

	
	dp4a.s32.s32 %r7388, %r7361, %r7446, %r7384;

	mul.lo.s32 %r8891, %r7388, %r8814;

	dp4a.s32.s32 %r7392, %r7364, %r7450, %r8123;

	
	dp4a.s32.s32 %r7396, %r7367, %r7454, %r7392;

	
	dp4a.s32.s32 %r7400, %r7370, %r7458, %r7396;

	
	dp4a.s32.s32 %r7404, %r7373, %r7462, %r7400;

	mad.lo.s32 %r8892, %r7404, %r8816, %r8891;
mul.ftz.f32 %f1296, %f1267, %f1291;
cvt.rn.f32.s32 %f1297, %r8892;
fma.rn.ftz.f32 %f1746, %f1296, %f1297, %f1746;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8081; 
mov.b32 b,%r8082; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7408,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8084; 
mov.b32 b,%r8085; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7411,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8087; 
mov.b32 b,%r8088; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7414,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8090; 
mov.b32 b,%r8091; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7417,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8093; 
mov.b32 b,%r8094; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7420,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8096; 
mov.b32 b,%r8097; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7423,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8099; 
mov.b32 b,%r8100; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7426,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8102; 
mov.b32 b,%r8103; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7429,r; 
}

	
	dp4a.s32.s32 %r7432, %r7408, %r7434, %r8123;

	
	dp4a.s32.s32 %r7436, %r7411, %r7438, %r7432;

	
	dp4a.s32.s32 %r7440, %r7414, %r7442, %r7436;

	
	dp4a.s32.s32 %r7444, %r7417, %r7446, %r7440;

	mul.lo.s32 %r8893, %r7444, %r8858;

	dp4a.s32.s32 %r7448, %r7420, %r7450, %r8123;

	
	dp4a.s32.s32 %r7452, %r7423, %r7454, %r7448;

	
	dp4a.s32.s32 %r7456, %r7426, %r7458, %r7452;

	
	dp4a.s32.s32 %r7460, %r7429, %r7462, %r7456;

	mad.lo.s32 %r8894, %r7460, %r8860, %r8893;
mul.ftz.f32 %f1298, %f1270, %f1291;
cvt.rn.f32.s32 %f1299, %r8894;
fma.rn.ftz.f32 %f1714, %f1298, %f1299, %f1714;
add.s32 %r8895, %r8146, 3712;
shr.u32 %r8896, %r8895, 1;
add.s32 %r8897, %r9004, %r8896;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7913; 
mov.b32 b,%r7914; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7464,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7916; 
mov.b32 b,%r7917; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7467,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7919; 
mov.b32 b,%r7920; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7470,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7922; 
mov.b32 b,%r7923; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7473,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7925; 
mov.b32 b,%r7926; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7476,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7928; 
mov.b32 b,%r7929; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7479,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7931; 
mov.b32 b,%r7932; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7482,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7934; 
mov.b32 b,%r7935; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7485,r; 
}

	ld.shared.u32 %r7658, [%r8221+14848];

	dp4a.s32.s32 %r7488, %r7464, %r7658, %r8123;

	ld.shared.u32 %r7662, [%r8221+14852];

	dp4a.s32.s32 %r7492, %r7467, %r7662, %r7488;

	ld.shared.u32 %r7666, [%r8221+14856];

	dp4a.s32.s32 %r7496, %r7470, %r7666, %r7492;

	ld.shared.u32 %r7670, [%r8221+14860];

	dp4a.s32.s32 %r7500, %r7473, %r7670, %r7496;

	mul.lo.s32 %r8898, %r7500, %r8715;
ld.shared.u32 %r7674, [%r8221+14864];

	dp4a.s32.s32 %r7504, %r7476, %r7674, %r8123;

	ld.shared.u32 %r7678, [%r8221+14868];

	dp4a.s32.s32 %r7508, %r7479, %r7678, %r7504;

	ld.shared.u32 %r7682, [%r8221+14872];

	dp4a.s32.s32 %r7512, %r7482, %r7682, %r7508;

	ld.shared.u32 %r7686, [%r8221+14876];

	dp4a.s32.s32 %r7516, %r7485, %r7686, %r7512;

	mad.lo.s32 %r8899, %r7516, %r8717, %r8898;
ld.shared.f32 %f1300, [%r8897];
mul.ftz.f32 %f1301, %f1252, %f1300;
cvt.rn.f32.s32 %f1302, %r8899;
fma.rn.ftz.f32 %f1809, %f1301, %f1302, %f1809;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7969; 
mov.b32 b,%r7970; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7520,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7972; 
mov.b32 b,%r7973; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7523,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7975; 
mov.b32 b,%r7976; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7526,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7978; 
mov.b32 b,%r7979; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7529,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7981; 
mov.b32 b,%r7982; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7532,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7984; 
mov.b32 b,%r7985; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7535,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7987; 
mov.b32 b,%r7988; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7538,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7990; 
mov.b32 b,%r7991; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7541,r; 
}

	
	dp4a.s32.s32 %r7544, %r7520, %r7658, %r8123;

	
	dp4a.s32.s32 %r7548, %r7523, %r7662, %r7544;

	
	dp4a.s32.s32 %r7552, %r7526, %r7666, %r7548;

	
	dp4a.s32.s32 %r7556, %r7529, %r7670, %r7552;

	mul.lo.s32 %r8900, %r7556, %r8759;

	dp4a.s32.s32 %r7560, %r7532, %r7674, %r8123;

	
	dp4a.s32.s32 %r7564, %r7535, %r7678, %r7560;

	
	dp4a.s32.s32 %r7568, %r7538, %r7682, %r7564;

	
	dp4a.s32.s32 %r7572, %r7541, %r7686, %r7568;

	mad.lo.s32 %r8901, %r7572, %r8761, %r8900;
mul.ftz.f32 %f1303, %f1255, %f1300;
cvt.rn.f32.s32 %f1304, %r8901;
fma.rn.ftz.f32 %f1777, %f1303, %f1304, %f1777;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8025; 
mov.b32 b,%r8026; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7576,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8028; 
mov.b32 b,%r8029; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7579,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8031; 
mov.b32 b,%r8032; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7582,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8034; 
mov.b32 b,%r8035; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7585,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8037; 
mov.b32 b,%r8038; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7588,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8040; 
mov.b32 b,%r8041; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7591,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8043; 
mov.b32 b,%r8044; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7594,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8046; 
mov.b32 b,%r8047; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7597,r; 
}

	
	dp4a.s32.s32 %r7600, %r7576, %r7658, %r8123;

	
	dp4a.s32.s32 %r7604, %r7579, %r7662, %r7600;

	
	dp4a.s32.s32 %r7608, %r7582, %r7666, %r7604;

	
	dp4a.s32.s32 %r7612, %r7585, %r7670, %r7608;

	mul.lo.s32 %r8902, %r7612, %r8814;

	dp4a.s32.s32 %r7616, %r7588, %r7674, %r8123;

	
	dp4a.s32.s32 %r7620, %r7591, %r7678, %r7616;

	
	dp4a.s32.s32 %r7624, %r7594, %r7682, %r7620;

	
	dp4a.s32.s32 %r7628, %r7597, %r7686, %r7624;

	mad.lo.s32 %r8903, %r7628, %r8816, %r8902;
mul.ftz.f32 %f1305, %f1267, %f1300;
cvt.rn.f32.s32 %f1306, %r8903;
fma.rn.ftz.f32 %f1745, %f1305, %f1306, %f1745;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8081; 
mov.b32 b,%r8082; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7632,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8084; 
mov.b32 b,%r8085; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7635,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8087; 
mov.b32 b,%r8088; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7638,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8090; 
mov.b32 b,%r8091; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7641,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8093; 
mov.b32 b,%r8094; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7644,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8096; 
mov.b32 b,%r8097; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7647,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8099; 
mov.b32 b,%r8100; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7650,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8102; 
mov.b32 b,%r8103; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7653,r; 
}

	
	dp4a.s32.s32 %r7656, %r7632, %r7658, %r8123;

	
	dp4a.s32.s32 %r7660, %r7635, %r7662, %r7656;

	
	dp4a.s32.s32 %r7664, %r7638, %r7666, %r7660;

	
	dp4a.s32.s32 %r7668, %r7641, %r7670, %r7664;

	mul.lo.s32 %r8904, %r7668, %r8858;

	dp4a.s32.s32 %r7672, %r7644, %r7674, %r8123;

	
	dp4a.s32.s32 %r7676, %r7647, %r7678, %r7672;

	
	dp4a.s32.s32 %r7680, %r7650, %r7682, %r7676;

	
	dp4a.s32.s32 %r7684, %r7653, %r7686, %r7680;

	mad.lo.s32 %r8905, %r7684, %r8860, %r8904;
mul.ftz.f32 %f1307, %f1270, %f1300;
cvt.rn.f32.s32 %f1308, %r8905;
fma.rn.ftz.f32 %f1713, %f1307, %f1308, %f1713;
add.s32 %r8906, %r8146, 3840;
shr.u32 %r8907, %r8906, 1;
add.s32 %r8908, %r9004, %r8907;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7913; 
mov.b32 b,%r7914; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7688,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7916; 
mov.b32 b,%r7917; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7691,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7919; 
mov.b32 b,%r7920; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7694,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7922; 
mov.b32 b,%r7923; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7697,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7925; 
mov.b32 b,%r7926; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7700,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7928; 
mov.b32 b,%r7929; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7703,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7931; 
mov.b32 b,%r7932; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7706,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7934; 
mov.b32 b,%r7935; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7709,r; 
}

	ld.shared.u32 %r7882, [%r8221+15360];

	dp4a.s32.s32 %r7712, %r7688, %r7882, %r8123;

	ld.shared.u32 %r7886, [%r8221+15364];

	dp4a.s32.s32 %r7716, %r7691, %r7886, %r7712;

	ld.shared.u32 %r7890, [%r8221+15368];

	dp4a.s32.s32 %r7720, %r7694, %r7890, %r7716;

	ld.shared.u32 %r7894, [%r8221+15372];

	dp4a.s32.s32 %r7724, %r7697, %r7894, %r7720;

	mul.lo.s32 %r8909, %r7724, %r8715;
ld.shared.u32 %r7898, [%r8221+15376];

	dp4a.s32.s32 %r7728, %r7700, %r7898, %r8123;

	ld.shared.u32 %r7902, [%r8221+15380];

	dp4a.s32.s32 %r7732, %r7703, %r7902, %r7728;

	ld.shared.u32 %r7906, [%r8221+15384];

	dp4a.s32.s32 %r7736, %r7706, %r7906, %r7732;

	ld.shared.u32 %r7910, [%r8221+15388];

	dp4a.s32.s32 %r7740, %r7709, %r7910, %r7736;

	mad.lo.s32 %r8910, %r7740, %r8717, %r8909;
ld.shared.f32 %f1309, [%r8908];
mul.ftz.f32 %f1310, %f1252, %f1309;
cvt.rn.f32.s32 %f1311, %r8910;
fma.rn.ftz.f32 %f1808, %f1310, %f1311, %f1808;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7969; 
mov.b32 b,%r7970; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7744,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7972; 
mov.b32 b,%r7973; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7747,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7975; 
mov.b32 b,%r7976; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7750,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7978; 
mov.b32 b,%r7979; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7753,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7981; 
mov.b32 b,%r7982; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7756,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7984; 
mov.b32 b,%r7985; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7759,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7987; 
mov.b32 b,%r7988; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7762,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7990; 
mov.b32 b,%r7991; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7765,r; 
}

	
	dp4a.s32.s32 %r7768, %r7744, %r7882, %r8123;

	
	dp4a.s32.s32 %r7772, %r7747, %r7886, %r7768;

	
	dp4a.s32.s32 %r7776, %r7750, %r7890, %r7772;

	
	dp4a.s32.s32 %r7780, %r7753, %r7894, %r7776;

	mul.lo.s32 %r8911, %r7780, %r8759;

	dp4a.s32.s32 %r7784, %r7756, %r7898, %r8123;

	
	dp4a.s32.s32 %r7788, %r7759, %r7902, %r7784;

	
	dp4a.s32.s32 %r7792, %r7762, %r7906, %r7788;

	
	dp4a.s32.s32 %r7796, %r7765, %r7910, %r7792;

	mad.lo.s32 %r8912, %r7796, %r8761, %r8911;
mul.ftz.f32 %f1312, %f1255, %f1309;
cvt.rn.f32.s32 %f1313, %r8912;
fma.rn.ftz.f32 %f1776, %f1312, %f1313, %f1776;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8025; 
mov.b32 b,%r8026; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7800,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8028; 
mov.b32 b,%r8029; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7803,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8031; 
mov.b32 b,%r8032; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7806,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8034; 
mov.b32 b,%r8035; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7809,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8037; 
mov.b32 b,%r8038; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7812,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8040; 
mov.b32 b,%r8041; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7815,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8043; 
mov.b32 b,%r8044; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7818,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8046; 
mov.b32 b,%r8047; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7821,r; 
}

	
	dp4a.s32.s32 %r7824, %r7800, %r7882, %r8123;

	
	dp4a.s32.s32 %r7828, %r7803, %r7886, %r7824;

	
	dp4a.s32.s32 %r7832, %r7806, %r7890, %r7828;

	
	dp4a.s32.s32 %r7836, %r7809, %r7894, %r7832;

	mul.lo.s32 %r8913, %r7836, %r8814;

	dp4a.s32.s32 %r7840, %r7812, %r7898, %r8123;

	
	dp4a.s32.s32 %r7844, %r7815, %r7902, %r7840;

	
	dp4a.s32.s32 %r7848, %r7818, %r7906, %r7844;

	
	dp4a.s32.s32 %r7852, %r7821, %r7910, %r7848;

	mad.lo.s32 %r8914, %r7852, %r8816, %r8913;
mul.ftz.f32 %f1314, %f1267, %f1309;
cvt.rn.f32.s32 %f1315, %r8914;
fma.rn.ftz.f32 %f1744, %f1314, %f1315, %f1744;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8081; 
mov.b32 b,%r8082; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7856,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8084; 
mov.b32 b,%r8085; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7859,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8087; 
mov.b32 b,%r8088; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7862,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8090; 
mov.b32 b,%r8091; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7865,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8093; 
mov.b32 b,%r8094; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7868,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8096; 
mov.b32 b,%r8097; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7871,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8099; 
mov.b32 b,%r8100; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7874,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8102; 
mov.b32 b,%r8103; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7877,r; 
}

	
	dp4a.s32.s32 %r7880, %r7856, %r7882, %r8123;

	
	dp4a.s32.s32 %r7884, %r7859, %r7886, %r7880;

	
	dp4a.s32.s32 %r7888, %r7862, %r7890, %r7884;

	
	dp4a.s32.s32 %r7892, %r7865, %r7894, %r7888;

	mul.lo.s32 %r8915, %r7892, %r8858;

	dp4a.s32.s32 %r7896, %r7868, %r7898, %r8123;

	
	dp4a.s32.s32 %r7900, %r7871, %r7902, %r7896;

	
	dp4a.s32.s32 %r7904, %r7874, %r7906, %r7900;

	
	dp4a.s32.s32 %r7908, %r7877, %r7910, %r7904;

	mad.lo.s32 %r8916, %r7908, %r8860, %r8915;
mul.ftz.f32 %f1316, %f1270, %f1309;
cvt.rn.f32.s32 %f1317, %r8916;
fma.rn.ftz.f32 %f1712, %f1316, %f1317, %f1712;
add.s32 %r8917, %r8146, 3968;
shr.u32 %r8918, %r8917, 1;
add.s32 %r8919, %r9004, %r8918;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7913; 
mov.b32 b,%r7914; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7912,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7916; 
mov.b32 b,%r7917; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7915,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7919; 
mov.b32 b,%r7920; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7918,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7922; 
mov.b32 b,%r7923; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7921,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7925; 
mov.b32 b,%r7926; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7924,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7928; 
mov.b32 b,%r7929; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7927,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7931; 
mov.b32 b,%r7932; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7930,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7934; 
mov.b32 b,%r7935; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7933,r; 
}

	ld.shared.u32 %r8106, [%r8221+15872];

	dp4a.s32.s32 %r7936, %r7912, %r8106, %r8123;

	ld.shared.u32 %r8110, [%r8221+15876];

	dp4a.s32.s32 %r7940, %r7915, %r8110, %r7936;

	ld.shared.u32 %r8114, [%r8221+15880];

	dp4a.s32.s32 %r7944, %r7918, %r8114, %r7940;

	ld.shared.u32 %r8118, [%r8221+15884];

	dp4a.s32.s32 %r7948, %r7921, %r8118, %r7944;

	mul.lo.s32 %r8920, %r7948, %r8715;
ld.shared.u32 %r8122, [%r8221+15888];

	dp4a.s32.s32 %r7952, %r7924, %r8122, %r8123;

	ld.shared.u32 %r8126, [%r8221+15892];

	dp4a.s32.s32 %r7956, %r7927, %r8126, %r7952;

	ld.shared.u32 %r8130, [%r8221+15896];

	dp4a.s32.s32 %r7960, %r7930, %r8130, %r7956;

	ld.shared.u32 %r8134, [%r8221+15900];

	dp4a.s32.s32 %r7964, %r7933, %r8134, %r7960;

	mad.lo.s32 %r8921, %r7964, %r8717, %r8920;
ld.shared.f32 %f1318, [%r8919];
mul.ftz.f32 %f1319, %f1252, %f1318;
cvt.rn.f32.s32 %f1320, %r8921;
fma.rn.ftz.f32 %f1807, %f1319, %f1320, %f1807;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7969; 
mov.b32 b,%r7970; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7968,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7972; 
mov.b32 b,%r7973; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7971,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7975; 
mov.b32 b,%r7976; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7974,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7978; 
mov.b32 b,%r7979; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7977,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7981; 
mov.b32 b,%r7982; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7980,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7984; 
mov.b32 b,%r7985; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7983,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7987; 
mov.b32 b,%r7988; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7986,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r7990; 
mov.b32 b,%r7991; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r7989,r; 
}

	
	dp4a.s32.s32 %r7992, %r7968, %r8106, %r8123;

	
	dp4a.s32.s32 %r7996, %r7971, %r8110, %r7992;

	
	dp4a.s32.s32 %r8000, %r7974, %r8114, %r7996;

	
	dp4a.s32.s32 %r8004, %r7977, %r8118, %r8000;

	mul.lo.s32 %r8922, %r8004, %r8759;

	dp4a.s32.s32 %r8008, %r7980, %r8122, %r8123;

	
	dp4a.s32.s32 %r8012, %r7983, %r8126, %r8008;

	
	dp4a.s32.s32 %r8016, %r7986, %r8130, %r8012;

	
	dp4a.s32.s32 %r8020, %r7989, %r8134, %r8016;

	mad.lo.s32 %r8923, %r8020, %r8761, %r8922;
mul.ftz.f32 %f1321, %f1255, %f1318;
cvt.rn.f32.s32 %f1322, %r8923;
fma.rn.ftz.f32 %f1775, %f1321, %f1322, %f1775;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8025; 
mov.b32 b,%r8026; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8024,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8028; 
mov.b32 b,%r8029; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8027,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8031; 
mov.b32 b,%r8032; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8030,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8034; 
mov.b32 b,%r8035; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8033,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8037; 
mov.b32 b,%r8038; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8036,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8040; 
mov.b32 b,%r8041; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8039,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8043; 
mov.b32 b,%r8044; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8042,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8046; 
mov.b32 b,%r8047; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8045,r; 
}

	
	dp4a.s32.s32 %r8048, %r8024, %r8106, %r8123;

	
	dp4a.s32.s32 %r8052, %r8027, %r8110, %r8048;

	
	dp4a.s32.s32 %r8056, %r8030, %r8114, %r8052;

	
	dp4a.s32.s32 %r8060, %r8033, %r8118, %r8056;

	mul.lo.s32 %r8924, %r8060, %r8814;

	dp4a.s32.s32 %r8064, %r8036, %r8122, %r8123;

	
	dp4a.s32.s32 %r8068, %r8039, %r8126, %r8064;

	
	dp4a.s32.s32 %r8072, %r8042, %r8130, %r8068;

	
	dp4a.s32.s32 %r8076, %r8045, %r8134, %r8072;

	mad.lo.s32 %r8925, %r8076, %r8816, %r8924;
mul.ftz.f32 %f1323, %f1267, %f1318;
cvt.rn.f32.s32 %f1324, %r8925;
fma.rn.ftz.f32 %f1743, %f1323, %f1324, %f1743;

	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8081; 
mov.b32 b,%r8082; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8080,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8084; 
mov.b32 b,%r8085; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8083,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8087; 
mov.b32 b,%r8088; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8086,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8090; 
mov.b32 b,%r8091; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8089,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8093; 
mov.b32 b,%r8094; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8092,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8096; 
mov.b32 b,%r8097; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8095,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8099; 
mov.b32 b,%r8100; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8098,r; 
}

	
	{ 
.reg .u32 a,b,r,s,t,u,v,w; 
mov.b32 a,%r8102; 
mov.b32 b,%r8103; 
not.b32 u,b; 
xor.b32 s,u,a; 
or.b32 r,a,0x80808080;
and.b32 t,b,0x7f7f7f7f;
sub.u32 r,r,t; 
xor.b32 t,r,a; 
not.b32 u,s; 
and.b32 s,s,0x80808080;
xor.b32 r,r,s; 
and.b32 t,t,u; 
prmt.b32 s,a,0,0xba98; 
xor.b32 s,s,0x7f7f7f7f;
prmt.b32 t,t,0,0xba98; 
and.b32 s,s,t; 
not.b32 t,t; 
and.b32 r,r,t; 
or.b32 r,r,s; 
mov.b32 %r8101,r; 
}

	
	dp4a.s32.s32 %r8104, %r8080, %r8106, %r8123;

	
	dp4a.s32.s32 %r8108, %r8083, %r8110, %r8104;

	
	dp4a.s32.s32 %r8112, %r8086, %r8114, %r8108;

	
	dp4a.s32.s32 %r8116, %r8089, %r8118, %r8112;

	mul.lo.s32 %r8926, %r8116, %r8858;

	dp4a.s32.s32 %r8120, %r8092, %r8122, %r8123;

	
	dp4a.s32.s32 %r8124, %r8095, %r8126, %r8120;

	
	dp4a.s32.s32 %r8128, %r8098, %r8130, %r8124;

	
	dp4a.s32.s32 %r8132, %r8101, %r8134, %r8128;

	mad.lo.s32 %r8927, %r8132, %r8860, %r8926;
mul.ftz.f32 %f1325, %f1270, %f1318;
cvt.rn.f32.s32 %f1326, %r8927;
fma.rn.ftz.f32 %f1711, %f1325, %f1326, %f1711;
add.s32 %r9016, %r9016, 2;
setp.lt.s32 %p3, %r9016, %r9009;
@%p3 bra $L__BB54_5;

$L__BB54_6:
bar.sync 0;
add.s32 %r9015, %r9015, 1;
setp.lt.u32 %p4, %r9015, 4;
@%p4 bra $L__BB54_4;

add.s32 %r9014, %r9014, 2;
setp.lt.s32 %p5, %r9014, %r1;
@%p5 bra $L__BB54_3;
bra.uni $L__BB54_8;

$L__BB54_1:
mov.f32 %f1711, 0f00000000;
mov.f32 %f1712, %f1711;
mov.f32 %f1713, %f1711;
mov.f32 %f1714, %f1711;
mov.f32 %f1715, %f1711;
mov.f32 %f1716, %f1711;
mov.f32 %f1717, %f1711;
mov.f32 %f1718, %f1711;
mov.f32 %f1719, %f1711;
mov.f32 %f1720, %f1711;
mov.f32 %f1721, %f1711;
mov.f32 %f1722, %f1711;
mov.f32 %f1723, %f1711;
mov.f32 %f1724, %f1711;
mov.f32 %f1725, %f1711;
mov.f32 %f1726, %f1711;
mov.f32 %f1727, %f1711;
mov.f32 %f1728, %f1711;
mov.f32 %f1729, %f1711;
mov.f32 %f1730, %f1711;
mov.f32 %f1731, %f1711;
mov.f32 %f1732, %f1711;
mov.f32 %f1733, %f1711;
mov.f32 %f1734, %f1711;
mov.f32 %f1735, %f1711;
mov.f32 %f1736, %f1711;
mov.f32 %f1737, %f1711;
mov.f32 %f1738, %f1711;
mov.f32 %f1739, %f1711;
mov.f32 %f1740, %f1711;
mov.f32 %f1741, %f1711;
mov.f32 %f1742, %f1711;
mov.f32 %f1743, %f1711;
mov.f32 %f1744, %f1711;
mov.f32 %f1745, %f1711;
mov.f32 %f1746, %f1711;
mov.f32 %f1747, %f1711;
mov.f32 %f1748, %f1711;
mov.f32 %f1749, %f1711;
mov.f32 %f1750, %f1711;
mov.f32 %f1751, %f1711;
mov.f32 %f1752, %f1711;
mov.f32 %f1753, %f1711;
mov.f32 %f1754, %f1711;
mov.f32 %f1755, %f1711;
mov.f32 %f1756, %f1711;
mov.f32 %f1757, %f1711;
mov.f32 %f1758, %f1711;
mov.f32 %f1759, %f1711;
mov.f32 %f1760, %f1711;
mov.f32 %f1761, %f1711;
mov.f32 %f1762, %f1711;
mov.f32 %f1763, %f1711;
mov.f32 %f1764, %f1711;
mov.f32 %f1765, %f1711;
mov.f32 %f1766, %f1711;
mov.f32 %f1767, %f1711;
mov.f32 %f1768, %f1711;
mov.f32 %f1769, %f1711;
mov.f32 %f1770, %f1711;
mov.f32 %f1771, %f1711;
mov.f32 %f1772, %f1711;
mov.f32 %f1773, %f1711;
mov.f32 %f1774, %f1711;
mov.f32 %f1775, %f1711;
mov.f32 %f1776, %f1711;
mov.f32 %f1777, %f1711;
mov.f32 %f1778, %f1711;
mov.f32 %f1779, %f1711;
mov.f32 %f1780, %f1711;
mov.f32 %f1781, %f1711;
mov.f32 %f1782, %f1711;
mov.f32 %f1783, %f1711;
mov.f32 %f1784, %f1711;
mov.f32 %f1785, %f1711;
mov.f32 %f1786, %f1711;
mov.f32 %f1787, %f1711;
mov.f32 %f1788, %f1711;
mov.f32 %f1789, %f1711;
mov.f32 %f1790, %f1711;
mov.f32 %f1791, %f1711;
mov.f32 %f1792, %f1711;
mov.f32 %f1793, %f1711;
mov.f32 %f1794, %f1711;
mov.f32 %f1795, %f1711;
mov.f32 %f1796, %f1711;
mov.f32 %f1797, %f1711;
mov.f32 %f1798, %f1711;
mov.f32 %f1799, %f1711;
mov.f32 %f1800, %f1711;
mov.f32 %f1801, %f1711;
mov.f32 %f1802, %f1711;
mov.f32 %f1803, %f1711;
mov.f32 %f1804, %f1711;
mov.f32 %f1805, %f1711;
mov.f32 %f1806, %f1711;
mov.f32 %f1807, %f1711;
mov.f32 %f1808, %f1711;
mov.f32 %f1809, %f1711;
mov.f32 %f1810, %f1711;
mov.f32 %f1811, %f1711;
mov.f32 %f1812, %f1711;
mov.f32 %f1813, %f1711;
mov.f32 %f1814, %f1711;
mov.f32 %f1815, %f1711;
mov.f32 %f1816, %f1711;
mov.f32 %f1817, %f1711;
mov.f32 %f1818, %f1711;
mov.f32 %f1819, %f1711;
mov.f32 %f1820, %f1711;
mov.f32 %f1821, %f1711;
mov.f32 %f1822, %f1711;
mov.f32 %f1823, %f1711;
mov.f32 %f1824, %f1711;
mov.f32 %f1825, %f1711;
mov.f32 %f1826, %f1711;
mov.f32 %f1827, %f1711;
mov.f32 %f1828, %f1711;
mov.f32 %f1829, %f1711;
mov.f32 %f1830, %f1711;
mov.f32 %f1831, %f1711;
mov.f32 %f1832, %f1711;
mov.f32 %f1833, %f1711;
mov.f32 %f1834, %f1711;
mov.f32 %f1835, %f1711;
mov.f32 %f1836, %f1711;
mov.f32 %f1837, %f1711;
mov.f32 %f1838, %f1711;

$L__BB54_8:
mov.u32 %r8928, %ctaid.y;
shl.b32 %r8929, %r8928, 7;
mov.u32 %r8930, %tid.y;
add.s32 %r37, %r8929, %r8930;
mov.u32 %r8931, %ctaid.x;
shl.b32 %r8932, %r8931, 7;
mov.u32 %r8933, %tid.x;
add.s32 %r38, %r8932, %r8933;
setp.ge.s32 %p6, %r37, %r75;
@%p6 bra $L__BB54_296;

ld.param.u64 %rd507, [_Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_2];
ld.param.u32 %r8998, [_Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_7];
mul.lo.s32 %r39, %r37, %r8998;
add.s32 %r8934, %r38, %r39;
cvta.to.global.u64 %rd443, %rd507;
mul.wide.s32 %rd444, %r8934, 4;
add.s64 %rd1, %rd443, %rd444;
setp.ge.s32 %p7, %r38, %r8998;
@%p7 bra $L__BB54_11;

st.global.f32 [%rd1], %f1838;

$L__BB54_11:
ld.param.u32 %r8999, [_Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_7];
add.s32 %r40, %r38, 32;
setp.ge.s32 %p8, %r40, %r8999;
@%p8 bra $L__BB54_13;

st.global.f32 [%rd1+128], %f1806;

$L__BB54_13:
ld.param.u32 %r9000, [_Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_7];
add.s32 %r41, %r38, 64;
setp.ge.s32 %p9, %r41, %r9000;
@%p9 bra $L__BB54_15;

st.global.f32 [%rd1+256], %f1774;

$L__BB54_15:
ld.param.u32 %r9001, [_Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_7];
add.s32 %r42, %r38, 96;
setp.ge.s32 %p10, %r42, %r9001;
@%p10 bra $L__BB54_17;

st.global.f32 [%rd1+384], %f1742;

$L__BB54_17:
add.s32 %r8935, %r37, 4;
setp.ge.s32 %p11, %r8935, %r75;
@%p11 bra $L__BB54_296;

ld.param.u32 %r9002, [_Z12mul_mat_q3_KILb1EEvPKvS1_Pfiiiii_param_7];
shl.b32 %r43, %r9002, 2;
add.s32 %r44, %r39, %r43;
add.s32 %r8936, %r38, %r44;
mul.wide.s32 %rd446, %r8936, 4;
add.s64 %rd2, %rd443, %rd446;
@%p7 bra $L__BB54_20;

st.global.f32 [%rd2], %f1837;

$L__BB54_20:
@%p8 bra $L__BB54_22;

st.global.f32 [%rd2+128], %f1805;

$L__BB54_22:
@%p9 bra $L__BB54_24;

st.global.f32 [%rd2+256], %f1773;

$L__BB54_24:
@%p10 bra $L__BB54_26;

st.global.f32 [%rd2+384], %f1741;

$L__BB54_26:
add.s32 %r8937, %r37, 8;
setp.ge.s32 %p16, %r8937, %r75;
@%p16 bra $L__BB54_296;

add.s32 %r45, %r44, %r43;
add.s32 %r8938, %r38, %r45;
mul.wide.s32 %rd448, %r8938, 4;
add.s64 %rd3, %rd443, %rd448;
@%p7 bra $L__BB54_29;

st.global.f32 [%rd3], %f1836;

$L__BB54_29:
@%p8 bra $L__BB54_31;

st.global.f32 [%rd3+128], %f1804;

$L__BB54_31:
@%p9 bra $L__BB54_33;

st.global.f32 [%rd3+256], %f1772;

$L__BB54_33:
@%p10 bra $L__BB54_35;

st.global.f32 [%rd3+384], %f1740;

$L__BB54_35:
add.s32 %r8939, %r37, 12;
setp.ge.s32 %p21, %r8939, %r75;
@%p21 bra $L__BB54_296;

add.s32 %r46, %r45, %r43;
add.s32 %r8940, %r38, %r46;
mul.wide.s32 %rd450, %r8940, 4;
add.s64 %rd4, %rd443, %rd450;
@%p7 bra $L__BB54_38;

st.global.f32 [%rd4], %f1835;

$L__BB54_38:
@%p8 bra $L__BB54_40;

st.global.f32 [%rd4+128], %f1803;

$L__BB54_40:
@%p9 bra $L__BB54_42;

st.global.f32 [%rd4+256], %f1771;

$L__BB54_42:
@%p10 bra $L__BB54_44;

st.global.f32 [%rd4+384], %f1739;

$L__BB54_44:
add.s32 %r8941, %r37, 16;
setp.ge.s32 %p26, %r8941, %r75;
@%p26 bra $L__BB54_296;

add.s32 %r47, %r46, %r43;
add.s32 %r8942, %r38, %r47;
mul.wide.s32 %rd452, %r8942, 4;
add.s64 %rd5, %rd443, %rd452;
@%p7 bra $L__BB54_47;

st.global.f32 [%rd5], %f1834;

$L__BB54_47:
@%p8 bra $L__BB54_49;

st.global.f32 [%rd5+128], %f1802;

$L__BB54_49:
@%p9 bra $L__BB54_51;

st.global.f32 [%rd5+256], %f1770;

$L__BB54_51:
@%p10 bra $L__BB54_53;

st.global.f32 [%rd5+384], %f1738;

$L__BB54_53:
add.s32 %r8943, %r37, 20;
setp.ge.s32 %p31, %r8943, %r75;
@%p31 bra $L__BB54_296;

add.s32 %r48, %r47, %r43;
add.s32 %r8944, %r38, %r48;
mul.wide.s32 %rd454, %r8944, 4;
add.s64 %rd6, %rd443, %rd454;
@%p7 bra $L__BB54_56;

st.global.f32 [%rd6], %f1833;

$L__BB54_56:
@%p8 bra $L__BB54_58;

st.global.f32 [%rd6+128], %f1801;

$L__BB54_58:
@%p9 bra $L__BB54_60;

st.global.f32 [%rd6+256], %f1769;

$L__BB54_60:
@%p10 bra $L__BB54_62;

st.global.f32 [%rd6+384], %f1737;

$L__BB54_62:
add.s32 %r8945, %r37, 24;
setp.ge.s32 %p36, %r8945, %r75;
@%p36 bra $L__BB54_296;

add.s32 %r49, %r48, %r43;
add.s32 %r8946, %r38, %r49;
mul.wide.s32 %rd456, %r8946, 4;
add.s64 %rd7, %rd443, %rd456;
@%p7 bra $L__BB54_65;

st.global.f32 [%rd7], %f1832;

$L__BB54_65:
@%p8 bra $L__BB54_67;

st.global.f32 [%rd7+128], %f1800;

$L__BB54_67:
@%p9 bra $L__BB54_69;

st.global.f32 [%rd7+256], %f1768;

$L__BB54_69:
@%p10 bra $L__BB54_71;

st.global.f32 [%rd7+384], %f1736;

$L__BB54_71:
add.s32 %r8947, %r37, 28;
setp.ge.s32 %p41, %r8947, %r75;
@%p41 bra $L__BB54_296;

add.s32 %r50, %r49, %r43;
add.s32 %r8948, %r38, %r50;
mul.wide.s32 %rd458, %r8948, 4;
add.s64 %rd8, %rd443, %rd458;
@%p7 bra $L__BB54_74;

st.global.f32 [%rd8], %f1831;

$L__BB54_74:
@%p8 bra $L__BB54_76;

st.global.f32 [%rd8+128], %f1799;

$L__BB54_76:
@%p9 bra $L__BB54_78;

st.global.f32 [%rd8+256], %f1767;

$L__BB54_78:
@%p10 bra $L__BB54_80;

st.global.f32 [%rd8+384], %f1735;

$L__BB54_80:
add.s32 %r8949, %r37, 32;
setp.ge.s32 %p46, %r8949, %r75;
@%p46 bra $L__BB54_296;

add.s32 %r51, %r50, %r43;
add.s32 %r8950, %r38, %r51;
mul.wide.s32 %rd460, %r8950, 4;
add.s64 %rd9, %rd443, %rd460;
@%p7 bra $L__BB54_83;

st.global.f32 [%rd9], %f1830;

$L__BB54_83:
@%p8 bra $L__BB54_85;

st.global.f32 [%rd9+128], %f1798;

$L__BB54_85:
@%p9 bra $L__BB54_87;

st.global.f32 [%rd9+256], %f1766;

$L__BB54_87:
@%p10 bra $L__BB54_89;

st.global.f32 [%rd9+384], %f1734;

$L__BB54_89:
add.s32 %r8951, %r37, 36;
setp.ge.s32 %p51, %r8951, %r75;
@%p51 bra $L__BB54_296;

add.s32 %r52, %r51, %r43;
add.s32 %r8952, %r38, %r52;
mul.wide.s32 %rd462, %r8952, 4;
add.s64 %rd10, %rd443, %rd462;
@%p7 bra $L__BB54_92;

st.global.f32 [%rd10], %f1829;

$L__BB54_92:
@%p8 bra $L__BB54_94;

st.global.f32 [%rd10+128], %f1797;

$L__BB54_94:
@%p9 bra $L__BB54_96;

st.global.f32 [%rd10+256], %f1765;

$L__BB54_96:
@%p10 bra $L__BB54_98;

st.global.f32 [%rd10+384], %f1733;

$L__BB54_98:
add.s32 %r8953, %r37, 40;
setp.ge.s32 %p56, %r8953, %r75;
@%p56 bra $L__BB54_296;

add.s32 %r53, %r52, %r43;
add.s32 %r8954, %r38, %r53;
mul.wide.s32 %rd464, %r8954, 4;
add.s64 %rd11, %rd443, %rd464;
@%p7 bra $L__BB54_101;

st.global.f32 [%rd11], %f1828;

$L__BB54_101:
@%p8 bra $L__BB54_103;

st.global.f32 [%rd11+128], %f1796;

$L__BB54_103:
@%p9 bra $L__BB54_105;

st.global.f32 [%rd11+256], %f1764;

$L__BB54_105:
@%p10 bra $L__BB54_107;

st.global.f32 [%rd11+384], %f1732;

$L__BB54_107:
add.s32 %r8955, %r37, 44;
setp.ge.s32 %p61, %r8955, %r75;
@%p61 bra $L__BB54_296;

add.s32 %r54, %r53, %r43;
add.s32 %r8956, %r38, %r54;
mul.wide.s32 %rd466, %r8956, 4;
add.s64 %rd12, %rd443, %rd466;
@%p7 bra $L__BB54_110;

st.global.f32 [%rd12], %f1827;

$L__BB54_110:
@%p8 bra $L__BB54_112;

st.global.f32 [%rd12+128], %f1795;

$L__BB54_112:
@%p9 bra $L__BB54_114;

st.global.f32 [%rd12+256], %f1763;

$L__BB54_114:
@%p10 bra $L__BB54_116;

st.global.f32 [%rd12+384], %f1731;

$L__BB54_116:
add.s32 %r8957, %r37, 48;
setp.ge.s32 %p66, %r8957, %r75;
@%p66 bra $L__BB54_296;

add.s32 %r55, %r54, %r43;
add.s32 %r8958, %r38, %r55;
mul.wide.s32 %rd468, %r8958, 4;
add.s64 %rd13, %rd443, %rd468;
@%p7 bra $L__BB54_119;

st.global.f32 [%rd13], %f1826;

$L__BB54_119:
@%p8 bra $L__BB54_121;

st.global.f32 [%rd13+128], %f1794;

$L__BB54_121:
@%p9 bra $L__BB54_123;

st.global.f32 [%rd13+256], %f1762;

$L__BB54_123:
@%p10 bra $L__BB54_125;

st.global.f32 [%rd13+384], %f1730;

$L__BB54_125:
add.s32 %r8959, %r37, 52;
setp.ge.s32 %p71, %r8959, %r75;
@%p71 bra $L__BB54_296;

add.s32 %r56, %r55, %r43;
add.s32 %r8960, %r38, %r56;
mul.wide.s32 %rd470, %r8960, 4;
add.s64 %rd14, %rd443, %rd470;
@%p7 bra $L__BB54_128;

st.global.f32 [%rd14], %f1825;

$L__BB54_128:
@%p8 bra $L__BB54_130;

st.global.f32 [%rd14+128], %f1793;

$L__BB54_130:
@%p9 bra $L__BB54_132;

st.global.f32 [%rd14+256], %f1761;

$L__BB54_132:
@%p10 bra $L__BB54_134;

st.global.f32 [%rd14+384], %f1729;

$L__BB54_134:
add.s32 %r8961, %r37, 56;
setp.ge.s32 %p76, %r8961, %r75;
@%p76 bra $L__BB54_296;

add.s32 %r57, %r56, %r43;
add.s32 %r8962, %r38, %r57;
mul.wide.s32 %rd472, %r8962, 4;
add.s64 %rd15, %rd443, %rd472;
@%p7 bra $L__BB54_137;

st.global.f32 [%rd15], %f1824;

$L__BB54_137:
@%p8 bra $L__BB54_139;

st.global.f32 [%rd15+128], %f1792;

$L__BB54_139:
@%p9 bra $L__BB54_141;

st.global.f32 [%rd15+256], %f1760;

$L__BB54_141:
@%p10 bra $L__BB54_143;

st.global.f32 [%rd15+384], %f1728;

$L__BB54_143:
add.s32 %r8963, %r37, 60;
setp.ge.s32 %p81, %r8963, %r75;
@%p81 bra $L__BB54_296;

add.s32 %r58, %r57, %r43;
add.s32 %r8964, %r38, %r58;
mul.wide.s32 %rd474, %r8964, 4;
add.s64 %rd16, %rd443, %rd474;
@%p7 bra $L__BB54_146;

st.global.f32 [%rd16], %f1823;

$L__BB54_146:
@%p8 bra $L__BB54_148;

st.global.f32 [%rd16+128], %f1791;

$L__BB54_148:
@%p9 bra $L__BB54_150;

st.global.f32 [%rd16+256], %f1759;

$L__BB54_150:
@%p10 bra $L__BB54_152;

st.global.f32 [%rd16+384], %f1727;

$L__BB54_152:
add.s32 %r8965, %r37, 64;
setp.ge.s32 %p86, %r8965, %r75;
@%p86 bra $L__BB54_296;

add.s32 %r59, %r58, %r43;
add.s32 %r8966, %r38, %r59;
mul.wide.s32 %rd476, %r8966, 4;
add.s64 %rd17, %rd443, %rd476;
@%p7 bra $L__BB54_155;

st.global.f32 [%rd17], %f1822;

$L__BB54_155:
@%p8 bra $L__BB54_157;

st.global.f32 [%rd17+128], %f1790;

$L__BB54_157:
@%p9 bra $L__BB54_159;

st.global.f32 [%rd17+256], %f1758;

$L__BB54_159:
@%p10 bra $L__BB54_161;

st.global.f32 [%rd17+384], %f1726;

$L__BB54_161:
add.s32 %r8967, %r37, 68;
setp.ge.s32 %p91, %r8967, %r75;
@%p91 bra $L__BB54_296;

add.s32 %r60, %r59, %r43;
add.s32 %r8968, %r38, %r60;
mul.wide.s32 %rd478, %r8968, 4;
add.s64 %rd18, %rd443, %rd478;
@%p7 bra $L__BB54_164;

st.global.f32 [%rd18], %f1821;

$L__BB54_164:
@%p8 bra $L__BB54_166;

st.global.f32 [%rd18+128], %f1789;

$L__BB54_166:
@%p9 bra $L__BB54_168;

st.global.f32 [%rd18+256], %f1757;

$L__BB54_168:
@%p10 bra $L__BB54_170;

st.global.f32 [%rd18+384], %f1725;

$L__BB54_170:
add.s32 %r8969, %r37, 72;
setp.ge.s32 %p96, %r8969, %r75;
@%p96 bra $L__BB54_296;

add.s32 %r61, %r60, %r43;
add.s32 %r8970, %r38, %r61;
mul.wide.s32 %rd480, %r8970, 4;
add.s64 %rd19, %rd443, %rd480;
@%p7 bra $L__BB54_173;

st.global.f32 [%rd19], %f1820;

$L__BB54_173:
@%p8 bra $L__BB54_175;

st.global.f32 [%rd19+128], %f1788;

$L__BB54_175:
@%p9 bra $L__BB54_177;

st.global.f32 [%rd19+256], %f1756;

$L__BB54_177:
@%p10 bra $L__BB54_179;

st.global.f32 [%rd19+384], %f1724;

$L__BB54_179:
add.s32 %r8971, %r37, 76;
setp.ge.s32 %p101, %r8971, %r75;
@%p101 bra $L__BB54_296;

add.s32 %r62, %r61, %r43;
add.s32 %r8972, %r38, %r62;
mul.wide.s32 %rd482, %r8972, 4;
add.s64 %rd20, %rd443, %rd482;
@%p7 bra $L__BB54_182;

st.global.f32 [%rd20], %f1819;

$L__BB54_182:
@%p8 bra $L__BB54_184;

st.global.f32 [%rd20+128], %f1787;

$L__BB54_184:
@%p9 bra $L__BB54_186;

st.global.f32 [%rd20+256], %f1755;

$L__BB54_186:
@%p10 bra $L__BB54_188;

st.global.f32 [%rd20+384], %f1723;

$L__BB54_188:
add.s32 %r8973, %r37, 80;
setp.ge.s32 %p106, %r8973, %r75;
@%p106 bra $L__BB54_296;

add.s32 %r63, %r62, %r43;
add.s32 %r8974, %r38, %r63;
mul.wide.s32 %rd484, %r8974, 4;
add.s64 %rd21, %rd443, %rd484;
@%p7 bra $L__BB54_191;

st.global.f32 [%rd21], %f1818;

$L__BB54_191:
@%p8 bra $L__BB54_193;

st.global.f32 [%rd21+128], %f1786;

$L__BB54_193:
@%p9 bra $L__BB54_195;

st.global.f32 [%rd21+256], %f1754;

$L__BB54_195:
@%p10 bra $L__BB54_197;

st.global.f32 [%rd21+384], %f1722;

$L__BB54_197:
add.s32 %r8975, %r37, 84;
setp.ge.s32 %p111, %r8975, %r75;
@%p111 bra $L__BB54_296;

add.s32 %r64, %r63, %r43;
add.s32 %r8976, %r38, %r64;
mul.wide.s32 %rd486, %r8976, 4;
add.s64 %rd22, %rd443, %rd486;
@%p7 bra $L__BB54_200;

st.global.f32 [%rd22], %f1817;

$L__BB54_200:
@%p8 bra $L__BB54_202;

st.global.f32 [%rd22+128], %f1785;

$L__BB54_202:
@%p9 bra $L__BB54_204;

st.global.f32 [%rd22+256], %f1753;

$L__BB54_204:
@%p10 bra $L__BB54_206;

st.global.f32 [%rd22+384], %f1721;

$L__BB54_206:
add.s32 %r8977, %r37, 88;
setp.ge.s32 %p116, %r8977, %r75;
@%p116 bra $L__BB54_296;

add.s32 %r65, %r64, %r43;
add.s32 %r8978, %r38, %r65;
mul.wide.s32 %rd488, %r8978, 4;
add.s64 %rd23, %rd443, %rd488;
@%p7 bra $L__BB54_209;

st.global.f32 [%rd23], %f1816;

$L__BB54_209:
@%p8 bra $L__BB54_211;

st.global.f32 [%rd23+128], %f1784;

$L__BB54_211:
@%p9 bra $L__BB54_213;

st.global.f32 [%rd23+256], %f1752;

$L__BB54_213:
@%p10 bra $L__BB54_215;

st.global.f32 [%rd23+384], %f1720;

$L__BB54_215:
add.s32 %r8979, %r37, 92;
setp.ge.s32 %p121, %r8979, %r75;
@%p121 bra $L__BB54_296;

add.s32 %r66, %r65, %r43;
add.s32 %r8980, %r38, %r66;
mul.wide.s32 %rd490, %r8980, 4;
add.s64 %rd24, %rd443, %rd490;
@%p7 bra $L__BB54_218;

st.global.f32 [%rd24], %f1815;

$L__BB54_218:
@%p8 bra $L__BB54_220;

st.global.f32 [%rd24+128], %f1783;

$L__BB54_220:
@%p9 bra $L__BB54_222;

st.global.f32 [%rd24+256], %f1751;

$L__BB54_222:
@%p10 bra $L__BB54_224;

st.global.f32 [%rd24+384], %f1719;

$L__BB54_224:
add.s32 %r8981, %r37, 96;
setp.ge.s32 %p126, %r8981, %r75;
@%p126 bra $L__BB54_296;

add.s32 %r67, %r66, %r43;
add.s32 %r8982, %r38, %r67;
mul.wide.s32 %rd492, %r8982, 4;
add.s64 %rd25, %rd443, %rd492;
@%p7 bra $L__BB54_227;

st.global.f32 [%rd25], %f1814;

$L__BB54_227:
@%p8 bra $L__BB54_229;

st.global.f32 [%rd25+128], %f1782;

$L__BB54_229:
@%p9 bra $L__BB54_231;

st.global.f32 [%rd25+256], %f1750;

$L__BB54_231:
@%p10 bra $L__BB54_233;

st.global.f32 [%rd25+384], %f1718;

$L__BB54_233:
add.s32 %r8983, %r37, 100;
setp.ge.s32 %p131, %r8983, %r75;
@%p131 bra $L__BB54_296;

add.s32 %r68, %r67, %r43;
add.s32 %r8984, %r38, %r68;
mul.wide.s32 %rd494, %r8984, 4;
add.s64 %rd26, %rd443, %rd494;
@%p7 bra $L__BB54_236;

st.global.f32 [%rd26], %f1813;

$L__BB54_236:
@%p8 bra $L__BB54_238;

st.global.f32 [%rd26+128], %f1781;

$L__BB54_238:
@%p9 bra $L__BB54_240;

st.global.f32 [%rd26+256], %f1749;

$L__BB54_240:
@%p10 bra $L__BB54_242;

st.global.f32 [%rd26+384], %f1717;

$L__BB54_242:
add.s32 %r8985, %r37, 104;
setp.ge.s32 %p136, %r8985, %r75;
@%p136 bra $L__BB54_296;

add.s32 %r69, %r68, %r43;
add.s32 %r8986, %r38, %r69;
mul.wide.s32 %rd496, %r8986, 4;
add.s64 %rd27, %rd443, %rd496;
@%p7 bra $L__BB54_245;

st.global.f32 [%rd27], %f1812;

$L__BB54_245:
@%p8 bra $L__BB54_247;

st.global.f32 [%rd27+128], %f1780;

$L__BB54_247:
@%p9 bra $L__BB54_249;

st.global.f32 [%rd27+256], %f1748;

$L__BB54_249:
@%p10 bra $L__BB54_251;

st.global.f32 [%rd27+384], %f1716;

$L__BB54_251:
add.s32 %r8987, %r37, 108;
setp.ge.s32 %p141, %r8987, %r75;
@%p141 bra $L__BB54_296;

add.s32 %r70, %r69, %r43;
add.s32 %r8988, %r38, %r70;
mul.wide.s32 %rd498, %r8988, 4;
add.s64 %rd28, %rd443, %rd498;
@%p7 bra $L__BB54_254;

st.global.f32 [%rd28], %f1811;

$L__BB54_254:
@%p8 bra $L__BB54_256;

st.global.f32 [%rd28+128], %f1779;

$L__BB54_256:
@%p9 bra $L__BB54_258;

st.global.f32 [%rd28+256], %f1747;

$L__BB54_258:
@%p10 bra $L__BB54_260;

st.global.f32 [%rd28+384], %f1715;

$L__BB54_260:
add.s32 %r8989, %r37, 112;
setp.ge.s32 %p146, %r8989, %r75;
@%p146 bra $L__BB54_296;

add.s32 %r71, %r70, %r43;
add.s32 %r8990, %r38, %r71;
mul.wide.s32 %rd500, %r8990, 4;
add.s64 %rd29, %rd443, %rd500;
@%p7 bra $L__BB54_263;

st.global.f32 [%rd29], %f1810;

$L__BB54_263:
@%p8 bra $L__BB54_265;

st.global.f32 [%rd29+128], %f1778;

$L__BB54_265:
@%p9 bra $L__BB54_267;

st.global.f32 [%rd29+256], %f1746;

$L__BB54_267:
@%p10 bra $L__BB54_269;

st.global.f32 [%rd29+384], %f1714;

$L__BB54_269:
add.s32 %r8991, %r37, 116;
setp.ge.s32 %p151, %r8991, %r75;
@%p151 bra $L__BB54_296;

add.s32 %r72, %r71, %r43;
add.s32 %r8992, %r38, %r72;
mul.wide.s32 %rd502, %r8992, 4;
add.s64 %rd30, %rd443, %rd502;
@%p7 bra $L__BB54_272;

st.global.f32 [%rd30], %f1809;

$L__BB54_272:
@%p8 bra $L__BB54_274;

st.global.f32 [%rd30+128], %f1777;

$L__BB54_274:
@%p9 bra $L__BB54_276;

st.global.f32 [%rd30+256], %f1745;

$L__BB54_276:
@%p10 bra $L__BB54_278;

st.global.f32 [%rd30+384], %f1713;

$L__BB54_278:
add.s32 %r8993, %r37, 120;
setp.ge.s32 %p156, %r8993, %r75;
@%p156 bra $L__BB54_296;

add.s32 %r73, %r72, %r43;
add.s32 %r8994, %r38, %r73;
mul.wide.s32 %rd504, %r8994, 4;
add.s64 %rd31, %rd443, %rd504;
@%p7 bra $L__BB54_281;

st.global.f32 [%rd31], %f1808;

$L__BB54_281:
@%p8 bra $L__BB54_283;

st.global.f32 [%rd31+128], %f1776;

$L__BB54_283:
@%p9 bra $L__BB54_285;

st.global.f32 [%rd31+256], %f1744;

$L__BB54_285:
@%p10 bra $L__BB54_287;

st.global.f32 [%rd31+384], %f1712;

$L__BB54_287:
add.s32 %r8995, %r37, 124;
setp.ge.s32 %p161, %r8995, %r75;
@%p161 bra $L__BB54_296;

add.s32 %r8996, %r73, %r43;
add.s32 %r8997, %r38, %r8996;
mul.wide.s32 %rd506, %r8997, 4;
add.s64 %rd32, %rd443, %rd506;
@%p7 bra $L__BB54_290;

st.global.f32 [%rd32], %f1807;

$L__BB54_290:
@%p8 bra $L__BB54_292;

st.global.f32 [%rd32+128], %f1775;

$L__BB54_292:
@%p9 bra $L__BB54_294;

st.global.f32 [%rd32+256], %f1743;

$L__BB54_294:
@%p10 bra $L__BB54_296;

st.global.f32 [%rd32+384], %f1711;

$L__BB54_296:
ret;

}
