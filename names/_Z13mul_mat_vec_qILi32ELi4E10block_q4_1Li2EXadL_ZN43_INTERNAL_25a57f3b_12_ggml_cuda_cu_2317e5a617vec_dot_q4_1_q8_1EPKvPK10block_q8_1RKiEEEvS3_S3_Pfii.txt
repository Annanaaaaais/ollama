.entry _Z13mul_mat_vec_qILi32ELi4E10block_q4_1Li2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a617vec_dot_q4_1_q8_1EPKvPK10block_q8_1RKiEEEvS3_S3_Pfii
.param .u64 _Z13mul_mat_vec_qILi32ELi4E10block_q4_1Li2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a617vec_dot_q4_1_q8_1EPKvPK10block_q8_1RKiEEEvS3_S3_Pfii_param_0,
.param .u64 _Z13mul_mat_vec_qILi32ELi4E10block_q4_1Li2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a617vec_dot_q4_1_q8_1EPKvPK10block_q8_1RKiEEEvS3_S3_Pfii_param_1,
.param .u64 _Z13mul_mat_vec_qILi32ELi4E10block_q4_1Li2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a617vec_dot_q4_1_q8_1EPKvPK10block_q8_1RKiEEEvS3_S3_Pfii_param_2,
.param .u32 _Z13mul_mat_vec_qILi32ELi4E10block_q4_1Li2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a617vec_dot_q4_1_q8_1EPKvPK10block_q8_1RKiEEEvS3_S3_Pfii_param_3,
.param .u32 _Z13mul_mat_vec_qILi32ELi4E10block_q4_1Li2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a617vec_dot_q4_1_q8_1EPKvPK10block_q8_1RKiEEEvS3_S3_Pfii_param_4
)
{
.reg .pred %p<12>;
.reg .f32 %f<55>;
.reg .b32 %r<123>;
.reg .b64 %rd<38>;


ld.param.u64 %rd13, [_Z13mul_mat_vec_qILi32ELi4E10block_q4_1Li2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a617vec_dot_q4_1_q8_1EPKvPK10block_q8_1RKiEEEvS3_S3_Pfii_param_0];
ld.param.u64 %rd14, [_Z13mul_mat_vec_qILi32ELi4E10block_q4_1Li2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a617vec_dot_q4_1_q8_1EPKvPK10block_q8_1RKiEEEvS3_S3_Pfii_param_1];
ld.param.u64 %rd15, [_Z13mul_mat_vec_qILi32ELi4E10block_q4_1Li2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a617vec_dot_q4_1_q8_1EPKvPK10block_q8_1RKiEEEvS3_S3_Pfii_param_2];
ld.param.u32 %r14, [_Z13mul_mat_vec_qILi32ELi4E10block_q4_1Li2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a617vec_dot_q4_1_q8_1EPKvPK10block_q8_1RKiEEEvS3_S3_Pfii_param_3];
ld.param.u32 %r15, [_Z13mul_mat_vec_qILi32ELi4E10block_q4_1Li2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a617vec_dot_q4_1_q8_1EPKvPK10block_q8_1RKiEEEvS3_S3_Pfii_param_4];
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %ctaid.y;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r1, %r17, %r16, %r18;
setp.ge.s32 %p1, %r1, %r15;
@%p1 bra $L__BB29_10;

cvta.to.global.u64 %rd1, %rd13;
cvta.to.global.u64 %rd2, %rd14;
setp.gt.s32 %p2, %r14, 31;
@%p2 bra $L__BB29_3;
bra.uni $L__BB29_2;

$L__BB29_3:
shr.s32 %r20, %r14, 31;
shr.u32 %r21, %r20, 27;
add.s32 %r22, %r14, %r21;
shr.s32 %r23, %r22, 5;
mov.u32 %r2, %tid.x;
shr.u32 %r3, %r2, 1;
mad.lo.s32 %r4, %r23, %r1, %r3;
shl.b32 %r24, %r2, 3;
and.b32 %r5, %r24, 8;
add.s32 %r25, %r23, -1;
shr.u32 %r6, %r25, 4;
add.s32 %r26, %r6, 1;
and.b32 %r7, %r26, 1;
setp.eq.s32 %p3, %r6, 0;
mov.f32 %f52, 0f00000000;
mov.u32 %r122, 0;
@%p3 bra $L__BB29_6;

cvt.u64.u32 %rd16, %r5;
sub.s32 %r120, %r6, %r7;
mul.wide.s32 %rd17, %r4, 20;
add.s64 %rd37, %rd1, %rd17;
add.s64 %rd4, %rd16, 328;
cvt.u64.u32 %rd18, %r2;
shr.u64 %rd19, %rd18, 1;
mul.lo.s64 %rd20, %rd19, 36;
add.s64 %rd21, %rd20, %rd16;
add.s64 %rd22, %rd2, %rd21;
add.s64 %rd36, %rd22, 600;
add.s64 %rd23, %rd2, %rd20;
add.s64 %rd35, %rd23, 576;

$L__BB29_5:
ld.global.nc.u32 %r30, [%rd36+-596];
ld.global.nc.u32 %r34, [%rd36+-580];
add.s64 %rd24, %rd37, %rd4;
ld.global.nc.u32 %r68, [%rd24+-320];
ld.global.nc.u32 %r38, [%rd36+-592];
ld.global.nc.u32 %r42, [%rd36+-576];
ld.global.nc.u32 %r69, [%rd24+-324];
and.b32 %r29, %r69, 252645135;
shr.u32 %r70, %r69, 4;
and.b32 %r33, %r70, 252645135;
mov.u32 %r51, 0;

	dp4a.s32.s32 %r28, %r29, %r30, %r51;

	
	dp4a.s32.s32 %r32, %r33, %r34, %r28;

	and.b32 %r37, %r68, 252645135;
shr.u32 %r71, %r68, 4;
and.b32 %r41, %r71, 252645135;

	dp4a.s32.s32 %r36, %r37, %r38, %r32;

	
	dp4a.s32.s32 %r40, %r41, %r42, %r36;

	ld.global.nc.u32 %r44, [%rd37];

	{.reg .f16 low,high;
mov.b32 {low,high},%r44;
cvt.f32.f16 %f12, low;}


	
	{.reg .f16 low,high;
mov.b32 {low,high},%r44;
cvt.f32.f16 %f13, high;}


	ld.global.nc.u32 %r46, [%rd35+-576];

	{.reg .f16 low,high;
mov.b32 {low,high},%r46;
cvt.f32.f16 %f14, low;}


	
	{.reg .f16 low,high;
mov.b32 {low,high},%r46;
cvt.f32.f16 %f15, high;}


	mul.ftz.f32 %f20, %f12, %f14;
mul.ftz.f32 %f21, %f13, %f15;
cvt.rn.f32.s32 %f22, %r40;
mov.f32 %f23, 0f40000000;
div.approx.ftz.f32 %f24, %f21, %f23;
fma.rn.ftz.f32 %f25, %f20, %f22, %f24;
add.ftz.f32 %f26, %f52, %f25;
ld.global.nc.u32 %r50, [%rd36+-20];
ld.global.nc.u32 %r54, [%rd36+-4];
ld.global.nc.u32 %r72, [%rd24];
ld.global.nc.u32 %r58, [%rd36+-16];
ld.global.nc.u32 %r62, [%rd36];
ld.global.nc.u32 %r73, [%rd24+-4];
and.b32 %r49, %r73, 252645135;
shr.u32 %r74, %r73, 4;
and.b32 %r53, %r74, 252645135;

	dp4a.s32.s32 %r48, %r49, %r50, %r51;

	
	dp4a.s32.s32 %r52, %r53, %r54, %r48;

	and.b32 %r57, %r72, 252645135;
shr.u32 %r75, %r72, 4;
and.b32 %r61, %r75, 252645135;

	dp4a.s32.s32 %r56, %r57, %r58, %r52;

	
	dp4a.s32.s32 %r60, %r61, %r62, %r56;

	ld.global.nc.u32 %r64, [%rd37+320];

	{.reg .f16 low,high;
mov.b32 {low,high},%r64;
cvt.f32.f16 %f16, low;}


	
	{.reg .f16 low,high;
mov.b32 {low,high},%r64;
cvt.f32.f16 %f17, high;}


	ld.global.nc.u32 %r66, [%rd35];

	{.reg .f16 low,high;
mov.b32 {low,high},%r66;
cvt.f32.f16 %f18, low;}


	
	{.reg .f16 low,high;
mov.b32 {low,high},%r66;
cvt.f32.f16 %f19, high;}


	mul.ftz.f32 %f27, %f16, %f18;
mul.ftz.f32 %f28, %f17, %f19;
cvt.rn.f32.s32 %f29, %r60;
div.approx.ftz.f32 %f30, %f28, %f23;
fma.rn.ftz.f32 %f31, %f27, %f29, %f30;
add.ftz.f32 %f52, %f26, %f31;
add.s32 %r122, %r122, 32;
add.s64 %rd37, %rd37, 640;
add.s64 %rd36, %rd36, 1152;
add.s64 %rd35, %rd35, 1152;
add.s32 %r120, %r120, -2;
setp.ne.s32 %p4, %r120, -1;
@%p4 bra $L__BB29_5;

$L__BB29_6:
setp.eq.s32 %p5, %r7, 0;
@%p5 bra $L__BB29_8;

add.s32 %r96, %r4, %r122;
mul.wide.s32 %rd25, %r96, 20;
add.s64 %rd26, %rd1, %rd25;
add.s32 %r97, %r122, %r3;
mul.wide.s32 %rd27, %r97, 36;
add.s64 %rd28, %rd2, %rd27;
cvt.u64.u32 %rd29, %r5;
add.s64 %rd30, %rd26, %rd29;
add.s64 %rd31, %rd28, %rd29;
ld.global.nc.u32 %r78, [%rd31+4];
ld.global.nc.u32 %r82, [%rd31+20];
ld.global.nc.u32 %r98, [%rd30+8];
ld.global.nc.u32 %r86, [%rd31+8];
ld.global.nc.u32 %r90, [%rd31+24];
ld.global.nc.u32 %r99, [%rd30+4];
and.b32 %r77, %r99, 252645135;
shr.u32 %r100, %r99, 4;
and.b32 %r81, %r100, 252645135;
mov.u32 %r79, 0;

	dp4a.s32.s32 %r76, %r77, %r78, %r79;

	
	dp4a.s32.s32 %r80, %r81, %r82, %r76;

	and.b32 %r85, %r98, 252645135;
shr.u32 %r101, %r98, 4;
and.b32 %r89, %r101, 252645135;

	dp4a.s32.s32 %r84, %r85, %r86, %r80;

	
	dp4a.s32.s32 %r88, %r89, %r90, %r84;

	ld.global.nc.u32 %r92, [%rd26];

	{.reg .f16 low,high;
mov.b32 {low,high},%r92;
cvt.f32.f16 %f32, low;}


	
	{.reg .f16 low,high;
mov.b32 {low,high},%r92;
cvt.f32.f16 %f33, high;}


	ld.global.nc.u32 %r94, [%rd28];

	{.reg .f16 low,high;
mov.b32 {low,high},%r94;
cvt.f32.f16 %f34, low;}


	
	{.reg .f16 low,high;
mov.b32 {low,high},%r94;
cvt.f32.f16 %f35, high;}


	mul.ftz.f32 %f36, %f32, %f34;
mul.ftz.f32 %f37, %f33, %f35;
cvt.rn.f32.s32 %f38, %r88;
mov.f32 %f39, 0f40000000;
div.approx.ftz.f32 %f40, %f37, %f39;
fma.rn.ftz.f32 %f41, %f36, %f38, %f40;
add.ftz.f32 %f52, %f52, %f41;
bra.uni $L__BB29_8;

$L__BB29_2:
mov.f32 %f52, 0f00000000;

$L__BB29_8:
mov.b32 %r102, %f52;
mov.u32 %r103, 31;
mov.u32 %r104, 16;
mov.u32 %r105, -1;
shfl.sync.bfly.b32 %r106|%p6, %r102, %r104, %r103, %r105;
mov.b32 %f42, %r106;
add.ftz.f32 %f43, %f52, %f42;
mov.b32 %r107, %f43;
mov.u32 %r108, 8;
shfl.sync.bfly.b32 %r109|%p7, %r107, %r108, %r103, %r105;
mov.b32 %f44, %r109;
add.ftz.f32 %f45, %f43, %f44;
mov.b32 %r110, %f45;
mov.u32 %r111, 4;
shfl.sync.bfly.b32 %r112|%p8, %r110, %r111, %r103, %r105;
mov.b32 %f46, %r112;
add.ftz.f32 %f47, %f45, %f46;
mov.b32 %r113, %f47;
mov.u32 %r114, 2;
shfl.sync.bfly.b32 %r115|%p9, %r113, %r114, %r103, %r105;
mov.b32 %f48, %r115;
add.ftz.f32 %f49, %f47, %f48;
mov.b32 %r116, %f49;
mov.u32 %r117, 1;
shfl.sync.bfly.b32 %r118|%p10, %r116, %r117, %r103, %r105;
mov.b32 %f50, %r118;
add.ftz.f32 %f7, %f49, %f50;
mov.u32 %r119, %tid.x;
setp.ne.s32 %p11, %r119, 0;
@%p11 bra $L__BB29_10;

cvta.to.global.u64 %rd32, %rd15;
mul.wide.s32 %rd33, %r1, 4;
add.s64 %rd34, %rd32, %rd33;
st.global.f32 [%rd34], %f7;

$L__BB29_10:
ret;

}
