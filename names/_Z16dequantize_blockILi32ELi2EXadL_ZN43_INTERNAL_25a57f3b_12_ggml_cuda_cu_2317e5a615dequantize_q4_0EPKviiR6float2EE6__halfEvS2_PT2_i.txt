.entry _Z16dequantize_blockILi32ELi2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a615dequantize_q4_0EPKviiR6float2EE6__halfEvS2_PT2_i
.param .u64 _Z16dequantize_blockILi32ELi2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a615dequantize_q4_0EPKviiR6float2EE6__halfEvS2_PT2_i_param_0,
.param .u64 _Z16dequantize_blockILi32ELi2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a615dequantize_q4_0EPKviiR6float2EE6__halfEvS2_PT2_i_param_1,
.param .u32 _Z16dequantize_blockILi32ELi2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a615dequantize_q4_0EPKviiR6float2EE6__halfEvS2_PT2_i_param_2
)
{
.reg .pred %p<2>;
.reg .b16 %rs<5>;
.reg .f32 %f<8>;
.reg .b32 %r<21>;
.reg .b64 %rd<11>;


ld.param.u64 %rd1, [_Z16dequantize_blockILi32ELi2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a615dequantize_q4_0EPKviiR6float2EE6__halfEvS2_PT2_i_param_0];
ld.param.u64 %rd2, [_Z16dequantize_blockILi32ELi2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a615dequantize_q4_0EPKviiR6float2EE6__halfEvS2_PT2_i_param_1];
ld.param.u32 %r2, [_Z16dequantize_blockILi32ELi2EXadL_ZN43_INTERNAL_25a57f3b_12_ggml_cuda_cu_2317e5a615dequantize_q4_0EPKviiR6float2EE6__halfEvS2_PT2_i_param_2];
mov.u32 %r3, %ctaid.x;
mov.u32 %r4, %ntid.x;
mov.u32 %r5, %tid.x;
shl.b32 %r6, %r5, 1;
mad.lo.s32 %r1, %r4, %r3, %r6;
setp.ge.s32 %p1, %r1, %r2;
@%p1 bra $L__BB63_2;

cvta.to.global.u64 %rd3, %rd1;
shr.s32 %r7, %r1, 31;
shr.u32 %r8, %r7, 27;
add.s32 %r9, %r1, %r8;
and.b32 %r10, %r9, -32;
sub.s32 %r11, %r1, %r10;
shr.u32 %r12, %r11, 31;
add.s32 %r13, %r11, %r12;
shr.s32 %r14, %r13, 1;
shr.s32 %r15, %r9, 5;
mul.wide.s32 %rd4, %r15, 18;
add.s64 %rd5, %rd3, %rd4;
ld.global.nc.u16 %rs1, [%rd5];

	{ cvt.f32.f16 %f1, %rs1;}


	cvt.s64.s32 %rd6, %r14;
add.s64 %rd7, %rd5, %rd6;
ld.global.nc.u8 %rs4, [%rd7+2];
cvt.u32.u16 %r16, %rs4;
and.b32 %r17, %r16, 240;
and.b32 %r18, %r16, 15;
cvt.rn.f32.s32 %f4, %r18;
shr.u32 %r19, %r17, 4;
cvt.rn.f32.s32 %f5, %r19;
add.ftz.f32 %f6, %f4, 0fC1000000;
mul.ftz.f32 %f2, %f1, %f6;
add.ftz.f32 %f7, %f5, 0fC1000000;
mul.ftz.f32 %f3, %f1, %f7;
add.s32 %r20, %r10, %r14;

	{ cvt.rn.f16.f32 %rs2, %f2;}


	cvta.to.global.u64 %rd8, %rd2;
mul.wide.s32 %rd9, %r20, 2;
add.s64 %rd10, %rd8, %rd9;
st.global.u16 [%rd10], %rs2;

	{ cvt.rn.f16.f32 %rs3, %f3;}


	st.global.u16 [%rd10+32], %rs3;

$L__BB63_2:
ret;

}
